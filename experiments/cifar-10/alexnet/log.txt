[2020-03-03 08:33:03,860] - {'architecture': 'alexnet', 'ckpt_path': './', 'ckpt_name': 'alexnet', 'log_path': './', 'log_name': 'cifar10', 'log_color': {'train': 'cyan', 'cost_time': 'yellow', 'test': 'red'}, 'data_name': 'CIFAR10', 'num_classes': 10, 'train_set_path': './data/cifar-10', 'test_set_path': './data/cifar-10', 'augmentation': {'normalize': True, 'random_crop': True, 'random_horizontal_filp': True}, 'device': 'cuda', 'input_size': 32, 'batch_size': 128, 'num_epochs': 50, 'num_print': 100, 'num_workers': 4, 'eval_freq': 1, 'test_batch': 200, 'optimizer': {'name': 'SGD', 'params': {'lr': 0.02, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': True}}, 'lr_scheduler': {'type': 'STEP', 'lr_epochs': [40], 'lr_mults': 0.1}, 'learning_curve': {'style': 'ggplot', 'xtick_step': 5, 'draw_freq': 10, 'save_path': './plot/'}}
AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace)
    (10): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace)
  )
  (classifier): Sequential(
    (0): Linear(in_features=1152, out_features=32, bias=True)
    (1): ReLU(inplace)
    (2): Dropout(p=0.5)
    (3): Linear(in_features=32, out_features=32, bias=True)
    (4): ReLU(inplace)
    (5): Dropout(p=0.5)
    (6): Linear(in_features=32, out_features=10, bias=True)
  )
)
-------------------- Training parameters: 1432970 --------------------
[2020-03-03 08:33:03,860] - ========== epoch: [1/50] ==========
[2020-03-03 08:33:04,624] - step: [100/391], train_loss: 2.305 | train_acc:  9.891% | lr: 0.020000
[2020-03-03 08:33:05,141] - step: [200/391], train_loss: 2.297 | train_acc: 11.008% | lr: 0.020000
[2020-03-03 08:33:05,661] - step: [300/391], train_loss: 2.239 | train_acc: 13.159% | lr: 0.020000
[2020-03-03 08:33:06,147] - --- cost time: 2.2868s ---
[2020-03-03 08:33:06,148] - *************** test ***************
[2020-03-03 08:33:06,686] - test_loss: 1.932 | test_acc: 19.370%
[2020-03-03 08:33:06,686] - ************************************

[2020-03-03 08:33:06,708] - ========== epoch: [2/50] ==========
[2020-03-03 08:33:07,303] - step: [100/391], train_loss: 1.980 | train_acc: 19.312% | lr: 0.020000
[2020-03-03 08:33:07,826] - step: [200/391], train_loss: 1.963 | train_acc: 19.527% | lr: 0.020000
[2020-03-03 08:33:08,346] - step: [300/391], train_loss: 1.957 | train_acc: 19.773% | lr: 0.020000
[2020-03-03 08:33:08,838] - --- cost time: 2.1302s ---
[2020-03-03 08:33:08,838] - *************** test ***************
[2020-03-03 08:33:09,353] - test_loss: 1.894 | test_acc: 20.890%
[2020-03-03 08:33:09,354] - ************************************

[2020-03-03 08:33:09,375] - ========== epoch: [3/50] ==========
[2020-03-03 08:33:09,967] - step: [100/391], train_loss: 1.908 | train_acc: 21.531% | lr: 0.020000
[2020-03-03 08:33:10,486] - step: [200/391], train_loss: 1.900 | train_acc: 21.906% | lr: 0.020000
[2020-03-03 08:33:11,006] - step: [300/391], train_loss: 1.896 | train_acc: 22.018% | lr: 0.020000
[2020-03-03 08:33:11,497] - --- cost time: 2.1222s ---
[2020-03-03 08:33:11,497] - *************** test ***************
[2020-03-03 08:33:12,023] - test_loss: 1.816 | test_acc: 24.940%
[2020-03-03 08:33:12,024] - ************************************

[2020-03-03 08:33:12,045] - ========== epoch: [4/50] ==========
[2020-03-03 08:33:12,639] - step: [100/391], train_loss: 1.872 | train_acc: 23.070% | lr: 0.020000
[2020-03-03 08:33:13,159] - step: [200/391], train_loss: 1.867 | train_acc: 23.707% | lr: 0.020000
[2020-03-03 08:33:13,677] - step: [300/391], train_loss: 1.861 | train_acc: 24.227% | lr: 0.020000
[2020-03-03 08:33:14,169] - --- cost time: 2.1231s ---
[2020-03-03 08:33:14,169] - *************** test ***************
[2020-03-03 08:33:14,683] - test_loss: 1.808 | test_acc: 25.830%
[2020-03-03 08:33:14,683] - ************************************

[2020-03-03 08:33:14,705] - ========== epoch: [5/50] ==========
[2020-03-03 08:35:23,695] - {'architecture': 'alexnet', 'ckpt_path': './', 'ckpt_name': 'alexnet', 'log_path': './', 'log_name': 'cifar10', 'log_color': {'train': 'cyan', 'cost_time': 'yellow', 'test': 'red'}, 'data_name': 'CIFAR10', 'num_classes': 10, 'train_set_path': './data/cifar-10', 'test_set_path': './data/cifar-10', 'augmentation': {'normalize': True, 'random_crop': True, 'random_horizontal_filp': True}, 'device': 'cuda', 'input_size': 32, 'batch_size': 128, 'num_epochs': 50, 'num_print': 100, 'num_workers': 4, 'eval_freq': 1, 'test_batch': 200, 'optimizer': {'name': 'SGD', 'params': {'lr': 0.02, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': True}}, 'lr_scheduler': {'type': 'STEP', 'lr_epochs': [40], 'lr_mults': 0.1}, 'learning_curve': {'style': 'ggplot', 'xtick_step': 5, 'draw_freq': 10, 'save_path': './plot/'}}
AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace)
    (10): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace)
  )
  (classifier): Sequential(
    (0): Linear(in_features=1152, out_features=32, bias=True)
    (1): ReLU(inplace)
    (2): Dropout(p=0.5)
    (3): Linear(in_features=32, out_features=32, bias=True)
    (4): ReLU(inplace)
    (5): Dropout(p=0.5)
    (6): Linear(in_features=32, out_features=10, bias=True)
  )
)
-------------------- Training parameters: 1432970 --------------------
[2020-03-03 08:35:23,695] - ========== epoch: [1/50] ==========
[2020-03-03 08:35:24,464] - step: [100/391], train_loss: 2.305 | train_acc:  9.719% | lr: 0.020000
[2020-03-03 08:35:24,986] - step: [200/391], train_loss: 2.303 | train_acc: 10.266% | lr: 0.020000
[2020-03-03 08:35:25,506] - step: [300/391], train_loss: 2.278 | train_acc: 11.776% | lr: 0.020000
[2020-03-03 08:35:25,988] - --- cost time: 2.2923s ---
[2020-03-03 08:35:25,988] - *************** test ***************
[2020-03-03 08:35:26,500] - test_loss: 1.989 | test_acc: 18.700%
[2020-03-03 08:35:26,500] - ************************************

[2020-03-03 08:35:26,521] - ========== epoch: [2/50] ==========
[2020-03-03 08:35:27,113] - step: [100/391], train_loss: 2.005 | train_acc: 18.570% | lr: 0.020000
[2020-03-03 08:35:27,627] - step: [200/391], train_loss: 1.986 | train_acc: 18.910% | lr: 0.020000
[2020-03-03 08:35:28,144] - step: [300/391], train_loss: 1.966 | train_acc: 19.557% | lr: 0.020000
[2020-03-03 08:35:28,630] - --- cost time: 2.1084s ---
[2020-03-03 08:35:28,630] - *************** test ***************
[2020-03-03 08:35:29,133] - test_loss: 1.876 | test_acc: 25.330%
[2020-03-03 08:35:29,134] - ************************************

[2020-03-03 08:35:29,155] - ========== epoch: [3/50] ==========
[2020-03-03 08:35:29,753] - step: [100/391], train_loss: 1.910 | train_acc: 22.625% | lr: 0.020000
[2020-03-03 08:35:30,270] - step: [200/391], train_loss: 1.898 | train_acc: 23.387% | lr: 0.020000
[2020-03-03 08:35:30,788] - step: [300/391], train_loss: 1.889 | train_acc: 23.695% | lr: 0.020000
[2020-03-03 08:35:31,275] - --- cost time: 2.1197s ---
[2020-03-03 08:35:31,275] - *************** test ***************
[2020-03-03 08:35:31,778] - test_loss: 1.825 | test_acc: 27.490%
[2020-03-03 08:35:31,779] - ************************************

[2020-03-03 08:35:31,797] - ========== epoch: [4/50] ==========
[2020-03-03 08:36:10,252] - {'architecture': 'alexnet', 'ckpt_path': './', 'ckpt_name': 'alexnet', 'log_path': './', 'log_name': 'cifar10', 'log_color': {'train': 'cyan', 'cost_time': 'yellow', 'test': 'cyan'}, 'data_name': 'CIFAR10', 'num_classes': 10, 'train_set_path': './data/cifar-10', 'test_set_path': './data/cifar-10', 'augmentation': {'normalize': True, 'random_crop': True, 'random_horizontal_filp': True}, 'device': 'cuda', 'input_size': 32, 'batch_size': 128, 'num_epochs': 50, 'num_print': 100, 'num_workers': 4, 'eval_freq': 1, 'test_batch': 200, 'optimizer': {'name': 'SGD', 'params': {'lr': 0.02, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': True}}, 'lr_scheduler': {'type': 'STEP', 'lr_epochs': [40], 'lr_mults': 0.1}, 'learning_curve': {'style': 'ggplot', 'xtick_step': 5, 'draw_freq': 10, 'save_path': './plot/'}}
AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace)
    (10): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace)
  )
  (classifier): Sequential(
    (0): Linear(in_features=1152, out_features=32, bias=True)
    (1): ReLU(inplace)
    (2): Dropout(p=0.5)
    (3): Linear(in_features=32, out_features=32, bias=True)
    (4): ReLU(inplace)
    (5): Dropout(p=0.5)
    (6): Linear(in_features=32, out_features=10, bias=True)
  )
)
-------------------- Training parameters: 1432970 --------------------
[2020-03-03 08:36:10,252] - ========== epoch: [1/50] ==========
[2020-03-03 08:36:11,035] - step: [100/391], train_loss: 2.304 | train_acc: 10.352% | lr: 0.020000
[2020-03-03 08:36:11,556] - step: [200/391], train_loss: 2.278 | train_acc: 12.035% | lr: 0.020000
[2020-03-03 08:36:12,074] - step: [300/391], train_loss: 2.211 | train_acc: 13.990% | lr: 0.020000
[2020-03-03 08:36:12,560] - --- cost time: 2.3080s ---
[2020-03-03 08:36:12,561] - *************** test ***************
[2020-03-03 08:36:13,069] - test_loss: 1.939 | test_acc: 21.100%
[2020-03-03 08:36:13,069] - ************************************

[2020-03-03 08:36:13,091] - ========== epoch: [2/50] ==========
[2020-03-03 08:36:13,685] - step: [100/391], train_loss: 1.957 | train_acc: 19.859% | lr: 0.020000
[2020-03-03 08:36:14,201] - step: [200/391], train_loss: 1.953 | train_acc: 19.805% | lr: 0.020000
[2020-03-03 08:36:14,716] - step: [300/391], train_loss: 1.945 | train_acc: 20.247% | lr: 0.020000
[2020-03-03 08:36:15,200] - --- cost time: 2.1084s ---
[2020-03-03 08:36:15,200] - *************** test ***************
[2020-03-03 08:36:15,717] - test_loss: 1.872 | test_acc: 23.530%
[2020-03-03 08:36:15,717] - ************************************

[2020-03-03 08:36:15,738] - ========== epoch: [3/50] ==========
[2020-03-03 08:36:16,330] - step: [100/391], train_loss: 1.911 | train_acc: 21.938% | lr: 0.020000
[2020-03-03 08:36:16,852] - step: [200/391], train_loss: 1.899 | train_acc: 22.070% | lr: 0.020000
[2020-03-03 08:36:17,374] - step: [300/391], train_loss: 1.896 | train_acc: 22.565% | lr: 0.020000
[2020-03-03 08:36:17,859] - --- cost time: 2.1204s ---
[2020-03-03 08:36:17,859] - *************** test ***************
[2020-03-03 08:36:18,360] - test_loss: 1.810 | test_acc: 29.550%
[2020-03-03 08:36:18,360] - ************************************

[2020-03-03 08:36:18,381] - ========== epoch: [4/50] ==========
[2020-03-03 08:36:18,972] - step: [100/391], train_loss: 1.849 | train_acc: 26.172% | lr: 0.020000
[2020-03-03 08:36:19,487] - step: [200/391], train_loss: 1.837 | train_acc: 27.250% | lr: 0.020000
[2020-03-03 08:36:20,000] - step: [300/391], train_loss: 1.828 | train_acc: 27.974% | lr: 0.020000
[2020-03-03 08:36:20,495] - --- cost time: 2.1138s ---
[2020-03-03 08:36:20,495] - *************** test ***************
[2020-03-03 08:36:20,997] - test_loss: 1.695 | test_acc: 32.740%
[2020-03-03 08:36:20,997] - ************************************

[2020-03-03 08:36:21,018] - ========== epoch: [5/50] ==========
[2020-03-03 08:36:21,617] - step: [100/391], train_loss: 1.719 | train_acc: 33.648% | lr: 0.020000
[2020-03-03 08:36:22,133] - step: [200/391], train_loss: 1.708 | train_acc: 33.980% | lr: 0.020000
[2020-03-03 08:36:22,653] - step: [300/391], train_loss: 1.688 | train_acc: 34.701% | lr: 0.020000
[2020-03-03 08:36:23,134] - --- cost time: 2.1156s ---
[2020-03-03 08:36:23,134] - *************** test ***************
[2020-03-03 08:36:23,642] - test_loss: 1.486 | test_acc: 42.050%
[2020-03-03 08:36:23,642] - ************************************

[2020-03-03 08:36:23,663] - ========== epoch: [6/50] ==========
[2020-03-03 08:36:24,260] - step: [100/391], train_loss: 1.599 | train_acc: 38.438% | lr: 0.020000
[2020-03-03 08:36:24,779] - step: [200/391], train_loss: 1.596 | train_acc: 38.602% | lr: 0.020000
[2020-03-03 08:36:25,299] - step: [300/391], train_loss: 1.588 | train_acc: 38.951% | lr: 0.020000
[2020-03-03 08:36:25,800] - --- cost time: 2.1368s ---
[2020-03-03 08:36:25,801] - *************** test ***************
[2020-03-03 08:36:26,323] - test_loss: 1.428 | test_acc: 45.620%
[2020-03-03 08:36:26,323] - ************************************

[2020-03-03 08:36:26,344] - ========== epoch: [7/50] ==========
[2020-03-03 08:36:26,935] - step: [100/391], train_loss: 1.547 | train_acc: 41.219% | lr: 0.020000
[2020-03-03 08:36:27,453] - step: [200/391], train_loss: 1.540 | train_acc: 41.422% | lr: 0.020000
[2020-03-03 08:36:27,970] - step: [300/391], train_loss: 1.530 | train_acc: 41.974% | lr: 0.020000
[2020-03-03 08:36:28,467] - --- cost time: 2.1230s ---
[2020-03-03 08:36:28,468] - *************** test ***************
[2020-03-03 08:36:28,977] - test_loss: 1.340 | test_acc: 48.950%
[2020-03-03 08:36:28,977] - ************************************

[2020-03-03 08:36:28,998] - ========== epoch: [8/50] ==========
[2020-03-03 08:38:09,143] - {'architecture': 'alexnet', 'ckpt_path': './', 'ckpt_name': 'alexnet', 'log_path': './', 'log_name': 'cifar10', 'log_color': {'train': 'cyan', 'cost_time': 'yellow', 'test': 'red'}, 'data_name': 'CIFAR10', 'num_classes': 10, 'train_set_path': './data/cifar-10', 'test_set_path': './data/cifar-10', 'augmentation': {'normalize': True, 'random_crop': True, 'random_horizontal_filp': True}, 'device': 'cuda', 'input_size': 32, 'batch_size': 128, 'num_epochs': 50, 'num_print': 100, 'num_workers': 4, 'eval_freq': 1, 'test_batch': 200, 'optimizer': {'name': 'SGD', 'params': {'lr': 0.02, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': True}}, 'lr_scheduler': {'type': 'STEP', 'lr_epochs': [40], 'lr_mults': 0.1}, 'learning_curve': {'style': 'ggplot', 'xtick_step': 5, 'draw_freq': 10, 'save_path': './plot/'}}
AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace)
    (10): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace)
  )
  (classifier): Sequential(
    (0): Linear(in_features=1152, out_features=32, bias=True)
    (1): ReLU(inplace)
    (2): Dropout(p=0.5)
    (3): Linear(in_features=32, out_features=32, bias=True)
    (4): ReLU(inplace)
    (5): Dropout(p=0.5)
    (6): Linear(in_features=32, out_features=10, bias=True)
  )
)
-------------------- Training parameters: 1432970 --------------------
[2020-03-03 08:38:09,144] - ========== epoch: [1/50] ==========
[2020-03-03 08:38:09,910] - step: [100/391], train_loss: 2.304 | train_acc: 10.445% | lr: 0.020000
[2020-03-03 08:38:10,427] - step: [200/391], train_loss: 2.299 | train_acc: 10.938% | lr: 0.020000
[2020-03-03 08:38:10,938] - step: [300/391], train_loss: 2.240 | train_acc: 12.862% | lr: 0.020000
[2020-03-03 08:38:11,422] - --- cost time: 2.2779s ---
[2020-03-03 08:38:11,422] - *************** test ***************
[2020-03-03 08:38:11,936] - test_loss: 1.938 | test_acc: 19.200%
[2020-03-03 08:38:11,936] - ************************************

[2020-03-03 08:38:11,958] - ========== epoch: [2/50] ==========
[2020-03-03 08:38:12,555] - step: [100/391], train_loss: 1.964 | train_acc: 20.008% | lr: 0.020000
[2020-03-03 08:38:13,073] - step: [200/391], train_loss: 1.953 | train_acc: 20.449% | lr: 0.020000
[2020-03-03 08:38:13,596] - step: [300/391], train_loss: 1.943 | train_acc: 20.633% | lr: 0.020000
[2020-03-03 08:38:14,082] - --- cost time: 2.1235s ---
[2020-03-03 08:38:14,082] - *************** test ***************
[2020-03-03 08:38:14,595] - test_loss: 1.914 | test_acc: 20.550%
[2020-03-03 08:38:14,595] - ************************************

[2020-03-03 08:38:14,616] - ========== epoch: [3/50] ==========
[2020-03-03 08:38:15,218] - step: [100/391], train_loss: 1.897 | train_acc: 21.781% | lr: 0.020000
[2020-03-03 08:38:15,740] - step: [200/391], train_loss: 1.895 | train_acc: 22.148% | lr: 0.020000
[2020-03-03 08:44:47,115] - {'architecture': 'alexnet', 'ckpt_path': './', 'ckpt_name': 'alexnet', 'log_path': './', 'log_name': 'cifar10', 'log_color': {'train': 'cyan', 'cost_time': 'yellow', 'test': 'red'}, 'data_name': 'CIFAR10', 'num_classes': 10, 'train_set_path': './data/cifar-10', 'test_set_path': './data/cifar-10', 'augmentation': {'normalize': True, 'random_crop': True, 'random_horizontal_filp': True}, 'device': 'cuda', 'input_size': 32, 'batch_size': 128, 'num_epochs': 50, 'num_print': 100, 'num_workers': 4, 'eval_freq': 1, 'test_batch': 200, 'optimizer': {'name': 'SGD', 'params': {'lr': 0.02, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': True}}, 'lr_scheduler': {'type': 'STEP', 'lr_epochs': [40], 'lr_mults': 0.1}, 'learning_curve': {'style': 'ggplot', 'xtick_step': 5, 'draw_freq': 10, 'save_path': './plot/'}}
AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace)
    (10): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace)
  )
  (classifier): Sequential(
    (0): Linear(in_features=1152, out_features=32, bias=True)
    (1): ReLU(inplace)
    (2): Dropout(p=0.5)
    (3): Linear(in_features=32, out_features=32, bias=True)
    (4): ReLU(inplace)
    (5): Dropout(p=0.5)
    (6): Linear(in_features=32, out_features=10, bias=True)
  )
)
-------------------- Training parameters: 1432970 --------------------
[2020-03-03 08:44:47,116] - ========== epoch: [1/50] ==========
[2020-03-03 08:44:47,894] - step: [100/391], train_loss: 2.305 | train_acc: 10.031% | lr: 0.020000
[2020-03-03 08:44:48,418] - step: [200/391], train_loss: 2.303 | train_acc: 10.297% | lr: 0.020000
[2020-03-03 08:44:48,945] - step: [300/391], train_loss: 2.299 | train_acc: 10.888% | lr: 0.020000
[2020-03-03 08:44:49,432] - --- cost time: 2.3165s ---
[2020-03-03 08:44:49,433] - *************** test ***************
[2020-03-03 08:44:49,946] - test_loss: 2.023 | test_acc: 17.830%
[2020-03-03 08:44:49,946] - ************************************

[2020-03-03 08:44:49,967] - ========== epoch: [2/50] ==========
[2020-03-03 08:44:50,564] - step: [100/391], train_loss: 2.044 | train_acc: 18.102% | lr: 0.020000
[2020-03-03 08:44:51,095] - step: [200/391], train_loss: 2.012 | train_acc: 18.680% | lr: 0.020000
[2020-03-03 08:44:51,612] - step: [300/391], train_loss: 1.990 | train_acc: 19.188% | lr: 0.020000
[2020-03-03 08:44:52,103] - --- cost time: 2.1353s ---
[2020-03-03 08:44:52,103] - *************** test ***************
[2020-03-03 08:44:52,613] - test_loss: 1.871 | test_acc: 21.950%
[2020-03-03 08:44:52,613] - ************************************

[2020-03-03 08:44:52,635] - ========== epoch: [3/50] ==========
[2020-03-03 08:44:53,231] - step: [100/391], train_loss: 1.902 | train_acc: 23.039% | lr: 0.020000
[2020-03-03 08:44:53,753] - step: [200/391], train_loss: 1.892 | train_acc: 23.465% | lr: 0.020000
[2020-03-03 08:44:54,274] - step: [300/391], train_loss: 1.873 | train_acc: 24.305% | lr: 0.020000
[2020-03-03 08:44:54,767] - --- cost time: 2.1320s ---
[2020-03-03 08:44:54,767] - *************** test ***************
[2020-03-03 08:44:55,275] - test_loss: 1.807 | test_acc: 28.530%
[2020-03-03 08:44:55,275] - ************************************

[2020-03-03 08:44:55,317] - ========== epoch: [4/50] ==========
[2020-03-03 08:44:55,924] - step: [100/391], train_loss: 1.808 | train_acc: 28.383% | lr: 0.020000
[2020-03-03 08:44:56,441] - step: [200/391], train_loss: 1.792 | train_acc: 29.004% | lr: 0.020000
[2020-03-03 08:44:56,953] - step: [300/391], train_loss: 1.783 | train_acc: 29.359% | lr: 0.020000
[2020-03-03 08:44:57,436] - --- cost time: 2.1186s ---
[2020-03-03 08:44:57,436] - *************** test ***************
[2020-03-03 08:44:57,952] - test_loss: 1.625 | test_acc: 34.270%
[2020-03-03 08:44:57,952] - ************************************

[2020-03-03 08:44:57,974] - ========== epoch: [5/50] ==========
[2020-03-03 08:44:58,569] - step: [100/391], train_loss: 1.710 | train_acc: 32.180% | lr: 0.020000
[2020-03-03 08:44:59,094] - step: [200/391], train_loss: 1.713 | train_acc: 32.602% | lr: 0.020000
[2020-03-03 08:44:59,618] - step: [300/391], train_loss: 1.705 | train_acc: 33.133% | lr: 0.020000
[2020-03-03 08:45:00,108] - --- cost time: 2.1344s ---
[2020-03-03 08:45:00,109] - *************** test ***************
[2020-03-03 08:45:00,619] - test_loss: 1.507 | test_acc: 39.290%
[2020-03-03 08:45:00,620] - ************************************

[2020-03-03 08:45:00,641] - ========== epoch: [6/50] ==========
[2020-03-03 08:45:01,240] - step: [100/391], train_loss: 1.619 | train_acc: 38.383% | lr: 0.020000
[2020-03-03 08:45:01,760] - step: [200/391], train_loss: 1.621 | train_acc: 38.043% | lr: 0.020000
[2020-03-03 08:45:02,275] - step: [300/391], train_loss: 1.615 | train_acc: 38.466% | lr: 0.020000
[2020-03-03 08:45:02,756] - --- cost time: 2.1147s ---
[2020-03-03 08:45:02,756] - *************** test ***************
[2020-03-03 08:45:03,288] - test_loss: 1.594 | test_acc: 41.880%
[2020-03-03 08:45:03,288] - ************************************

[2020-03-03 08:45:03,310] - ========== epoch: [7/50] ==========
[2020-03-03 08:45:03,903] - step: [100/391], train_loss: 1.557 | train_acc: 40.641% | lr: 0.020000
[2020-03-03 08:45:04,425] - step: [200/391], train_loss: 1.576 | train_acc: 39.582% | lr: 0.020000
[2020-03-03 08:45:04,946] - step: [300/391], train_loss: 1.571 | train_acc: 40.135% | lr: 0.020000
[2020-03-03 08:45:05,432] - --- cost time: 2.1220s ---
[2020-03-03 08:45:05,432] - *************** test ***************
[2020-03-03 08:45:05,940] - test_loss: 1.387 | test_acc: 47.770%
[2020-03-03 08:45:05,940] - ************************************

[2020-03-03 08:45:05,958] - ========== epoch: [8/50] ==========
[2020-03-03 08:45:06,558] - step: [100/391], train_loss: 1.477 | train_acc: 43.875% | lr: 0.020000
[2020-03-03 08:45:07,081] - step: [200/391], train_loss: 1.489 | train_acc: 43.875% | lr: 0.020000
[2020-03-03 08:45:07,603] - step: [300/391], train_loss: 1.492 | train_acc: 43.969% | lr: 0.020000
[2020-03-03 08:45:08,107] - --- cost time: 2.1484s ---
[2020-03-03 08:45:08,107] - *************** test ***************
[2020-03-03 08:45:08,607] - test_loss: 1.313 | test_acc: 49.750%
[2020-03-03 08:45:08,608] - ************************************

[2020-03-03 08:45:08,624] - ========== epoch: [9/50] ==========
[2020-03-03 08:45:09,219] - step: [100/391], train_loss: 1.467 | train_acc: 45.125% | lr: 0.020000
[2020-03-03 08:45:09,736] - step: [200/391], train_loss: 1.441 | train_acc: 46.395% | lr: 0.020000
[2020-03-03 08:45:10,253] - step: [300/391], train_loss: 1.428 | train_acc: 46.964% | lr: 0.020000
[2020-03-03 08:45:10,739] - --- cost time: 2.1144s ---
[2020-03-03 08:45:10,739] - *************** test ***************
[2020-03-03 08:45:11,263] - test_loss: 1.299 | test_acc: 51.990%
[2020-03-03 08:45:11,263] - ************************************

[2020-03-03 08:45:11,290] - ========== epoch: [10/50] ==========
[2020-03-03 08:45:11,916] - step: [100/391], train_loss: 1.393 | train_acc: 49.281% | lr: 0.020000
[2020-03-03 08:45:12,434] - step: [200/391], train_loss: 1.396 | train_acc: 49.387% | lr: 0.020000
[2020-03-03 08:45:12,947] - step: [300/391], train_loss: 1.394 | train_acc: 49.362% | lr: 0.020000
[2020-03-03 08:45:13,433] - --- cost time: 2.1417s ---
[2020-03-03 08:45:13,433] - *************** test ***************
[2020-03-03 08:45:13,943] - test_loss: 1.212 | test_acc: 54.930%
[2020-03-03 08:45:13,943] - ************************************

[2020-03-03 08:45:14,276] - ========== epoch: [11/50] ==========
[2020-03-03 08:45:14,929] - step: [100/391], train_loss: 1.351 | train_acc: 50.227% | lr: 0.020000
[2020-03-03 08:45:15,469] - step: [200/391], train_loss: 1.353 | train_acc: 50.813% | lr: 0.020000
[2020-03-03 08:45:15,997] - step: [300/391], train_loss: 1.353 | train_acc: 50.716% | lr: 0.020000
[2020-03-03 08:45:16,489] - --- cost time: 2.2123s ---
[2020-03-03 08:45:16,489] - *************** test ***************
[2020-03-03 08:45:17,010] - test_loss: 1.200 | test_acc: 57.050%
[2020-03-03 08:45:17,011] - ************************************

[2020-03-03 08:45:17,027] - ========== epoch: [12/50] ==========
[2020-03-03 08:45:17,629] - step: [100/391], train_loss: 1.320 | train_acc: 51.922% | lr: 0.020000
[2020-03-03 08:45:18,155] - step: [200/391], train_loss: 1.323 | train_acc: 52.172% | lr: 0.020000
[2020-03-03 08:45:18,679] - step: [300/391], train_loss: 1.319 | train_acc: 52.560% | lr: 0.020000
[2020-03-03 08:45:19,174] - --- cost time: 2.1467s ---
[2020-03-03 08:45:19,174] - *************** test ***************
[2020-03-03 08:45:19,683] - test_loss: 1.154 | test_acc: 59.960%
[2020-03-03 08:45:19,683] - ************************************

[2020-03-03 08:45:19,704] - ========== epoch: [13/50] ==========
[2020-03-03 08:45:20,308] - step: [100/391], train_loss: 1.271 | train_acc: 54.688% | lr: 0.020000
[2020-03-03 08:45:20,826] - step: [200/391], train_loss: 1.275 | train_acc: 54.793% | lr: 0.020000
[2020-03-03 08:45:21,345] - step: [300/391], train_loss: 1.269 | train_acc: 54.964% | lr: 0.020000
[2020-03-03 08:45:21,836] - --- cost time: 2.1309s ---
[2020-03-03 08:45:21,836] - *************** test ***************
[2020-03-03 08:45:22,354] - test_loss: 1.117 | test_acc: 60.340%
[2020-03-03 08:45:22,354] - ************************************

[2020-03-03 08:45:22,375] - ========== epoch: [14/50] ==========
[2020-03-03 08:45:22,973] - step: [100/391], train_loss: 1.248 | train_acc: 55.875% | lr: 0.020000
[2020-03-03 08:45:23,491] - step: [200/391], train_loss: 1.244 | train_acc: 56.176% | lr: 0.020000
[2020-03-03 08:45:24,014] - step: [300/391], train_loss: 1.249 | train_acc: 56.086% | lr: 0.020000
[2020-03-03 08:45:24,505] - --- cost time: 2.1292s ---
[2020-03-03 08:45:24,505] - *************** test ***************
[2020-03-03 08:45:25,018] - test_loss: 1.114 | test_acc: 62.100%
[2020-03-03 08:45:25,018] - ************************************

[2020-03-03 08:45:25,039] - ========== epoch: [15/50] ==========
[2020-03-03 08:45:25,641] - step: [100/391], train_loss: 1.218 | train_acc: 57.797% | lr: 0.020000
[2020-03-03 08:45:26,165] - step: [200/391], train_loss: 1.218 | train_acc: 58.000% | lr: 0.020000
[2020-03-03 08:45:26,691] - step: [300/391], train_loss: 1.220 | train_acc: 57.951% | lr: 0.020000
[2020-03-03 08:45:27,180] - --- cost time: 2.1406s ---
[2020-03-03 08:45:27,181] - *************** test ***************
[2020-03-03 08:45:27,700] - test_loss: 1.094 | test_acc: 63.720%
[2020-03-03 08:45:27,700] - ************************************

[2020-03-03 08:45:27,721] - ========== epoch: [16/50] ==========
[2020-03-03 08:45:51,846] - {'architecture': 'alexnet', 'ckpt_path': './', 'ckpt_name': 'alexnet', 'log_path': './', 'log_name': 'cifar10', 'log_color': {'train': 'cyan', 'cost_time': 'yellow', 'test': 'red'}, 'data_name': 'CIFAR10', 'num_classes': 10, 'train_set_path': './data/cifar-10', 'test_set_path': './data/cifar-10', 'augmentation': {'normalize': True, 'random_crop': True, 'random_horizontal_filp': True}, 'device': 'cuda', 'input_size': 32, 'batch_size': 128, 'num_epochs': 50, 'num_print': 100, 'num_workers': 4, 'eval_freq': 1, 'test_batch': 200, 'optimizer': {'name': 'SGD', 'params': {'lr': 0.02, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': True}}, 'lr_scheduler': {'type': 'STEP', 'lr_epochs': [40], 'lr_mults': 0.1}, 'learning_curve': {'style': 'ggplot', 'xtick_step': 5, 'draw_freq': 10, 'save_path': './'}}
AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace)
    (10): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace)
  )
  (classifier): Sequential(
    (0): Linear(in_features=1152, out_features=32, bias=True)
    (1): ReLU(inplace)
    (2): Dropout(p=0.5)
    (3): Linear(in_features=32, out_features=32, bias=True)
    (4): ReLU(inplace)
    (5): Dropout(p=0.5)
    (6): Linear(in_features=32, out_features=10, bias=True)
  )
)
-------------------- Training parameters: 1432970 --------------------
[2020-03-03 08:45:51,847] - ========== epoch: [1/50] ==========
[2020-03-03 08:45:52,633] - step: [100/391], train_loss: 2.304 | train_acc:  9.938% | lr: 0.020000
[2020-03-03 08:45:53,156] - step: [200/391], train_loss: 2.281 | train_acc: 11.902% | lr: 0.020000
[2020-03-03 08:45:53,681] - step: [300/391], train_loss: 2.217 | train_acc: 13.654% | lr: 0.020000
[2020-03-03 08:45:54,169] - --- cost time: 2.3221s ---
[2020-03-03 08:45:54,169] - *************** test ***************
[2020-03-03 08:45:54,686] - test_loss: 1.921 | test_acc: 21.810%
[2020-03-03 08:45:54,686] - ************************************

[2020-03-03 08:45:54,708] - ========== epoch: [2/50] ==========
[2020-03-03 08:45:55,307] - step: [100/391], train_loss: 1.978 | train_acc: 20.219% | lr: 0.020000
[2020-03-03 08:45:55,830] - step: [200/391], train_loss: 1.964 | train_acc: 20.449% | lr: 0.020000
[2020-03-03 08:45:56,347] - step: [300/391], train_loss: 1.952 | train_acc: 20.654% | lr: 0.020000
[2020-03-03 08:45:56,832] - --- cost time: 2.1229s ---
[2020-03-03 08:45:56,832] - *************** test ***************
[2020-03-03 08:45:57,357] - test_loss: 1.874 | test_acc: 22.170%
[2020-03-03 08:45:57,357] - ************************************

[2020-03-03 08:45:57,378] - ========== epoch: [3/50] ==========
[2020-03-03 08:45:57,977] - step: [100/391], train_loss: 1.905 | train_acc: 22.219% | lr: 0.020000
[2020-03-03 08:45:58,491] - step: [200/391], train_loss: 1.896 | train_acc: 23.000% | lr: 0.020000
[2020-03-03 08:45:59,012] - step: [300/391], train_loss: 1.887 | train_acc: 23.529% | lr: 0.020000
[2020-03-03 08:45:59,500] - --- cost time: 2.1214s ---
[2020-03-03 08:45:59,500] - *************** test ***************
[2020-03-03 08:46:00,017] - test_loss: 1.771 | test_acc: 31.200%
[2020-03-03 08:46:00,017] - ************************************

[2020-03-03 08:46:00,039] - ========== epoch: [4/50] ==========
[2020-03-03 08:46:00,641] - step: [100/391], train_loss: 1.803 | train_acc: 28.492% | lr: 0.020000
[2020-03-03 08:46:01,161] - step: [200/391], train_loss: 1.792 | train_acc: 28.770% | lr: 0.020000
[2020-03-03 08:46:01,679] - step: [300/391], train_loss: 1.782 | train_acc: 29.375% | lr: 0.020000
[2020-03-03 08:46:02,177] - --- cost time: 2.1386s ---
[2020-03-03 08:46:02,178] - *************** test ***************
[2020-03-03 08:46:02,734] - test_loss: 1.649 | test_acc: 36.090%
[2020-03-03 08:46:02,734] - ************************************

[2020-03-03 08:46:02,755] - ========== epoch: [5/50] ==========
[2020-03-03 08:46:03,351] - step: [100/391], train_loss: 1.705 | train_acc: 33.609% | lr: 0.020000
[2020-03-03 08:46:03,867] - step: [200/391], train_loss: 1.697 | train_acc: 34.000% | lr: 0.020000
[2020-03-03 08:46:04,386] - step: [300/391], train_loss: 1.683 | train_acc: 34.870% | lr: 0.020000
[2020-03-03 08:46:04,871] - --- cost time: 2.1153s ---
[2020-03-03 08:46:04,871] - *************** test ***************
[2020-03-03 08:46:05,384] - test_loss: 1.499 | test_acc: 43.740%
[2020-03-03 08:46:05,384] - ************************************

[2020-03-03 08:46:05,406] - ========== epoch: [6/50] ==========
[2020-03-03 08:46:06,001] - step: [100/391], train_loss: 1.598 | train_acc: 39.875% | lr: 0.020000
[2020-03-03 08:46:06,525] - step: [200/391], train_loss: 1.585 | train_acc: 40.180% | lr: 0.020000
[2020-03-03 08:46:07,048] - step: [300/391], train_loss: 1.577 | train_acc: 40.656% | lr: 0.020000
[2020-03-03 08:46:07,535] - --- cost time: 2.1289s ---
[2020-03-03 08:46:07,535] - *************** test ***************
[2020-03-03 08:46:08,048] - test_loss: 1.396 | test_acc: 47.050%
[2020-03-03 08:46:08,048] - ************************************

[2020-03-03 08:46:08,096] - ========== epoch: [7/50] ==========
[2020-03-03 08:46:08,701] - step: [100/391], train_loss: 1.502 | train_acc: 43.398% | lr: 0.020000
[2020-03-03 08:46:09,220] - step: [200/391], train_loss: 1.492 | train_acc: 44.023% | lr: 0.020000
[2020-03-03 08:46:09,736] - step: [300/391], train_loss: 1.489 | train_acc: 44.156% | lr: 0.020000
[2020-03-03 08:46:10,234] - --- cost time: 2.1375s ---
[2020-03-03 08:46:10,234] - *************** test ***************
[2020-03-03 08:46:10,781] - test_loss: 1.398 | test_acc: 47.510%
[2020-03-03 08:46:10,781] - ************************************

[2020-03-03 08:46:10,802] - ========== epoch: [8/50] ==========
[2020-03-03 08:46:11,400] - step: [100/391], train_loss: 1.445 | train_acc: 45.812% | lr: 0.020000
[2020-03-03 08:46:11,923] - step: [200/391], train_loss: 1.451 | train_acc: 45.730% | lr: 0.020000
[2020-03-03 08:46:12,447] - step: [300/391], train_loss: 1.445 | train_acc: 46.201% | lr: 0.020000
[2020-03-03 08:46:12,938] - --- cost time: 2.1358s ---
[2020-03-03 08:46:12,939] - *************** test ***************
[2020-03-03 08:46:13,459] - test_loss: 1.283 | test_acc: 52.810%
[2020-03-03 08:46:13,459] - ************************************

[2020-03-03 08:46:13,480] - ========== epoch: [9/50] ==========
[2020-03-03 08:46:14,075] - step: [100/391], train_loss: 1.435 | train_acc: 46.773% | lr: 0.020000
[2020-03-03 08:46:14,595] - step: [200/391], train_loss: 1.419 | train_acc: 47.602% | lr: 0.020000
[2020-03-03 08:46:15,116] - step: [300/391], train_loss: 1.406 | train_acc: 48.206% | lr: 0.020000
[2020-03-03 08:46:15,604] - --- cost time: 2.1233s ---
[2020-03-03 08:46:15,604] - *************** test ***************
[2020-03-03 08:46:16,112] - test_loss: 1.294 | test_acc: 52.540%
[2020-03-03 08:46:16,112] - ************************************

[2020-03-03 08:46:16,124] - ========== epoch: [10/50] ==========
[2020-03-03 08:46:16,719] - step: [100/391], train_loss: 1.360 | train_acc: 50.352% | lr: 0.020000
[2020-03-03 08:46:17,240] - step: [200/391], train_loss: 1.359 | train_acc: 50.602% | lr: 0.020000
[2020-03-03 08:46:17,752] - step: [300/391], train_loss: 1.357 | train_acc: 50.794% | lr: 0.020000
[2020-03-03 08:46:18,239] - --- cost time: 2.1152s ---
[2020-03-03 08:46:18,239] - *************** test ***************
[2020-03-03 08:46:18,756] - test_loss: 1.168 | test_acc: 56.830%
[2020-03-03 08:46:18,756] - ************************************

[2020-03-03 08:46:18,932] - ========== epoch: [11/50] ==========
[2020-03-03 08:46:19,539] - step: [100/391], train_loss: 1.303 | train_acc: 52.812% | lr: 0.020000
[2020-03-03 08:46:20,061] - step: [200/391], train_loss: 1.329 | train_acc: 52.266% | lr: 0.020000
[2020-03-03 08:46:20,583] - step: [300/391], train_loss: 1.325 | train_acc: 52.469% | lr: 0.020000
[2020-03-03 08:46:21,076] - --- cost time: 2.1436s ---
[2020-03-03 08:46:21,076] - *************** test ***************
[2020-03-03 08:46:21,595] - test_loss: 1.169 | test_acc: 58.840%
[2020-03-03 08:46:21,595] - ************************************

[2020-03-03 08:46:21,616] - ========== epoch: [12/50] ==========
[2020-03-03 08:46:22,218] - step: [100/391], train_loss: 1.292 | train_acc: 54.688% | lr: 0.020000
[2020-03-03 08:46:22,741] - step: [200/391], train_loss: 1.299 | train_acc: 54.660% | lr: 0.020000
[2020-03-03 08:46:23,266] - step: [300/391], train_loss: 1.290 | train_acc: 54.922% | lr: 0.020000
[2020-03-03 08:47:21,888] - {'architecture': 'alexnet', 'ckpt_path': './', 'ckpt_name': 'alexnet', 'log_path': './', 'log_name': 'cifar10', 'log_color': {'train': 'cyan', 'cost_time': 'yellow', 'test': 'red'}, 'data_name': 'CIFAR10', 'num_classes': 10, 'train_set_path': './data/cifar-10', 'test_set_path': './data/cifar-10', 'augmentation': {'normalize': True, 'random_crop': True, 'random_horizontal_filp': True}, 'device': 'cuda', 'input_size': 32, 'batch_size': 128, 'num_epochs': 50, 'num_print': 100, 'num_workers': 4, 'eval_freq': 1, 'test_batch': 200, 'optimizer': {'name': 'SGD', 'params': {'lr': 0.02, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': True}}, 'lr_scheduler': {'type': 'STEP', 'lr_epochs': [40], 'lr_mults': 0.1}, 'learning_curve': {'style': 'ggplot', 'xtick_step': 5, 'draw_freq': 10, 'save_path': './'}}
AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace)
    (10): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace)
  )
  (classifier): Sequential(
    (0): Linear(in_features=1152, out_features=32, bias=True)
    (1): ReLU(inplace)
    (2): Dropout(p=0.5)
    (3): Linear(in_features=32, out_features=32, bias=True)
    (4): ReLU(inplace)
    (5): Dropout(p=0.5)
    (6): Linear(in_features=32, out_features=10, bias=True)
  )
)
-------------------- Training parameters: 1432970 --------------------
[2020-03-03 08:47:21,888] - ========== epoch: [1/50] ==========
[2020-03-03 08:47:22,657] - step: [100/391], train_loss: 2.304 | train_acc: 10.547% | lr: 0.020000
[2020-03-03 08:47:23,182] - step: [200/391], train_loss: 2.276 | train_acc: 12.238% | lr: 0.020000
[2020-03-03 08:47:23,708] - step: [300/391], train_loss: 2.209 | train_acc: 13.945% | lr: 0.020000
[2020-03-03 08:47:24,199] - --- cost time: 2.3112s ---
[2020-03-03 08:47:24,200] - *************** test ***************
[2020-03-03 08:47:24,718] - test_loss: 1.919 | test_acc: 20.040%
[2020-03-03 08:47:24,718] - ************************************

[2020-03-03 08:47:24,739] - ========== epoch: [2/50] ==========
[2020-03-03 08:47:25,339] - step: [100/391], train_loss: 1.956 | train_acc: 19.156% | lr: 0.020000
[2020-03-03 08:47:25,864] - step: [200/391], train_loss: 1.950 | train_acc: 19.543% | lr: 0.020000
[2020-03-03 08:47:26,390] - step: [300/391], train_loss: 1.941 | train_acc: 19.935% | lr: 0.020000
[2020-03-03 08:47:26,884] - --- cost time: 2.1445s ---
[2020-03-03 08:47:26,884] - *************** test ***************
[2020-03-03 08:47:27,402] - test_loss: 1.868 | test_acc: 21.180%
[2020-03-03 08:47:27,402] - ************************************

[2020-03-03 08:47:27,419] - ========== epoch: [3/50] ==========
[2020-03-03 08:47:28,023] - step: [100/391], train_loss: 1.890 | train_acc: 22.836% | lr: 0.020000
[2020-03-03 08:47:28,549] - step: [200/391], train_loss: 1.888 | train_acc: 22.695% | lr: 0.020000
[2020-03-03 08:47:29,075] - step: [300/391], train_loss: 1.884 | train_acc: 22.964% | lr: 0.020000
[2020-03-03 08:47:29,573] - --- cost time: 2.1540s ---
[2020-03-03 08:47:29,573] - *************** test ***************
[2020-03-03 08:47:30,098] - test_loss: 1.814 | test_acc: 25.970%
[2020-03-03 08:47:30,098] - ************************************

[2020-03-03 08:47:30,119] - ========== epoch: [4/50] ==========
[2020-03-03 08:47:30,726] - step: [100/391], train_loss: 1.853 | train_acc: 24.055% | lr: 0.020000
[2020-03-03 08:47:31,248] - step: [200/391], train_loss: 1.848 | train_acc: 24.348% | lr: 0.020000
[2020-03-03 08:47:31,766] - step: [300/391], train_loss: 1.845 | train_acc: 24.583% | lr: 0.020000
[2020-03-03 08:47:32,254] - --- cost time: 2.1347s ---
[2020-03-03 08:47:32,255] - *************** test ***************
[2020-03-03 08:47:32,773] - test_loss: 1.721 | test_acc: 31.450%
[2020-03-03 08:47:32,773] - ************************************

[2020-03-03 08:47:32,794] - ========== epoch: [5/50] ==========
[2020-03-03 08:47:33,397] - step: [100/391], train_loss: 1.776 | train_acc: 28.680% | lr: 0.020000
[2020-03-03 08:47:33,922] - step: [200/391], train_loss: 1.766 | train_acc: 29.172% | lr: 0.020000
[2020-03-03 08:47:34,445] - step: [300/391], train_loss: 1.756 | train_acc: 29.539% | lr: 0.020000
[2020-03-03 08:47:34,961] - --- cost time: 2.1668s ---
[2020-03-03 08:47:34,961] - *************** test ***************
[2020-03-03 08:47:35,477] - test_loss: 1.600 | test_acc: 36.100%
[2020-03-03 08:47:35,477] - ************************************

[2020-03-03 08:47:35,498] - ========== epoch: [6/50] ==========
[2020-03-03 08:47:36,099] - step: [100/391], train_loss: 1.707 | train_acc: 32.516% | lr: 0.020000
[2020-03-03 08:47:36,620] - step: [200/391], train_loss: 1.691 | train_acc: 32.723% | lr: 0.020000
[2020-03-03 08:47:37,150] - step: [300/391], train_loss: 1.689 | train_acc: 33.117% | lr: 0.020000
[2020-03-03 08:47:37,644] - --- cost time: 2.1453s ---
[2020-03-03 08:47:37,644] - *************** test ***************
[2020-03-03 08:47:38,174] - test_loss: 1.554 | test_acc: 39.930%
[2020-03-03 08:47:38,174] - ************************************

[2020-03-03 08:47:38,221] - ========== epoch: [7/50] ==========
[2020-03-03 08:47:38,838] - step: [100/391], train_loss: 1.608 | train_acc: 37.508% | lr: 0.020000
[2020-03-03 08:47:39,356] - step: [200/391], train_loss: 1.602 | train_acc: 38.066% | lr: 0.020000
[2020-03-03 08:47:39,883] - step: [300/391], train_loss: 1.607 | train_acc: 38.089% | lr: 0.020000
[2020-03-03 08:47:40,372] - --- cost time: 2.1502s ---
[2020-03-03 08:47:40,372] - *************** test ***************
[2020-03-03 08:47:40,894] - test_loss: 1.455 | test_acc: 44.850%
[2020-03-03 08:47:40,894] - ************************************

[2020-03-03 08:47:40,911] - ========== epoch: [8/50] ==========
[2020-03-03 08:47:41,514] - step: [100/391], train_loss: 1.559 | train_acc: 41.203% | lr: 0.020000
[2020-03-03 08:47:42,043] - step: [200/391], train_loss: 1.550 | train_acc: 41.645% | lr: 0.020000
[2020-03-03 08:47:42,567] - step: [300/391], train_loss: 1.543 | train_acc: 42.307% | lr: 0.020000
[2020-03-03 08:47:43,056] - --- cost time: 2.1444s ---
[2020-03-03 08:47:43,056] - *************** test ***************
[2020-03-03 08:47:43,568] - test_loss: 1.433 | test_acc: 47.310%
[2020-03-03 08:47:43,569] - ************************************

[2020-03-03 08:47:43,590] - ========== epoch: [9/50] ==========
[2020-03-03 08:47:44,194] - step: [100/391], train_loss: 1.485 | train_acc: 45.281% | lr: 0.020000
[2020-03-03 08:47:44,720] - step: [200/391], train_loss: 1.474 | train_acc: 45.707% | lr: 0.020000
[2020-03-03 08:47:45,248] - step: [300/391], train_loss: 1.477 | train_acc: 45.802% | lr: 0.020000
[2020-03-03 08:47:45,741] - --- cost time: 2.1513s ---
[2020-03-03 08:47:45,742] - *************** test ***************
[2020-03-03 08:47:46,279] - test_loss: 1.279 | test_acc: 52.700%
[2020-03-03 08:47:46,279] - ************************************

[2020-03-03 08:47:46,300] - ========== epoch: [10/50] ==========
[2020-03-03 08:47:46,904] - step: [100/391], train_loss: 1.420 | train_acc: 47.391% | lr: 0.020000
[2020-03-03 08:47:47,440] - step: [200/391], train_loss: 1.411 | train_acc: 48.105% | lr: 0.020000
[2020-03-03 08:47:47,966] - step: [300/391], train_loss: 1.412 | train_acc: 48.190% | lr: 0.020000
[2020-03-03 08:48:20,167] - {'architecture': 'alexnet', 'ckpt_path': './', 'ckpt_name': 'alexnet', 'log_path': './', 'log_name': 'cifar10', 'log_color': {'train': 'blue', 'cost_time': 'yellow', 'test': 'red'}, 'data_name': 'CIFAR10', 'num_classes': 10, 'train_set_path': './data/cifar-10', 'test_set_path': './data/cifar-10', 'augmentation': {'normalize': True, 'random_crop': True, 'random_horizontal_filp': True}, 'device': 'cuda', 'input_size': 32, 'batch_size': 128, 'num_epochs': 50, 'num_print': 100, 'num_workers': 4, 'eval_freq': 1, 'test_batch': 200, 'optimizer': {'name': 'SGD', 'params': {'lr': 0.02, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': True}}, 'lr_scheduler': {'type': 'STEP', 'lr_epochs': [40], 'lr_mults': 0.1}, 'learning_curve': {'style': 'ggplot', 'xtick_step': 5, 'draw_freq': 10, 'save_path': './'}}
AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace)
    (10): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace)
  )
  (classifier): Sequential(
    (0): Linear(in_features=1152, out_features=32, bias=True)
    (1): ReLU(inplace)
    (2): Dropout(p=0.5)
    (3): Linear(in_features=32, out_features=32, bias=True)
    (4): ReLU(inplace)
    (5): Dropout(p=0.5)
    (6): Linear(in_features=32, out_features=10, bias=True)
  )
)
-------------------- Training parameters: 1432970 --------------------
[2020-03-03 08:48:20,167] - ========== epoch: [1/50] ==========
[2020-03-03 08:48:20,936] - step: [100/391], train_loss: 2.304 | train_acc:  9.812% | lr: 0.020000
[2020-03-03 08:48:21,449] - step: [200/391], train_loss: 2.303 | train_acc: 10.113% | lr: 0.020000
[2020-03-03 08:48:21,966] - step: [300/391], train_loss: 2.302 | train_acc: 10.695% | lr: 0.020000
[2020-03-03 08:48:22,448] - --- cost time: 2.2804s ---
[2020-03-03 08:48:22,448] - *************** test ***************
[2020-03-03 08:48:22,963] - test_loss: 2.082 | test_acc: 18.930%
[2020-03-03 08:48:22,963] - ************************************

[2020-03-03 08:48:22,985] - ========== epoch: [2/50] ==========
[2020-03-03 08:48:23,576] - step: [100/391], train_loss: 2.086 | train_acc: 17.578% | lr: 0.020000
[2020-03-03 08:48:24,094] - step: [200/391], train_loss: 2.048 | train_acc: 18.309% | lr: 0.020000
[2020-03-03 08:48:24,614] - step: [300/391], train_loss: 2.028 | train_acc: 18.596% | lr: 0.020000
[2020-03-03 08:48:25,097] - --- cost time: 2.1120s ---
[2020-03-03 08:48:25,097] - *************** test ***************
[2020-03-03 08:48:25,628] - test_loss: 1.909 | test_acc: 20.890%
[2020-03-03 08:48:25,629] - ************************************

[2020-03-03 08:48:25,656] - ========== epoch: [3/50] ==========
[2020-03-03 08:48:26,279] - step: [100/391], train_loss: 1.939 | train_acc: 20.055% | lr: 0.020000
[2020-03-03 08:48:26,793] - step: [200/391], train_loss: 1.934 | train_acc: 20.926% | lr: 0.020000
[2020-03-03 08:48:27,318] - step: [300/391], train_loss: 1.929 | train_acc: 21.268% | lr: 0.020000
[2020-03-03 08:48:27,802] - --- cost time: 2.1455s ---
[2020-03-03 08:48:27,803] - *************** test ***************
[2020-03-03 08:48:28,365] - test_loss: 1.859 | test_acc: 23.080%
[2020-03-03 08:48:28,366] - ************************************

[2020-03-03 08:48:28,387] - ========== epoch: [4/50] ==========
[2020-03-03 08:48:28,985] - step: [100/391], train_loss: 1.892 | train_acc: 23.164% | lr: 0.020000
[2020-03-03 08:48:29,506] - step: [200/391], train_loss: 1.877 | train_acc: 23.855% | lr: 0.020000
[2020-03-03 08:48:30,029] - step: [300/391], train_loss: 1.871 | train_acc: 24.195% | lr: 0.020000
[2020-03-03 08:48:30,518] - --- cost time: 2.1313s ---
[2020-03-03 08:48:30,518] - *************** test ***************
[2020-03-03 08:48:31,035] - test_loss: 1.753 | test_acc: 30.070%
[2020-03-03 08:48:31,035] - ************************************

[2020-03-03 08:48:31,056] - ========== epoch: [5/50] ==========
[2020-03-03 08:48:31,658] - step: [100/391], train_loss: 1.823 | train_acc: 27.453% | lr: 0.020000
[2020-03-03 08:48:32,179] - step: [200/391], train_loss: 1.805 | train_acc: 28.277% | lr: 0.020000
[2020-03-03 08:48:32,694] - step: [300/391], train_loss: 1.789 | train_acc: 29.331% | lr: 0.020000
[2020-03-03 08:48:33,196] - --- cost time: 2.1400s ---
[2020-03-03 08:48:33,197] - *************** test ***************
[2020-03-03 08:48:33,718] - test_loss: 1.767 | test_acc: 32.640%
[2020-03-03 08:48:33,718] - ************************************

[2020-03-03 08:48:33,740] - ========== epoch: [6/50] ==========
[2020-03-03 08:48:34,338] - step: [100/391], train_loss: 1.737 | train_acc: 31.828% | lr: 0.020000
[2020-03-03 08:48:34,860] - step: [200/391], train_loss: 1.720 | train_acc: 32.496% | lr: 0.020000
[2020-03-03 08:48:35,380] - step: [300/391], train_loss: 1.716 | train_acc: 32.807% | lr: 0.020000
[2020-03-03 08:48:35,877] - --- cost time: 2.1371s ---
[2020-03-03 08:48:35,877] - *************** test ***************
[2020-03-03 08:48:36,383] - test_loss: 1.570 | test_acc: 37.030%
[2020-03-03 08:48:36,383] - ************************************

[2020-03-03 08:48:36,404] - ========== epoch: [7/50] ==========
[2020-03-03 08:48:37,001] - step: [100/391], train_loss: 1.647 | train_acc: 35.117% | lr: 0.020000
[2020-03-03 08:48:37,522] - step: [200/391], train_loss: 1.653 | train_acc: 35.488% | lr: 0.020000
[2020-03-03 08:48:38,042] - step: [300/391], train_loss: 1.645 | train_acc: 36.542% | lr: 0.020000
[2020-03-03 08:48:38,531] - --- cost time: 2.1266s ---
[2020-03-03 08:48:38,531] - *************** test ***************
[2020-03-03 08:48:39,060] - test_loss: 1.483 | test_acc: 40.640%
[2020-03-03 08:48:39,060] - ************************************

[2020-03-03 08:48:39,081] - ========== epoch: [8/50] ==========
[2020-03-03 08:48:39,681] - step: [100/391], train_loss: 1.612 | train_acc: 37.750% | lr: 0.020000
[2020-03-03 08:48:40,199] - step: [200/391], train_loss: 1.595 | train_acc: 39.078% | lr: 0.020000
[2020-03-03 08:48:40,719] - step: [300/391], train_loss: 1.580 | train_acc: 39.940% | lr: 0.020000
[2020-03-03 08:48:41,206] - --- cost time: 2.1246s ---
[2020-03-03 08:48:41,206] - *************** test ***************
[2020-03-03 08:48:41,716] - test_loss: 1.486 | test_acc: 45.590%
[2020-03-03 08:48:41,716] - ************************************

[2020-03-03 08:48:41,737] - ========== epoch: [9/50] ==========
[2020-03-03 08:48:42,339] - step: [100/391], train_loss: 1.532 | train_acc: 43.594% | lr: 0.020000
[2020-03-03 08:48:42,859] - step: [200/391], train_loss: 1.521 | train_acc: 44.062% | lr: 0.020000
[2020-03-03 08:48:43,381] - step: [300/391], train_loss: 1.513 | train_acc: 44.276% | lr: 0.020000
[2020-03-03 08:48:43,876] - --- cost time: 2.1392s ---
[2020-03-03 08:48:43,877] - *************** test ***************
[2020-03-03 08:48:44,394] - test_loss: 1.303 | test_acc: 49.590%
[2020-03-03 08:48:44,394] - ************************************

[2020-03-03 08:48:44,417] - ========== epoch: [10/50] ==========
[2020-03-03 08:48:45,015] - step: [100/391], train_loss: 1.445 | train_acc: 46.805% | lr: 0.020000
[2020-03-03 08:48:45,539] - step: [200/391], train_loss: 1.449 | train_acc: 46.824% | lr: 0.020000
[2020-03-03 08:48:46,056] - step: [300/391], train_loss: 1.445 | train_acc: 46.992% | lr: 0.020000
[2020-03-03 08:48:46,551] - --- cost time: 2.1336s ---
[2020-03-03 08:48:46,551] - *************** test ***************
[2020-03-03 08:48:47,073] - test_loss: 1.329 | test_acc: 50.850%
[2020-03-03 08:48:47,074] - ************************************

[2020-03-03 08:48:47,239] - ========== epoch: [11/50] ==========
[2020-03-03 08:48:47,841] - step: [100/391], train_loss: 1.407 | train_acc: 48.461% | lr: 0.020000
[2020-03-03 08:48:48,363] - step: [200/391], train_loss: 1.391 | train_acc: 49.328% | lr: 0.020000
[2020-03-03 08:48:48,882] - step: [300/391], train_loss: 1.387 | train_acc: 49.510% | lr: 0.020000
[2020-03-03 08:48:49,368] - --- cost time: 2.1294s ---
[2020-03-03 08:48:49,369] - *************** test ***************
[2020-03-03 08:48:49,888] - test_loss: 1.227 | test_acc: 55.520%
[2020-03-03 08:48:49,888] - ************************************

[2020-03-03 08:48:49,910] - ========== epoch: [12/50] ==========
[2020-03-03 08:48:50,507] - step: [100/391], train_loss: 1.333 | train_acc: 50.875% | lr: 0.020000
[2020-03-03 08:48:51,025] - step: [200/391], train_loss: 1.339 | train_acc: 50.980% | lr: 0.020000
[2020-03-03 08:48:51,542] - step: [300/391], train_loss: 1.336 | train_acc: 51.573% | lr: 0.020000
[2020-03-03 08:48:52,035] - --- cost time: 2.1250s ---
[2020-03-03 08:48:52,035] - *************** test ***************
[2020-03-03 08:48:52,569] - test_loss: 1.192 | test_acc: 57.330%
[2020-03-03 08:48:52,569] - ************************************

[2020-03-03 08:48:52,590] - ========== epoch: [13/50] ==========
[2020-03-03 08:48:53,190] - step: [100/391], train_loss: 1.314 | train_acc: 53.328% | lr: 0.020000
[2020-03-03 08:48:53,712] - step: [200/391], train_loss: 1.306 | train_acc: 54.238% | lr: 0.020000
[2020-03-03 08:48:54,236] - step: [300/391], train_loss: 1.300 | train_acc: 54.435% | lr: 0.020000
[2020-03-03 08:48:54,737] - --- cost time: 2.1467s ---
[2020-03-03 08:48:54,737] - *************** test ***************
[2020-03-03 08:48:55,292] - test_loss: 1.158 | test_acc: 59.600%
[2020-03-03 08:48:55,292] - ************************************

[2020-03-03 08:48:55,313] - ========== epoch: [14/50] ==========
[2020-03-03 08:48:55,933] - step: [100/391], train_loss: 1.271 | train_acc: 56.023% | lr: 0.020000
[2020-03-03 08:48:56,440] - step: [200/391], train_loss: 1.267 | train_acc: 56.219% | lr: 0.020000
[2020-03-03 08:48:56,961] - step: [300/391], train_loss: 1.260 | train_acc: 56.596% | lr: 0.020000
[2020-03-03 08:48:57,451] - --- cost time: 2.1374s ---
[2020-03-03 08:48:57,451] - *************** test ***************
[2020-03-03 08:48:57,966] - test_loss: 1.095 | test_acc: 62.760%
[2020-03-03 08:48:57,966] - ************************************

[2020-03-03 08:48:57,988] - ========== epoch: [15/50] ==========
[2020-03-03 08:48:58,587] - step: [100/391], train_loss: 1.227 | train_acc: 58.312% | lr: 0.020000
[2020-03-03 08:48:59,103] - step: [200/391], train_loss: 1.219 | train_acc: 58.578% | lr: 0.020000
[2020-03-03 08:48:59,620] - step: [300/391], train_loss: 1.222 | train_acc: 58.503% | lr: 0.020000
[2020-03-03 08:49:00,111] - --- cost time: 2.1233s ---
[2020-03-03 08:49:00,112] - *************** test ***************
[2020-03-03 08:49:00,641] - test_loss: 1.162 | test_acc: 62.270%
[2020-03-03 08:49:00,641] - ************************************

[2020-03-03 08:49:00,654] - ========== epoch: [16/50] ==========
[2020-03-03 08:49:01,255] - step: [100/391], train_loss: 1.221 | train_acc: 59.156% | lr: 0.020000
[2020-03-03 08:49:01,774] - step: [200/391], train_loss: 1.210 | train_acc: 59.633% | lr: 0.020000
[2020-03-03 08:49:02,288] - step: [300/391], train_loss: 1.203 | train_acc: 59.930% | lr: 0.020000
[2020-03-03 08:49:02,772] - --- cost time: 2.1184s ---
[2020-03-03 08:49:02,773] - *************** test ***************
[2020-03-03 08:49:03,300] - test_loss: 1.056 | test_acc: 65.550%
[2020-03-03 08:49:03,300] - ************************************

[2020-03-03 08:49:03,321] - ========== epoch: [17/50] ==========
[2020-03-03 08:49:03,921] - step: [100/391], train_loss: 1.190 | train_acc: 60.391% | lr: 0.020000
[2020-03-03 08:49:04,439] - step: [200/391], train_loss: 1.185 | train_acc: 60.371% | lr: 0.020000
[2020-03-03 08:49:04,960] - step: [300/391], train_loss: 1.182 | train_acc: 60.503% | lr: 0.020000
[2020-03-03 08:49:05,453] - --- cost time: 2.1317s ---
[2020-03-03 08:49:05,453] - *************** test ***************
[2020-03-03 08:49:05,976] - test_loss: 1.003 | test_acc: 66.110%
[2020-03-03 08:49:05,976] - ************************************

[2020-03-03 08:49:05,997] - ========== epoch: [18/50] ==========
[2020-03-03 08:49:06,593] - step: [100/391], train_loss: 1.170 | train_acc: 61.547% | lr: 0.020000
[2020-03-03 08:49:07,115] - step: [200/391], train_loss: 1.165 | train_acc: 61.820% | lr: 0.020000
[2020-03-03 08:49:07,638] - step: [300/391], train_loss: 1.168 | train_acc: 61.760% | lr: 0.020000
[2020-03-03 08:49:08,128] - --- cost time: 2.1310s ---
[2020-03-03 08:49:08,129] - *************** test ***************
[2020-03-03 08:49:08,648] - test_loss: 0.991 | test_acc: 67.450%
[2020-03-03 08:49:08,648] - ************************************

[2020-03-03 08:49:08,669] - ========== epoch: [19/50] ==========
[2020-03-03 08:49:09,268] - step: [100/391], train_loss: 1.122 | train_acc: 63.188% | lr: 0.020000
[2020-03-03 08:49:09,786] - step: [200/391], train_loss: 1.128 | train_acc: 62.945% | lr: 0.020000
[2020-03-03 08:49:10,305] - step: [300/391], train_loss: 1.126 | train_acc: 63.026% | lr: 0.020000
[2020-03-03 08:49:10,795] - --- cost time: 2.1251s ---
[2020-03-03 08:49:10,795] - *************** test ***************
[2020-03-03 08:49:11,327] - test_loss: 1.034 | test_acc: 65.420%
[2020-03-03 08:49:11,327] - ************************************

[2020-03-03 08:49:11,339] - ========== epoch: [20/50] ==========
[2020-03-03 08:49:11,938] - step: [100/391], train_loss: 1.135 | train_acc: 63.078% | lr: 0.020000
[2020-03-03 08:49:12,462] - step: [200/391], train_loss: 1.126 | train_acc: 63.348% | lr: 0.020000
[2020-03-03 08:49:12,986] - step: [300/391], train_loss: 1.121 | train_acc: 63.487% | lr: 0.020000
[2020-03-03 08:49:13,472] - --- cost time: 2.1320s ---
[2020-03-03 08:49:13,472] - *************** test ***************
[2020-03-03 08:49:13,992] - test_loss: 0.985 | test_acc: 68.910%
[2020-03-03 08:49:13,993] - ************************************

[2020-03-03 08:49:14,150] - ========== epoch: [21/50] ==========
[2020-03-03 08:49:14,766] - step: [100/391], train_loss: 1.090 | train_acc: 64.805% | lr: 0.020000
[2020-03-03 08:49:15,289] - step: [200/391], train_loss: 1.092 | train_acc: 64.617% | lr: 0.020000
[2020-03-03 08:49:15,810] - step: [300/391], train_loss: 1.102 | train_acc: 64.359% | lr: 0.020000
[2020-03-03 08:49:16,296] - --- cost time: 2.1456s ---
[2020-03-03 08:49:16,296] - *************** test ***************
[2020-03-03 08:49:16,813] - test_loss: 0.944 | test_acc: 69.260%
[2020-03-03 08:49:16,813] - ************************************

[2020-03-03 08:49:16,834] - ========== epoch: [22/50] ==========
[2020-03-03 08:49:17,435] - step: [100/391], train_loss: 1.102 | train_acc: 64.500% | lr: 0.020000
[2020-03-03 08:49:17,955] - step: [200/391], train_loss: 1.096 | train_acc: 64.766% | lr: 0.020000
[2020-03-03 08:49:18,472] - step: [300/391], train_loss: 1.097 | train_acc: 64.690% | lr: 0.020000
[2020-03-03 08:49:18,960] - --- cost time: 2.1254s ---
[2020-03-03 08:49:18,960] - *************** test ***************
[2020-03-03 08:49:19,507] - test_loss: 0.961 | test_acc: 68.020%
[2020-03-03 08:49:19,507] - ************************************

[2020-03-03 08:49:19,519] - ========== epoch: [23/50] ==========
[2020-03-03 08:49:20,122] - step: [100/391], train_loss: 1.065 | train_acc: 65.367% | lr: 0.020000
[2020-03-03 08:49:20,647] - step: [200/391], train_loss: 1.060 | train_acc: 65.824% | lr: 0.020000
[2020-03-03 08:49:21,163] - step: [300/391], train_loss: 1.068 | train_acc: 65.523% | lr: 0.020000
[2020-03-03 08:49:21,651] - --- cost time: 2.1309s ---
[2020-03-03 08:49:21,651] - *************** test ***************
[2020-03-03 08:49:22,169] - test_loss: 0.949 | test_acc: 69.240%
[2020-03-03 08:49:22,169] - ************************************

[2020-03-03 08:49:22,181] - ========== epoch: [24/50] ==========
[2020-03-03 08:49:22,783] - step: [100/391], train_loss: 1.058 | train_acc: 65.734% | lr: 0.020000
[2020-03-03 08:49:23,305] - step: [200/391], train_loss: 1.068 | train_acc: 65.535% | lr: 0.020000
[2020-03-03 08:49:23,818] - step: [300/391], train_loss: 1.066 | train_acc: 65.609% | lr: 0.020000
[2020-03-03 08:49:24,300] - --- cost time: 2.1195s ---
[2020-03-03 08:49:24,301] - *************** test ***************
[2020-03-03 08:49:24,814] - test_loss: 0.943 | test_acc: 69.110%
[2020-03-03 08:49:24,814] - ************************************

[2020-03-03 08:49:24,826] - ========== epoch: [25/50] ==========
[2020-03-03 08:49:25,427] - step: [100/391], train_loss: 1.040 | train_acc: 66.672% | lr: 0.020000
[2020-03-03 08:49:25,949] - step: [200/391], train_loss: 1.049 | train_acc: 66.113% | lr: 0.020000
[2020-03-03 08:49:26,467] - step: [300/391], train_loss: 1.057 | train_acc: 65.984% | lr: 0.020000
[2020-03-03 08:49:26,955] - --- cost time: 2.1292s ---
[2020-03-03 08:49:26,955] - *************** test ***************
[2020-03-03 08:49:27,477] - test_loss: 0.891 | test_acc: 70.750%
[2020-03-03 08:49:27,477] - ************************************

[2020-03-03 08:49:27,494] - ========== epoch: [26/50] ==========
[2020-03-03 08:49:28,103] - step: [100/391], train_loss: 1.064 | train_acc: 65.172% | lr: 0.020000
[2020-03-03 08:49:28,621] - step: [200/391], train_loss: 1.057 | train_acc: 65.840% | lr: 0.020000
[2020-03-03 08:49:29,143] - step: [300/391], train_loss: 1.056 | train_acc: 66.292% | lr: 0.020000
[2020-03-03 08:49:29,634] - --- cost time: 2.1405s ---
[2020-03-03 08:49:29,635] - *************** test ***************
[2020-03-03 08:49:30,156] - test_loss: 0.866 | test_acc: 71.690%
[2020-03-03 08:49:30,156] - ************************************

[2020-03-03 08:49:30,178] - ========== epoch: [27/50] ==========
[2020-03-03 08:49:30,805] - step: [100/391], train_loss: 1.009 | train_acc: 67.617% | lr: 0.020000
[2020-03-03 08:49:31,329] - step: [200/391], train_loss: 1.016 | train_acc: 67.340% | lr: 0.020000
[2020-03-03 08:49:31,845] - step: [300/391], train_loss: 1.019 | train_acc: 67.128% | lr: 0.020000
[2020-03-03 08:49:32,341] - --- cost time: 2.1632s ---
[2020-03-03 08:49:32,341] - *************** test ***************
[2020-03-03 08:49:32,886] - test_loss: 0.888 | test_acc: 71.620%
[2020-03-03 08:49:32,886] - ************************************

[2020-03-03 08:49:32,896] - ========== epoch: [28/50] ==========
[2020-03-03 08:49:33,503] - step: [100/391], train_loss: 1.029 | train_acc: 66.828% | lr: 0.020000
[2020-03-03 08:49:34,025] - step: [200/391], train_loss: 1.018 | train_acc: 67.367% | lr: 0.020000
[2020-03-03 08:49:34,543] - step: [300/391], train_loss: 1.011 | train_acc: 67.677% | lr: 0.020000
[2020-03-03 08:49:35,034] - --- cost time: 2.1372s ---
[2020-03-03 08:49:35,034] - *************** test ***************
[2020-03-03 08:49:35,551] - test_loss: 0.886 | test_acc: 71.160%
[2020-03-03 08:49:35,552] - ************************************

[2020-03-03 08:49:35,563] - ========== epoch: [29/50] ==========
[2020-03-03 08:49:36,159] - step: [100/391], train_loss: 1.000 | train_acc: 67.945% | lr: 0.020000
[2020-03-03 08:49:36,679] - step: [200/391], train_loss: 1.007 | train_acc: 67.727% | lr: 0.020000
[2020-03-03 08:49:37,195] - step: [300/391], train_loss: 1.007 | train_acc: 67.698% | lr: 0.020000
[2020-03-03 08:49:37,684] - --- cost time: 2.1208s ---
[2020-03-03 08:49:37,685] - *************** test ***************
[2020-03-03 08:49:38,213] - test_loss: 0.921 | test_acc: 69.520%
[2020-03-03 08:49:38,213] - ************************************

[2020-03-03 08:49:38,231] - ========== epoch: [30/50] ==========
[2020-03-03 08:49:38,839] - step: [100/391], train_loss: 1.013 | train_acc: 68.492% | lr: 0.020000
[2020-03-03 08:49:39,359] - step: [200/391], train_loss: 1.005 | train_acc: 68.539% | lr: 0.020000
[2020-03-03 08:49:39,896] - step: [300/391], train_loss: 1.008 | train_acc: 68.294% | lr: 0.020000
[2020-03-03 08:49:40,381] - --- cost time: 2.1497s ---
[2020-03-03 08:49:40,381] - *************** test ***************
[2020-03-03 08:49:40,903] - test_loss: 0.845 | test_acc: 72.190%
[2020-03-03 08:49:40,903] - ************************************

[2020-03-03 08:49:41,063] - ========== epoch: [31/50] ==========
[2020-03-03 08:49:41,677] - step: [100/391], train_loss: 1.003 | train_acc: 67.953% | lr: 0.020000
[2020-03-03 08:49:42,197] - step: [200/391], train_loss: 0.995 | train_acc: 68.086% | lr: 0.020000
[2020-03-03 08:49:42,729] - step: [300/391], train_loss: 1.000 | train_acc: 67.768% | lr: 0.020000
[2020-03-03 08:49:43,224] - --- cost time: 2.1613s ---
[2020-03-03 08:49:43,225] - *************** test ***************
[2020-03-03 08:49:43,754] - test_loss: 0.873 | test_acc: 71.630%
[2020-03-03 08:49:43,754] - ************************************

[2020-03-03 08:49:43,766] - ========== epoch: [32/50] ==========
[2020-03-03 08:49:44,367] - step: [100/391], train_loss: 0.981 | train_acc: 69.000% | lr: 0.020000
[2020-03-03 08:49:44,888] - step: [200/391], train_loss: 0.972 | train_acc: 69.188% | lr: 0.020000
[2020-03-03 08:49:45,410] - step: [300/391], train_loss: 0.982 | train_acc: 68.917% | lr: 0.020000
[2020-03-03 08:49:45,897] - --- cost time: 2.1313s ---
[2020-03-03 08:49:45,898] - *************** test ***************
[2020-03-03 08:49:46,421] - test_loss: 0.886 | test_acc: 70.880%
[2020-03-03 08:49:46,421] - ************************************

[2020-03-03 08:49:46,433] - ========== epoch: [33/50] ==========
[2020-03-03 08:49:47,033] - step: [100/391], train_loss: 0.967 | train_acc: 69.773% | lr: 0.020000
[2020-03-03 08:49:47,553] - step: [200/391], train_loss: 0.974 | train_acc: 69.336% | lr: 0.020000
[2020-03-03 08:49:48,072] - step: [300/391], train_loss: 0.973 | train_acc: 69.474% | lr: 0.020000
[2020-03-03 08:49:48,571] - --- cost time: 2.1380s ---
[2020-03-03 08:49:48,571] - *************** test ***************
[2020-03-03 08:49:49,092] - test_loss: 0.850 | test_acc: 72.780%
[2020-03-03 08:49:49,092] - ************************************

[2020-03-03 08:49:49,114] - ========== epoch: [34/50] ==========
[2020-03-03 08:49:49,715] - step: [100/391], train_loss: 0.983 | train_acc: 69.320% | lr: 0.020000
[2020-03-03 08:49:50,239] - step: [200/391], train_loss: 0.984 | train_acc: 69.281% | lr: 0.020000
[2020-03-03 08:49:50,764] - step: [300/391], train_loss: 0.984 | train_acc: 69.253% | lr: 0.020000
[2020-03-03 08:49:51,254] - --- cost time: 2.1401s ---
[2020-03-03 08:49:51,254] - *************** test ***************
[2020-03-03 08:49:51,777] - test_loss: 0.865 | test_acc: 71.110%
[2020-03-03 08:49:51,777] - ************************************

[2020-03-03 08:51:09,466] - {'architecture': 'alexnet', 'ckpt_path': './', 'ckpt_name': 'alexnet', 'log_path': './', 'log_name': 'cifar10', 'log_color': {'train': 'blue', 'cost_time': 'yellow', 'time': 'cyan', 'test': 'red'}, 'data_name': 'CIFAR10', 'num_classes': 10, 'train_set_path': './data/cifar-10', 'test_set_path': './data/cifar-10', 'augmentation': {'normalize': True, 'random_crop': True, 'random_horizontal_filp': True}, 'device': 'cuda', 'input_size': 32, 'batch_size': 128, 'num_epochs': 50, 'num_print': 100, 'num_workers': 4, 'eval_freq': 1, 'test_batch': 200, 'optimizer': {'name': 'SGD', 'params': {'lr': 0.02, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': True}}, 'lr_scheduler': {'type': 'STEP', 'lr_epochs': [40], 'lr_mults': 0.1}, 'learning_curve': {'style': 'ggplot', 'xtick_step': 5, 'draw_freq': 10, 'save_path': './'}}
AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace)
    (10): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace)
  )
  (classifier): Sequential(
    (0): Linear(in_features=1152, out_features=32, bias=True)
    (1): ReLU(inplace)
    (2): Dropout(p=0.5)
    (3): Linear(in_features=32, out_features=32, bias=True)
    (4): ReLU(inplace)
    (5): Dropout(p=0.5)
    (6): Linear(in_features=32, out_features=10, bias=True)
  )
)
-------------------- Training parameters: 1432970 --------------------
[2020-03-03 08:51:09,467] - ========== epoch: [1/50] ==========
[2020-03-03 08:51:10,242] - step: [100/391], train_loss: 2.305 | train_acc: 10.141% | lr: 0.020000
[2020-03-03 08:51:10,767] - step: [200/391], train_loss: 2.304 | train_acc: 10.449% | lr: 0.020000
[2020-03-03 08:51:11,287] - step: [300/391], train_loss: 2.294 | train_acc: 11.844% | lr: 0.020000
[2020-03-03 08:51:11,766] - --- cost time: 2.2991s ---
[2020-03-03 08:51:11,766] - *************** test ***************
[2020-03-03 08:51:12,285] - test_loss: 1.992 | test_acc: 18.240%
[2020-03-03 08:51:12,285] - ************************************

[2020-03-03 08:51:12,307] - ========== epoch: [2/50] ==========
[2020-03-03 08:51:12,910] - step: [100/391], train_loss: 2.016 | train_acc: 18.367% | lr: 0.020000
[2020-03-03 08:51:13,427] - step: [200/391], train_loss: 1.995 | train_acc: 18.691% | lr: 0.020000
[2020-03-03 08:51:13,947] - step: [300/391], train_loss: 1.982 | train_acc: 19.255% | lr: 0.020000
[2020-03-03 08:51:14,460] - --- cost time: 2.1529s ---
[2020-03-03 08:51:14,461] - *************** test ***************
[2020-03-03 08:51:14,982] - test_loss: 1.918 | test_acc: 19.840%
[2020-03-03 08:51:14,983] - ************************************

[2020-03-03 08:51:15,004] - ========== epoch: [3/50] ==========
[2020-03-03 08:51:15,606] - step: [100/391], train_loss: 1.924 | train_acc: 20.492% | lr: 0.020000
[2020-03-03 08:51:16,128] - step: [200/391], train_loss: 1.914 | train_acc: 20.766% | lr: 0.020000
[2020-03-03 08:51:16,652] - step: [300/391], train_loss: 1.905 | train_acc: 21.518% | lr: 0.020000
[2020-03-03 08:51:17,144] - --- cost time: 2.1397s ---
[2020-03-03 08:51:17,144] - *************** test ***************
[2020-03-03 08:51:17,671] - test_loss: 1.773 | test_acc: 29.120%
[2020-03-03 08:51:17,672] - ************************************

[2020-03-03 08:51:17,693] - ========== epoch: [4/50] ==========
[2020-03-03 08:51:18,301] - step: [100/391], train_loss: 1.826 | train_acc: 26.961% | lr: 0.020000
[2020-03-03 08:51:18,821] - step: [200/391], train_loss: 1.811 | train_acc: 27.910% | lr: 0.020000
[2020-03-03 08:51:19,351] - step: [300/391], train_loss: 1.809 | train_acc: 28.120% | lr: 0.020000
[2020-03-03 08:51:19,838] - --- cost time: 2.1446s ---
[2020-03-03 08:51:19,838] - *************** test ***************
[2020-03-03 08:52:06,878] - {'architecture': 'alexnet', 'ckpt_path': './', 'ckpt_name': 'alexnet', 'log_path': './', 'log_name': 'cifar10', 'log_color': {'train': 'blue', 'cost_time': 'yellow', 'time': 'green', 'test': 'red'}, 'data_name': 'CIFAR10', 'num_classes': 10, 'train_set_path': './data/cifar-10', 'test_set_path': './data/cifar-10', 'augmentation': {'normalize': True, 'random_crop': True, 'random_horizontal_filp': True}, 'device': 'cuda', 'input_size': 32, 'batch_size': 128, 'num_epochs': 50, 'num_print': 100, 'num_workers': 4, 'eval_freq': 1, 'test_batch': 200, 'optimizer': {'name': 'SGD', 'params': {'lr': 0.02, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': True}}, 'lr_scheduler': {'type': 'STEP', 'lr_epochs': [40], 'lr_mults': 0.1}, 'learning_curve': {'style': 'ggplot', 'xtick_step': 5, 'draw_freq': 10, 'save_path': './'}}
AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace)
    (10): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace)
  )
  (classifier): Sequential(
    (0): Linear(in_features=1152, out_features=32, bias=True)
    (1): ReLU(inplace)
    (2): Dropout(p=0.5)
    (3): Linear(in_features=32, out_features=32, bias=True)
    (4): ReLU(inplace)
    (5): Dropout(p=0.5)
    (6): Linear(in_features=32, out_features=10, bias=True)
  )
)
-------------------- Training parameters: 1432970 --------------------
[2020-03-03 08:52:06,878] - ========== epoch: [1/50] ==========
[2020-03-03 08:52:07,658] - step: [100/391], train_loss: 2.304 | train_acc: 10.195% | lr: 0.020000
[2020-03-03 08:52:08,183] - step: [200/391], train_loss: 2.288 | train_acc: 11.812% | lr: 0.020000
[2020-03-03 08:52:08,707] - step: [300/391], train_loss: 2.229 | train_acc: 13.602% | lr: 0.020000
[2020-03-03 08:52:09,202] - --- cost time: 2.3237s ---
[2020-03-03 08:52:09,202] - *************** test ***************
[2020-03-03 08:52:09,722] - test_loss: 1.929 | test_acc: 21.090%
[2020-03-03 08:52:09,722] - ************************************

[2020-03-03 08:52:09,744] - ========== epoch: [2/50] ==========
[2020-03-03 08:52:10,347] - step: [100/391], train_loss: 1.967 | train_acc: 20.617% | lr: 0.020000
[2020-03-03 08:52:10,867] - step: [200/391], train_loss: 1.955 | train_acc: 20.809% | lr: 0.020000
[2020-03-03 08:52:11,384] - step: [300/391], train_loss: 1.947 | train_acc: 21.294% | lr: 0.020000
[2020-03-03 08:52:11,872] - --- cost time: 2.1280s ---
[2020-03-03 08:52:11,873] - *************** test ***************
[2020-03-03 08:52:12,399] - test_loss: 1.841 | test_acc: 25.930%
[2020-03-03 08:52:12,399] - ************************************

[2020-03-03 08:52:12,416] - ========== epoch: [3/50] ==========
[2020-03-03 08:52:13,015] - step: [100/391], train_loss: 1.893 | train_acc: 23.383% | lr: 0.020000
[2020-03-03 08:52:13,536] - step: [200/391], train_loss: 1.881 | train_acc: 23.824% | lr: 0.020000
[2020-03-03 08:52:14,057] - step: [300/391], train_loss: 1.872 | train_acc: 24.531% | lr: 0.020000
[2020-03-03 08:52:14,542] - --- cost time: 2.1255s ---
[2020-03-03 08:52:14,542] - *************** test ***************
[2020-03-03 08:52:15,062] - test_loss: 1.813 | test_acc: 28.290%
[2020-03-03 08:52:15,062] - ************************************

[2020-03-03 08:52:15,079] - ========== epoch: [4/50] ==========
[2020-03-03 08:52:15,681] - step: [100/391], train_loss: 1.802 | train_acc: 29.094% | lr: 0.020000
[2020-03-03 08:52:16,201] - step: [200/391], train_loss: 1.799 | train_acc: 28.957% | lr: 0.020000
[2020-03-03 08:52:16,723] - step: [300/391], train_loss: 1.785 | train_acc: 29.698% | lr: 0.020000
[2020-03-03 08:52:17,213] - --- cost time: 2.1342s ---
[2020-03-03 08:52:17,214] - *************** test ***************
[2020-03-03 08:52:17,735] - test_loss: 1.598 | test_acc: 37.730%
[2020-03-03 08:52:17,735] - ************************************

[2020-03-03 08:52:17,762] - ========== epoch: [5/50] ==========
[2020-03-03 08:52:18,368] - step: [100/391], train_loss: 1.700 | train_acc: 33.547% | lr: 0.020000
[2020-03-03 08:52:18,891] - step: [200/391], train_loss: 1.699 | train_acc: 33.828% | lr: 0.020000
[2020-03-03 08:52:19,416] - step: [300/391], train_loss: 1.694 | train_acc: 34.380% | lr: 0.020000
[2020-03-03 08:52:19,910] - --- cost time: 2.1484s ---
[2020-03-03 08:52:19,910] - *************** test ***************
[2020-03-03 08:52:20,428] - test_loss: 1.513 | test_acc: 40.610%
[2020-03-03 08:52:20,428] - ************************************

[2020-03-03 08:52:20,449] - ========== epoch: [6/50] ==========
[2020-03-03 08:52:21,054] - step: [100/391], train_loss: 1.639 | train_acc: 36.375% | lr: 0.020000
[2020-03-03 08:52:21,573] - step: [200/391], train_loss: 1.632 | train_acc: 37.379% | lr: 0.020000
[2020-03-03 08:52:22,095] - step: [300/391], train_loss: 1.621 | train_acc: 38.214% | lr: 0.020000
[2020-03-03 08:52:22,581] - --- cost time: 2.1317s ---
[2020-03-03 08:52:22,581] - *************** test ***************
[2020-03-03 08:52:23,102] - test_loss: 1.442 | test_acc: 45.950%
[2020-03-03 08:52:23,103] - ************************************

[2020-03-03 08:52:23,119] - ========== epoch: [7/50] ==========
[2020-03-03 08:52:23,720] - step: [100/391], train_loss: 1.546 | train_acc: 42.086% | lr: 0.020000
[2020-03-03 08:52:24,240] - step: [200/391], train_loss: 1.540 | train_acc: 42.324% | lr: 0.020000
[2020-03-03 08:52:24,758] - step: [300/391], train_loss: 1.530 | train_acc: 42.688% | lr: 0.020000
[2020-03-03 08:52:25,248] - --- cost time: 2.1286s ---
[2020-03-03 08:52:25,249] - *************** test ***************
[2020-03-03 08:52:25,766] - test_loss: 1.341 | test_acc: 49.990%
[2020-03-03 08:52:25,766] - ************************************

[2020-03-03 08:52:25,787] - ========== epoch: [8/50] ==========
[2020-03-03 08:52:26,388] - step: [100/391], train_loss: 1.468 | train_acc: 45.805% | lr: 0.020000
[2020-03-03 08:52:26,907] - step: [200/391], train_loss: 1.475 | train_acc: 45.328% | lr: 0.020000
[2020-03-03 08:52:27,434] - step: [300/391], train_loss: 1.473 | train_acc: 45.474% | lr: 0.020000
[2020-03-03 08:52:27,924] - --- cost time: 2.1370s ---
[2020-03-03 08:52:27,925] - *************** test ***************
[2020-03-03 08:52:28,438] - test_loss: 1.271 | test_acc: 52.310%
[2020-03-03 08:52:28,438] - ************************************

[2020-03-03 08:52:28,459] - ========== epoch: [9/50] ==========
[2020-03-03 08:52:29,064] - step: [100/391], train_loss: 1.433 | train_acc: 47.086% | lr: 0.020000
[2020-03-03 08:52:29,586] - step: [200/391], train_loss: 1.421 | train_acc: 47.699% | lr: 0.020000
[2020-03-03 08:52:30,110] - step: [300/391], train_loss: 1.418 | train_acc: 48.062% | lr: 0.020000
[2020-03-03 08:52:30,608] - --- cost time: 2.1485s ---
[2020-03-03 08:52:30,608] - *************** test ***************
[2020-03-03 08:52:31,131] - test_loss: 1.262 | test_acc: 54.050%
[2020-03-03 08:52:31,131] - ************************************

[2020-03-03 08:52:31,152] - ========== epoch: [10/50] ==========
[2020-03-03 08:52:31,760] - step: [100/391], train_loss: 1.390 | train_acc: 49.430% | lr: 0.020000
[2020-03-03 08:52:32,282] - step: [200/391], train_loss: 1.372 | train_acc: 50.434% | lr: 0.020000
[2020-03-03 08:52:32,801] - step: [300/391], train_loss: 1.367 | train_acc: 50.828% | lr: 0.020000
[2020-03-03 08:52:33,291] - --- cost time: 2.1379s ---
[2020-03-03 08:52:33,291] - *************** test ***************
[2020-03-03 08:52:33,824] - test_loss: 1.242 | test_acc: 54.240%
[2020-03-03 08:52:33,824] - ************************************

[2020-03-03 08:52:33,983] - ========== epoch: [11/50] ==========
[2020-03-03 08:52:34,591] - step: [100/391], train_loss: 1.331 | train_acc: 52.125% | lr: 0.020000
[2020-03-03 08:52:35,113] - step: [200/391], train_loss: 1.333 | train_acc: 52.555% | lr: 0.020000
[2020-03-03 08:52:35,635] - step: [300/391], train_loss: 1.326 | train_acc: 53.081% | lr: 0.020000
[2020-03-03 08:52:36,126] - --- cost time: 2.1423s ---
[2020-03-03 08:52:36,126] - *************** test ***************
[2020-03-03 08:52:36,645] - test_loss: 1.207 | test_acc: 58.340%
[2020-03-03 08:52:36,645] - ************************************

[2020-03-03 08:52:36,666] - ========== epoch: [12/50] ==========
[2020-03-03 08:52:37,269] - step: [100/391], train_loss: 1.318 | train_acc: 53.141% | lr: 0.020000
[2020-03-03 08:52:37,784] - step: [200/391], train_loss: 1.316 | train_acc: 53.641% | lr: 0.020000
[2020-03-03 08:52:38,301] - step: [300/391], train_loss: 1.309 | train_acc: 54.091% | lr: 0.020000
[2020-03-03 08:52:38,792] - --- cost time: 2.1260s ---
[2020-03-03 08:52:38,792] - *************** test ***************
[2020-03-03 08:52:39,312] - test_loss: 1.113 | test_acc: 61.700%
[2020-03-03 08:52:39,312] - ************************************

[2020-03-03 08:52:39,333] - ========== epoch: [13/50] ==========
[2020-03-03 08:52:39,934] - step: [100/391], train_loss: 1.256 | train_acc: 56.477% | lr: 0.020000
[2020-03-03 08:52:40,456] - step: [200/391], train_loss: 1.261 | train_acc: 56.535% | lr: 0.020000
[2020-03-03 08:52:40,975] - step: [300/391], train_loss: 1.250 | train_acc: 57.102% | lr: 0.020000
[2020-03-03 08:52:41,462] - --- cost time: 2.1290s ---
[2020-03-03 08:52:41,462] - *************** test ***************
[2020-03-03 08:52:41,998] - test_loss: 1.153 | test_acc: 61.420%
[2020-03-03 08:52:41,998] - ************************************

[2020-03-03 08:52:42,011] - ========== epoch: [14/50] ==========
[2020-03-03 08:53:16,202] - {'architecture': 'alexnet', 'ckpt_path': './', 'ckpt_name': 'alexnet', 'log_path': './', 'log_name': 'cifar10', 'log_color': {'train': 'blue', 'cost_time': 'yellow', 'time': 'purple', 'test': 'red'}, 'data_name': 'CIFAR10', 'num_classes': 10, 'train_set_path': './data/cifar-10', 'test_set_path': './data/cifar-10', 'augmentation': {'normalize': True, 'random_crop': True, 'random_horizontal_filp': True}, 'device': 'cuda', 'input_size': 32, 'batch_size': 128, 'num_epochs': 50, 'num_print': 100, 'num_workers': 4, 'eval_freq': 1, 'test_batch': 200, 'optimizer': {'name': 'SGD', 'params': {'lr': 0.02, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': True}}, 'lr_scheduler': {'type': 'STEP', 'lr_epochs': [40], 'lr_mults': 0.1}, 'learning_curve': {'style': 'ggplot', 'xtick_step': 5, 'draw_freq': 10, 'save_path': './'}}
AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace)
    (10): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace)
  )
  (classifier): Sequential(
    (0): Linear(in_features=1152, out_features=32, bias=True)
    (1): ReLU(inplace)
    (2): Dropout(p=0.5)
    (3): Linear(in_features=32, out_features=32, bias=True)
    (4): ReLU(inplace)
    (5): Dropout(p=0.5)
    (6): Linear(in_features=32, out_features=10, bias=True)
  )
)
-------------------- Training parameters: 1432970 --------------------
[2020-03-03 08:53:16,203] - ========== epoch: [1/50] ==========
[2020-03-03 08:53:16,984] - step: [100/391], train_loss: 2.304 | train_acc: 10.570% | lr: 0.020000
[2020-03-03 08:53:17,500] - step: [200/391], train_loss: 2.302 | train_acc: 11.273% | lr: 0.020000
[2020-03-03 08:53:18,018] - step: [300/391], train_loss: 2.264 | train_acc: 13.013% | lr: 0.020000
[2020-03-03 08:53:18,516] - --- cost time: 2.3133s ---
[2020-03-03 08:53:18,517] - *************** test ***************
[2020-03-03 08:53:19,031] - test_loss: 1.942 | test_acc: 18.800%
[2020-03-03 08:53:19,031] - ************************************

[2020-03-03 08:53:19,048] - ========== epoch: [2/50] ==========
[2020-03-03 08:53:19,648] - step: [100/391], train_loss: 1.988 | train_acc: 19.266% | lr: 0.020000
[2020-03-03 08:53:20,162] - step: [200/391], train_loss: 1.977 | train_acc: 19.695% | lr: 0.020000
[2020-03-03 08:53:20,684] - step: [300/391], train_loss: 1.962 | train_acc: 19.995% | lr: 0.020000
[2020-03-03 08:53:21,173] - --- cost time: 2.1244s ---
[2020-03-03 08:53:21,173] - *************** test ***************
[2020-03-03 08:53:21,691] - test_loss: 1.882 | test_acc: 20.780%
[2020-03-03 08:53:21,691] - ************************************

[2020-03-03 08:53:21,712] - ========== epoch: [3/50] ==========
[2020-03-03 08:53:22,309] - step: [100/391], train_loss: 1.918 | train_acc: 21.484% | lr: 0.020000
[2020-03-03 08:53:22,827] - step: [200/391], train_loss: 1.906 | train_acc: 22.148% | lr: 0.020000
[2020-03-03 08:53:23,344] - step: [300/391], train_loss: 1.897 | train_acc: 22.372% | lr: 0.020000
[2020-03-03 08:53:23,830] - --- cost time: 2.1172s ---
[2020-03-03 08:53:23,830] - *************** test ***************
[2020-03-03 08:53:24,337] - test_loss: 1.852 | test_acc: 24.170%
[2020-03-03 08:53:24,337] - ************************************

[2020-03-03 08:53:24,369] - ========== epoch: [4/50] ==========
[2020-03-03 08:53:24,968] - step: [100/391], train_loss: 1.872 | train_acc: 24.148% | lr: 0.020000
[2020-03-03 08:53:25,489] - step: [200/391], train_loss: 1.860 | train_acc: 24.199% | lr: 0.020000
[2020-03-03 08:53:26,008] - step: [300/391], train_loss: 1.841 | train_acc: 25.206% | lr: 0.020000
[2020-03-03 08:53:26,508] - --- cost time: 2.1381s ---
[2020-03-03 08:53:26,508] - *************** test ***************
[2020-03-03 08:53:27,021] - test_loss: 1.694 | test_acc: 32.680%
[2020-03-03 08:53:27,021] - ************************************

[2020-03-03 08:53:27,043] - ========== epoch: [5/50] ==========
[2020-03-03 08:53:27,641] - step: [100/391], train_loss: 1.773 | train_acc: 29.523% | lr: 0.020000
[2020-03-03 08:53:28,155] - step: [200/391], train_loss: 1.757 | train_acc: 30.340% | lr: 0.020000
[2020-03-03 08:53:28,670] - step: [300/391], train_loss: 1.748 | train_acc: 30.919% | lr: 0.020000
[2020-03-03 08:53:29,170] - --- cost time: 2.1270s ---
[2020-03-03 08:53:29,170] - *************** test ***************
[2020-03-03 08:53:29,695] - test_loss: 1.594 | test_acc: 39.280%
[2020-03-03 08:53:29,695] - ************************************

[2020-03-03 08:53:29,716] - ========== epoch: [6/50] ==========
[2020-03-03 08:53:30,315] - step: [100/391], train_loss: 1.694 | train_acc: 34.070% | lr: 0.020000
[2020-03-03 08:53:30,841] - step: [200/391], train_loss: 1.691 | train_acc: 34.523% | lr: 0.020000
[2020-03-03 08:53:31,356] - step: [300/391], train_loss: 1.669 | train_acc: 35.615% | lr: 0.020000
[2020-03-03 08:53:31,839] - --- cost time: 2.1230s ---
[2020-03-03 08:53:31,840] - *************** test ***************
[2020-03-03 08:53:32,360] - test_loss: 1.501 | test_acc: 44.190%
[2020-03-03 08:53:32,360] - ************************************

[2020-03-03 08:53:32,381] - ========== epoch: [7/50] ==========
[2020-03-03 08:53:32,975] - step: [100/391], train_loss: 1.608 | train_acc: 39.008% | lr: 0.020000
[2020-03-03 08:53:33,496] - step: [200/391], train_loss: 1.605 | train_acc: 39.539% | lr: 0.020000
[2020-03-03 08:53:34,015] - step: [300/391], train_loss: 1.594 | train_acc: 39.917% | lr: 0.020000
[2020-03-03 08:53:34,502] - --- cost time: 2.1210s ---
[2020-03-03 08:53:34,502] - *************** test ***************
[2020-03-03 08:53:35,029] - test_loss: 1.412 | test_acc: 48.320%
[2020-03-03 08:53:35,029] - ************************************

[2020-03-03 08:53:35,051] - ========== epoch: [8/50] ==========
[2020-03-03 08:53:35,649] - step: [100/391], train_loss: 1.532 | train_acc: 43.516% | lr: 0.020000
[2020-03-03 08:53:36,175] - step: [200/391], train_loss: 1.535 | train_acc: 42.824% | lr: 0.020000
[2020-03-03 08:53:36,694] - step: [300/391], train_loss: 1.530 | train_acc: 42.833% | lr: 0.020000
[2020-03-03 08:53:37,181] - --- cost time: 2.1298s ---
[2020-03-03 08:53:37,181] - *************** test ***************
[2020-03-03 08:53:37,691] - test_loss: 1.325 | test_acc: 52.020%
[2020-03-03 08:53:37,691] - ************************************

[2020-03-03 08:53:37,712] - ========== epoch: [9/50] ==========
[2020-03-03 08:53:38,307] - step: [100/391], train_loss: 1.478 | train_acc: 45.281% | lr: 0.020000
[2020-03-03 08:53:38,825] - step: [200/391], train_loss: 1.479 | train_acc: 45.406% | lr: 0.020000
[2020-03-03 08:53:39,343] - step: [300/391], train_loss: 1.470 | train_acc: 45.755% | lr: 0.020000
[2020-03-03 08:53:39,834] - --- cost time: 2.1214s ---
[2020-03-03 08:53:39,834] - *************** test ***************
[2020-03-03 08:53:40,352] - test_loss: 1.368 | test_acc: 46.840%
[2020-03-03 08:53:40,352] - ************************************

[2020-03-03 08:53:40,365] - ========== epoch: [10/50] ==========
[2020-03-03 08:53:40,962] - step: [100/391], train_loss: 1.422 | train_acc: 47.914% | lr: 0.020000
[2020-03-03 08:53:41,479] - step: [200/391], train_loss: 1.418 | train_acc: 47.789% | lr: 0.020000
[2020-03-03 08:53:41,998] - step: [300/391], train_loss: 1.416 | train_acc: 48.188% | lr: 0.020000
[2020-03-03 08:53:42,491] - --- cost time: 2.1255s ---
[2020-03-03 08:53:42,491] - *************** test ***************
[2020-03-03 08:53:43,010] - test_loss: 1.215 | test_acc: 55.020%
[2020-03-03 08:53:43,010] - ************************************

[2020-03-03 08:53:43,171] - ========== epoch: [11/50] ==========
[2020-03-03 08:53:43,779] - step: [100/391], train_loss: 1.380 | train_acc: 50.078% | lr: 0.020000
[2020-03-03 08:53:44,302] - step: [200/391], train_loss: 1.374 | train_acc: 50.395% | lr: 0.020000
[2020-03-03 08:53:44,816] - step: [300/391], train_loss: 1.361 | train_acc: 50.859% | lr: 0.020000
[2020-03-03 08:53:45,306] - --- cost time: 2.1344s ---
[2020-03-03 08:53:45,306] - *************** test ***************
[2020-03-03 08:53:45,824] - test_loss: 1.222 | test_acc: 54.860%
[2020-03-03 08:53:45,824] - ************************************

[2020-03-03 08:53:45,836] - ========== epoch: [12/50] ==========
[2020-03-03 08:53:46,442] - step: [100/391], train_loss: 1.338 | train_acc: 51.414% | lr: 0.020000
[2020-03-03 08:53:46,961] - step: [200/391], train_loss: 1.337 | train_acc: 51.598% | lr: 0.020000
[2020-03-03 08:53:47,485] - step: [300/391], train_loss: 1.327 | train_acc: 52.125% | lr: 0.020000
[2020-03-03 08:53:47,975] - --- cost time: 2.1385s ---
[2020-03-03 08:53:47,975] - *************** test ***************
[2020-03-03 08:53:48,491] - test_loss: 1.173 | test_acc: 59.230%
[2020-03-03 08:53:48,491] - ************************************

[2020-03-03 08:53:48,513] - ========== epoch: [13/50] ==========
[2020-03-03 08:54:48,398] - {'architecture': 'alexnet', 'ckpt_path': './', 'ckpt_name': 'alexnet', 'log_path': './', 'log_name': 'cifar10', 'log_color': {'train': 'blue', 'cost_time': 'yellow', 'time': 'purple', 'test': 'red'}, 'data_name': 'CIFAR10', 'num_classes': 10, 'train_set_path': './data/cifar-10', 'test_set_path': './data/cifar-10', 'augmentation': {'normalize': True, 'random_crop': True, 'random_horizontal_filp': True}, 'device': 'cuda', 'input_size': 32, 'batch_size': 128, 'num_epochs': 50, 'num_print': 100, 'num_workers': 4, 'eval_freq': 1, 'test_batch': 200, 'optimizer': {'name': 'SGD', 'params': {'lr': 0.02, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': True}}, 'lr_scheduler': {'type': 'STEP', 'lr_epochs': [40], 'lr_mults': 0.1}, 'learning_curve': {'style': 'ggplot', 'xtick_step': 5, 'draw_freq': 10, 'save_path': './'}}
AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace)
    (10): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace)
  )
  (classifier): Sequential(
    (0): Linear(in_features=1152, out_features=32, bias=True)
    (1): ReLU(inplace)
    (2): Dropout(p=0.5)
    (3): Linear(in_features=32, out_features=32, bias=True)
    (4): ReLU(inplace)
    (5): Dropout(p=0.5)
    (6): Linear(in_features=32, out_features=10, bias=True)
  )
)
-------------------- Training parameters: 1432970 --------------------
[2020-03-03 08:54:48,399] - ========== epoch: [1/50] ==========
[2020-03-03 08:54:49,250] - step: [100/391], train_loss: 2.305 | train_acc:  9.602% | lr: 0.020000
[2020-03-03 08:54:49,770] - step: [200/391], train_loss: 2.296 | train_acc: 10.969% | lr: 0.020000
[2020-03-03 08:54:50,295] - step: [300/391], train_loss: 2.241 | train_acc: 13.044% | lr: 0.020000
[2020-03-03 08:54:50,781] - --- cost time: 2.3821s ---
[2020-03-03 08:54:50,781] - *************** test ***************
[2020-03-03 08:54:51,295] - test_loss: 1.951 | test_acc: 20.440%
[2020-03-03 08:54:51,295] - ************************************

[2020-03-03 08:54:51,318] - ========== epoch: [2/50] ==========
[2020-03-03 08:54:51,916] - step: [100/391], train_loss: 1.986 | train_acc: 19.594% | lr: 0.020000
[2020-03-03 08:54:52,431] - step: [200/391], train_loss: 1.968 | train_acc: 20.000% | lr: 0.020000
[2020-03-03 08:54:52,948] - step: [300/391], train_loss: 1.955 | train_acc: 20.474% | lr: 0.020000
[2020-03-03 08:54:53,435] - --- cost time: 2.1168s ---
[2020-03-03 08:54:53,435] - *************** test ***************
[2020-03-03 08:54:53,952] - test_loss: 1.872 | test_acc: 25.650%
[2020-03-03 08:54:53,953] - ************************************

[2020-03-03 08:54:53,974] - ========== epoch: [3/50] ==========
[2020-03-03 08:54:54,569] - step: [100/391], train_loss: 1.899 | train_acc: 23.828% | lr: 0.020000
[2020-03-03 08:54:55,085] - step: [200/391], train_loss: 1.893 | train_acc: 23.637% | lr: 0.020000
[2020-03-03 08:54:55,602] - step: [300/391], train_loss: 1.885 | train_acc: 23.633% | lr: 0.020000
[2020-03-03 08:54:56,086] - --- cost time: 2.1118s ---
[2020-03-03 08:54:56,086] - *************** test ***************
[2020-03-03 08:54:56,594] - test_loss: 1.823 | test_acc: 26.940%
[2020-03-03 08:54:56,594] - ************************************

[2020-03-03 08:54:56,622] - ========== epoch: [4/50] ==========
[2020-03-03 08:54:57,222] - step: [100/391], train_loss: 1.873 | train_acc: 24.016% | lr: 0.020000
[2020-03-03 08:54:57,746] - step: [200/391], train_loss: 1.855 | train_acc: 24.844% | lr: 0.020000
[2020-03-03 08:54:58,271] - step: [300/391], train_loss: 1.848 | train_acc: 25.245% | lr: 0.020000
[2020-03-03 08:54:58,770] - --- cost time: 2.1485s ---
[2020-03-03 08:54:58,771] - *************** test ***************
[2020-03-03 08:54:59,284] - test_loss: 1.790 | test_acc: 28.770%
[2020-03-03 08:54:59,284] - ************************************

[2020-03-03 08:54:59,304] - ========== epoch: [5/50] ==========
[2020-03-03 08:54:59,898] - step: [100/391], train_loss: 1.803 | train_acc: 27.172% | lr: 0.020000
[2020-03-03 08:55:00,413] - step: [200/391], train_loss: 1.800 | train_acc: 27.805% | lr: 0.020000
[2020-03-03 08:55:00,922] - step: [300/391], train_loss: 1.797 | train_acc: 28.203% | lr: 0.020000
[2020-03-03 08:55:01,420] - --- cost time: 2.1159s ---
[2020-03-03 08:55:01,420] - *************** test ***************
[2020-03-03 08:55:01,933] - test_loss: 1.590 | test_acc: 38.720%
[2020-03-03 08:55:01,933] - ************************************

[2020-03-03 08:55:01,951] - ========== epoch: [6/50] ==========
[2020-03-03 08:55:02,542] - step: [100/391], train_loss: 1.692 | train_acc: 34.789% | lr: 0.020000
[2020-03-03 08:55:03,060] - step: [200/391], train_loss: 1.687 | train_acc: 35.000% | lr: 0.020000
[2020-03-03 08:55:03,577] - step: [300/391], train_loss: 1.668 | train_acc: 35.823% | lr: 0.020000
[2020-03-03 08:55:04,059] - --- cost time: 2.1080s ---
[2020-03-03 08:55:04,060] - *************** test ***************
[2020-03-03 08:55:04,569] - test_loss: 1.579 | test_acc: 39.470%
[2020-03-03 08:55:04,569] - ************************************

[2020-03-03 08:55:04,588] - ========== epoch: [7/50] ==========
[2020-03-03 08:55:05,185] - step: [100/391], train_loss: 1.571 | train_acc: 40.109% | lr: 0.020000
[2020-03-03 08:55:05,702] - step: [200/391], train_loss: 1.579 | train_acc: 39.848% | lr: 0.020000
[2020-03-03 08:55:06,210] - step: [300/391], train_loss: 1.571 | train_acc: 40.367% | lr: 0.020000
[2020-03-03 08:55:06,692] - --- cost time: 2.1036s ---
[2020-03-03 08:55:06,692] - *************** test ***************
[2020-03-03 08:55:07,205] - test_loss: 1.392 | test_acc: 47.720%
[2020-03-03 08:55:07,205] - ************************************

[2020-03-03 08:55:07,222] - ========== epoch: [8/50] ==========
[2020-03-03 08:55:07,816] - step: [100/391], train_loss: 1.516 | train_acc: 42.219% | lr: 0.020000
[2020-03-03 08:55:08,328] - step: [200/391], train_loss: 1.516 | train_acc: 42.848% | lr: 0.020000
[2020-03-03 08:55:08,846] - step: [300/391], train_loss: 1.501 | train_acc: 43.281% | lr: 0.020000
[2020-03-03 08:55:09,330] - --- cost time: 2.1077s ---
[2020-03-03 08:55:09,330] - *************** test ***************
[2020-03-03 08:55:09,844] - test_loss: 1.304 | test_acc: 50.690%
[2020-03-03 08:55:09,844] - ************************************

[2020-03-03 08:55:09,866] - ========== epoch: [9/50] ==========
[2020-03-03 08:55:10,460] - step: [100/391], train_loss: 1.451 | train_acc: 45.961% | lr: 0.020000
[2020-03-03 08:55:10,978] - step: [200/391], train_loss: 1.447 | train_acc: 45.996% | lr: 0.020000
[2020-03-03 08:55:11,498] - step: [300/391], train_loss: 1.440 | train_acc: 46.289% | lr: 0.020000
[2020-03-03 08:55:11,983] - --- cost time: 2.1174s ---
[2020-03-03 08:55:11,984] - *************** test ***************
[2020-03-03 08:55:12,498] - test_loss: 1.254 | test_acc: 54.150%
[2020-03-03 08:55:12,499] - ************************************

[2020-03-03 08:55:12,520] - ========== epoch: [10/50] ==========
[2020-03-03 08:55:13,117] - step: [100/391], train_loss: 1.412 | train_acc: 47.578% | lr: 0.020000
[2020-03-03 08:55:13,629] - step: [200/391], train_loss: 1.409 | train_acc: 47.777% | lr: 0.020000
[2020-03-03 08:55:14,144] - step: [300/391], train_loss: 1.396 | train_acc: 48.255% | lr: 0.020000
[2020-03-03 08:55:14,640] - --- cost time: 2.1196s ---
[2020-03-03 08:55:14,640] - *************** test ***************
[2020-03-03 08:55:15,155] - test_loss: 1.237 | test_acc: 55.500%
[2020-03-03 08:55:15,155] - ************************************

[2020-03-03 08:55:26,525] - ========== epoch: [11/50] ==========
[2020-03-03 08:55:27,156] - step: [100/391], train_loss: 1.345 | train_acc: 50.758% | lr: 0.020000
[2020-03-03 08:55:27,681] - step: [200/391], train_loss: 1.338 | train_acc: 51.066% | lr: 0.020000
[2020-03-03 08:55:28,201] - step: [300/391], train_loss: 1.339 | train_acc: 51.227% | lr: 0.020000
[2020-03-03 08:55:28,705] - --- cost time: 2.1795s ---
[2020-03-03 08:55:28,706] - *************** test ***************
[2020-03-03 08:55:29,223] - test_loss: 1.233 | test_acc: 56.890%
[2020-03-03 08:55:29,223] - ************************************

[2020-03-03 08:55:29,245] - ========== epoch: [12/50] ==========
[2020-03-03 08:55:29,851] - step: [100/391], train_loss: 1.320 | train_acc: 52.891% | lr: 0.020000
[2020-03-03 08:55:30,374] - step: [200/391], train_loss: 1.293 | train_acc: 54.277% | lr: 0.020000
[2020-03-03 08:55:30,898] - step: [300/391], train_loss: 1.295 | train_acc: 54.398% | lr: 0.020000
[2020-03-03 08:55:31,390] - --- cost time: 2.1454s ---
[2020-03-03 08:55:31,391] - *************** test ***************
[2020-03-03 08:55:31,912] - test_loss: 1.199 | test_acc: 59.270%
[2020-03-03 08:55:31,912] - ************************************

[2020-03-03 08:55:31,933] - ========== epoch: [13/50] ==========
[2020-03-03 08:55:32,536] - step: [100/391], train_loss: 1.283 | train_acc: 55.969% | lr: 0.020000
[2020-03-03 08:55:33,068] - step: [200/391], train_loss: 1.282 | train_acc: 55.875% | lr: 0.020000
[2020-03-03 08:55:33,587] - step: [300/391], train_loss: 1.271 | train_acc: 55.982% | lr: 0.020000
[2020-03-03 08:55:34,089] - --- cost time: 2.1559s ---
[2020-03-03 08:55:34,090] - *************** test ***************
[2020-03-03 08:55:34,610] - test_loss: 1.180 | test_acc: 58.590%
[2020-03-03 08:55:34,610] - ************************************

[2020-03-03 08:55:34,622] - ========== epoch: [14/50] ==========
[2020-03-03 08:55:35,225] - step: [100/391], train_loss: 1.270 | train_acc: 56.680% | lr: 0.020000
[2020-03-03 08:55:35,746] - step: [200/391], train_loss: 1.252 | train_acc: 57.199% | lr: 0.020000
[2020-03-03 08:55:36,265] - step: [300/391], train_loss: 1.248 | train_acc: 57.474% | lr: 0.020000
[2020-03-03 08:55:36,757] - --- cost time: 2.1347s ---
[2020-03-03 08:55:36,758] - *************** test ***************
[2020-03-03 08:55:37,282] - test_loss: 1.061 | test_acc: 63.520%
[2020-03-03 08:55:37,282] - ************************************

[2020-03-03 08:55:37,304] - ========== epoch: [15/50] ==========
[2020-03-03 08:55:37,910] - step: [100/391], train_loss: 1.218 | train_acc: 58.367% | lr: 0.020000
[2020-03-03 08:55:38,443] - step: [200/391], train_loss: 1.212 | train_acc: 58.516% | lr: 0.020000
[2020-03-03 08:55:38,956] - step: [300/391], train_loss: 1.212 | train_acc: 58.932% | lr: 0.020000
[2020-03-03 08:55:39,458] - --- cost time: 2.1538s ---
[2020-03-03 08:55:39,458] - *************** test ***************
[2020-03-03 08:55:39,978] - test_loss: 1.084 | test_acc: 63.750%
[2020-03-03 08:55:39,978] - ************************************

[2020-03-03 08:55:40,026] - ========== epoch: [16/50] ==========
[2020-03-03 08:55:40,641] - step: [100/391], train_loss: 1.169 | train_acc: 60.820% | lr: 0.020000
[2020-03-03 08:55:41,162] - step: [200/391], train_loss: 1.170 | train_acc: 60.625% | lr: 0.020000
[2020-03-03 08:55:41,687] - step: [300/391], train_loss: 1.177 | train_acc: 60.508% | lr: 0.020000
[2020-03-03 08:55:42,176] - --- cost time: 2.1497s ---
[2020-03-03 08:55:42,176] - *************** test ***************
[2020-03-03 08:55:42,694] - test_loss: 1.038 | test_acc: 66.140%
[2020-03-03 08:55:42,694] - ************************************

[2020-03-03 08:55:42,716] - ========== epoch: [17/50] ==========
[2020-03-03 08:55:43,320] - step: [100/391], train_loss: 1.162 | train_acc: 61.117% | lr: 0.020000
[2020-03-03 08:55:43,846] - step: [200/391], train_loss: 1.169 | train_acc: 60.918% | lr: 0.020000
[2020-03-03 08:55:44,370] - step: [300/391], train_loss: 1.162 | train_acc: 61.135% | lr: 0.020000
[2020-03-03 08:55:44,856] - --- cost time: 2.1395s ---
[2020-03-03 08:55:44,856] - *************** test ***************
[2020-03-03 08:55:45,374] - test_loss: 1.106 | test_acc: 64.550%
[2020-03-03 08:55:45,374] - ************************************

[2020-03-03 08:55:45,386] - ========== epoch: [18/50] ==========
[2020-03-03 08:55:45,990] - step: [100/391], train_loss: 1.153 | train_acc: 61.258% | lr: 0.020000
[2020-03-03 08:55:46,518] - step: [200/391], train_loss: 1.164 | train_acc: 61.305% | lr: 0.020000
[2020-03-03 08:55:47,044] - step: [300/391], train_loss: 1.159 | train_acc: 61.628% | lr: 0.020000
[2020-03-03 08:55:47,540] - --- cost time: 2.1528s ---
[2020-03-03 08:55:47,540] - *************** test ***************
[2020-03-03 08:55:48,069] - test_loss: 1.025 | test_acc: 66.210%
[2020-03-03 08:55:48,070] - ************************************

[2020-03-03 08:55:48,092] - ========== epoch: [19/50] ==========
[2020-03-03 08:55:48,700] - step: [100/391], train_loss: 1.141 | train_acc: 62.930% | lr: 0.020000
[2020-03-03 08:55:49,227] - step: [200/391], train_loss: 1.139 | train_acc: 62.660% | lr: 0.020000
[2020-03-03 08:55:49,752] - step: [300/391], train_loss: 1.127 | train_acc: 62.914% | lr: 0.020000
[2020-03-03 08:55:50,238] - --- cost time: 2.1460s ---
[2020-03-03 08:55:50,238] - *************** test ***************
[2020-03-03 08:55:50,779] - test_loss: 0.990 | test_acc: 66.970%
[2020-03-03 08:55:50,780] - ************************************

[2020-03-03 08:55:50,801] - ========== epoch: [20/50] ==========
[2020-03-03 08:55:51,399] - step: [100/391], train_loss: 1.077 | train_acc: 64.359% | lr: 0.020000
[2020-03-03 08:55:51,925] - step: [200/391], train_loss: 1.092 | train_acc: 64.043% | lr: 0.020000
[2020-03-03 08:55:52,448] - step: [300/391], train_loss: 1.095 | train_acc: 64.112% | lr: 0.020000
[2020-03-03 08:55:52,937] - --- cost time: 2.1355s ---
[2020-03-03 08:55:52,937] - *************** test ***************
[2020-03-03 08:55:53,461] - test_loss: 0.956 | test_acc: 69.290%
[2020-03-03 08:55:53,461] - ************************************

[2020-03-03 08:56:12,712] - ========== epoch: [21/50] ==========
[2020-03-03 08:56:13,345] - step: [100/391], train_loss: 1.067 | train_acc: 65.352% | lr: 0.020000
[2020-03-03 08:56:13,870] - step: [200/391], train_loss: 1.086 | train_acc: 64.457% | lr: 0.020000
[2020-03-03 08:56:14,401] - step: [300/391], train_loss: 1.090 | train_acc: 64.195% | lr: 0.020000
[2020-03-03 08:56:14,891] - --- cost time: 2.1773s ---
[2020-03-03 08:56:14,891] - *************** test ***************
[2020-03-03 08:56:15,431] - test_loss: 0.944 | test_acc: 69.900%
[2020-03-03 08:56:15,431] - ************************************

[2020-03-03 08:56:15,478] - ========== epoch: [22/50] ==========
[2020-03-03 08:56:16,098] - step: [100/391], train_loss: 1.068 | train_acc: 65.469% | lr: 0.020000
[2020-03-03 08:56:16,621] - step: [200/391], train_loss: 1.078 | train_acc: 64.883% | lr: 0.020000
[2020-03-03 08:56:17,147] - step: [300/391], train_loss: 1.070 | train_acc: 65.292% | lr: 0.020000
[2020-03-03 08:56:17,640] - --- cost time: 2.1618s ---
[2020-03-03 08:56:17,641] - *************** test ***************
[2020-03-03 08:56:18,172] - test_loss: 0.925 | test_acc: 69.740%
[2020-03-03 08:56:18,172] - ************************************

[2020-03-03 08:56:18,183] - ========== epoch: [23/50] ==========
[2020-03-03 08:56:18,790] - step: [100/391], train_loss: 1.049 | train_acc: 66.266% | lr: 0.020000
[2020-03-03 08:56:19,314] - step: [200/391], train_loss: 1.056 | train_acc: 65.715% | lr: 0.020000
[2020-03-03 08:56:19,836] - step: [300/391], train_loss: 1.061 | train_acc: 65.471% | lr: 0.020000
[2020-03-03 08:56:20,330] - --- cost time: 2.1462s ---
[2020-03-03 08:56:20,330] - *************** test ***************
[2020-03-03 08:56:20,851] - test_loss: 0.925 | test_acc: 69.440%
[2020-03-03 08:56:20,851] - ************************************

[2020-03-03 08:56:20,862] - ========== epoch: [24/50] ==========
[2020-03-03 08:56:21,468] - step: [100/391], train_loss: 1.039 | train_acc: 66.156% | lr: 0.020000
[2020-03-03 08:56:21,984] - step: [200/391], train_loss: 1.044 | train_acc: 66.008% | lr: 0.020000
[2020-03-03 08:56:22,516] - step: [300/391], train_loss: 1.046 | train_acc: 65.966% | lr: 0.020000
[2020-03-03 08:56:23,004] - --- cost time: 2.1409s ---
[2020-03-03 08:56:23,004] - *************** test ***************
[2020-03-03 08:56:23,528] - test_loss: 0.915 | test_acc: 69.370%
[2020-03-03 08:56:23,528] - ************************************

[2020-03-03 08:56:23,540] - ========== epoch: [25/50] ==========
[2020-03-03 08:56:24,160] - step: [100/391], train_loss: 1.030 | train_acc: 66.320% | lr: 0.020000
[2020-03-03 08:56:24,696] - step: [200/391], train_loss: 1.033 | train_acc: 66.371% | lr: 0.020000
[2020-03-03 08:56:25,215] - step: [300/391], train_loss: 1.028 | train_acc: 66.581% | lr: 0.020000
[2020-03-03 08:56:25,708] - --- cost time: 2.1679s ---
[2020-03-03 08:56:25,709] - *************** test ***************
[2020-03-03 08:56:26,241] - test_loss: 0.888 | test_acc: 71.030%
[2020-03-03 08:56:26,242] - ************************************

[2020-03-03 08:56:26,263] - ========== epoch: [26/50] ==========
[2020-03-03 08:56:26,872] - step: [100/391], train_loss: 1.030 | train_acc: 66.594% | lr: 0.020000
[2020-03-03 08:56:27,398] - step: [200/391], train_loss: 1.030 | train_acc: 66.828% | lr: 0.020000
[2020-03-03 08:56:27,918] - step: [300/391], train_loss: 1.027 | train_acc: 66.867% | lr: 0.020000
[2020-03-03 08:56:28,414] - --- cost time: 2.1512s ---
[2020-03-03 08:56:28,415] - *************** test ***************
[2020-03-03 08:56:28,969] - test_loss: 0.899 | test_acc: 70.080%
[2020-03-03 08:56:28,970] - ************************************

[2020-03-03 08:56:28,979] - ========== epoch: [27/50] ==========
[2020-03-03 08:56:29,583] - step: [100/391], train_loss: 0.989 | train_acc: 68.547% | lr: 0.020000
[2020-03-03 08:56:30,106] - step: [200/391], train_loss: 1.010 | train_acc: 67.703% | lr: 0.020000
[2020-03-03 08:56:30,631] - step: [300/391], train_loss: 1.009 | train_acc: 67.896% | lr: 0.020000
[2020-03-03 08:56:31,143] - --- cost time: 2.1635s ---
[2020-03-03 08:56:31,143] - *************** test ***************
[2020-03-03 08:56:31,672] - test_loss: 0.900 | test_acc: 71.980%
[2020-03-03 08:56:31,673] - ************************************

[2020-03-03 08:56:31,694] - ========== epoch: [28/50] ==========
[2020-03-03 08:56:32,297] - step: [100/391], train_loss: 1.006 | train_acc: 67.625% | lr: 0.020000
[2020-03-03 08:56:32,817] - step: [200/391], train_loss: 1.024 | train_acc: 66.691% | lr: 0.020000
[2020-03-03 08:56:33,342] - step: [300/391], train_loss: 1.017 | train_acc: 67.060% | lr: 0.020000
[2020-03-03 08:56:33,839] - --- cost time: 2.1448s ---
[2020-03-03 08:56:33,839] - *************** test ***************
[2020-03-03 08:56:34,374] - test_loss: 0.885 | test_acc: 71.070%
[2020-03-03 08:56:34,374] - ************************************

[2020-03-03 08:56:34,384] - ========== epoch: [29/50] ==========
[2020-03-03 08:56:34,991] - step: [100/391], train_loss: 0.986 | train_acc: 68.781% | lr: 0.020000
[2020-03-03 08:56:35,515] - step: [200/391], train_loss: 0.990 | train_acc: 68.496% | lr: 0.020000
[2020-03-03 08:56:36,042] - step: [300/391], train_loss: 1.001 | train_acc: 68.117% | lr: 0.020000
[2020-03-03 08:56:36,532] - --- cost time: 2.1474s ---
[2020-03-03 08:56:36,532] - *************** test ***************
[2020-03-03 08:56:37,089] - test_loss: 0.923 | test_acc: 69.870%
[2020-03-03 08:56:37,089] - ************************************

[2020-03-03 08:56:37,101] - ========== epoch: [30/50] ==========
[2020-03-03 08:56:37,707] - step: [100/391], train_loss: 0.987 | train_acc: 68.398% | lr: 0.020000
[2020-03-03 08:56:38,234] - step: [200/391], train_loss: 0.980 | train_acc: 68.648% | lr: 0.020000
[2020-03-03 08:56:38,761] - step: [300/391], train_loss: 0.987 | train_acc: 68.378% | lr: 0.020000
[2020-03-03 08:56:39,255] - --- cost time: 2.1535s ---
[2020-03-03 08:56:39,255] - *************** test ***************
[2020-03-03 08:56:39,815] - test_loss: 0.919 | test_acc: 71.280%
[2020-03-03 08:56:39,815] - ************************************

[2020-03-03 08:56:46,296] - ========== epoch: [31/50] ==========
[2020-03-03 08:56:46,968] - step: [100/391], train_loss: 0.970 | train_acc: 69.195% | lr: 0.020000
[2020-03-03 08:56:47,482] - step: [200/391], train_loss: 0.979 | train_acc: 68.879% | lr: 0.020000
[2020-03-03 08:56:48,014] - step: [300/391], train_loss: 0.978 | train_acc: 68.609% | lr: 0.020000
[2020-03-03 08:56:48,508] - --- cost time: 2.2113s ---
[2020-03-03 08:56:48,508] - *************** test ***************
[2020-03-03 08:56:49,041] - test_loss: 0.971 | test_acc: 68.920%
[2020-03-03 08:56:49,041] - ************************************

[2020-03-03 08:56:49,053] - ========== epoch: [32/50] ==========
[2020-03-03 08:56:49,668] - step: [100/391], train_loss: 0.962 | train_acc: 68.977% | lr: 0.020000
[2020-03-03 08:56:50,187] - step: [200/391], train_loss: 0.963 | train_acc: 69.480% | lr: 0.020000
[2020-03-03 08:56:50,714] - step: [300/391], train_loss: 0.961 | train_acc: 69.492% | lr: 0.020000
[2020-03-03 08:56:51,207] - --- cost time: 2.1532s ---
[2020-03-03 08:56:51,207] - *************** test ***************
[2020-03-03 08:56:51,731] - test_loss: 0.880 | test_acc: 71.260%
[2020-03-03 08:56:51,731] - ************************************

[2020-03-03 08:56:51,743] - ========== epoch: [33/50] ==========
[2020-03-03 08:56:52,354] - step: [100/391], train_loss: 0.971 | train_acc: 68.938% | lr: 0.020000
[2020-03-03 08:56:52,895] - step: [200/391], train_loss: 0.978 | train_acc: 68.734% | lr: 0.020000
[2020-03-03 08:56:53,409] - step: [300/391], train_loss: 0.975 | train_acc: 68.953% | lr: 0.020000
[2020-03-03 08:56:53,917] - --- cost time: 2.1736s ---
[2020-03-03 08:56:53,917] - *************** test ***************
[2020-03-03 08:56:54,444] - test_loss: 0.891 | test_acc: 70.480%
[2020-03-03 08:56:54,445] - ************************************

[2020-03-03 08:56:54,457] - ========== epoch: [34/50] ==========
[2020-03-03 08:56:55,060] - step: [100/391], train_loss: 0.952 | train_acc: 69.609% | lr: 0.020000
[2020-03-03 08:56:55,585] - step: [200/391], train_loss: 0.959 | train_acc: 69.387% | lr: 0.020000
[2020-03-03 08:56:56,120] - step: [300/391], train_loss: 0.961 | train_acc: 69.526% | lr: 0.020000
[2020-03-03 08:56:56,609] - --- cost time: 2.1519s ---
[2020-03-03 08:56:56,609] - *************** test ***************
[2020-03-03 08:56:57,134] - test_loss: 0.884 | test_acc: 72.580%
[2020-03-03 08:56:57,134] - ************************************

[2020-03-03 08:56:57,151] - ========== epoch: [35/50] ==========
[2020-03-03 08:56:57,758] - step: [100/391], train_loss: 0.982 | train_acc: 68.680% | lr: 0.020000
[2020-03-03 08:56:58,284] - step: [200/391], train_loss: 0.975 | train_acc: 68.996% | lr: 0.020000
[2020-03-03 08:56:58,812] - step: [300/391], train_loss: 0.974 | train_acc: 69.232% | lr: 0.020000
[2020-03-03 08:56:59,308] - --- cost time: 2.1566s ---
[2020-03-03 08:56:59,309] - *************** test ***************
[2020-03-03 08:56:59,860] - test_loss: 0.839 | test_acc: 73.090%
[2020-03-03 08:56:59,860] - ************************************

[2020-03-03 08:56:59,881] - ========== epoch: [36/50] ==========
[2020-03-03 08:57:00,493] - step: [100/391], train_loss: 0.943 | train_acc: 69.781% | lr: 0.020000
[2020-03-03 08:57:01,036] - step: [200/391], train_loss: 0.937 | train_acc: 70.348% | lr: 0.020000
[2020-03-03 08:57:01,561] - step: [300/391], train_loss: 0.945 | train_acc: 70.172% | lr: 0.020000
[2020-03-03 08:57:02,056] - --- cost time: 2.1741s ---
[2020-03-03 08:57:02,056] - *************** test ***************
[2020-03-03 08:57:02,575] - test_loss: 0.888 | test_acc: 71.230%
[2020-03-03 08:57:02,576] - ************************************

[2020-03-03 08:57:02,587] - ========== epoch: [37/50] ==========
[2020-03-03 08:57:03,191] - step: [100/391], train_loss: 0.934 | train_acc: 70.203% | lr: 0.020000
[2020-03-03 08:57:03,713] - step: [200/391], train_loss: 0.938 | train_acc: 70.121% | lr: 0.020000
[2020-03-03 08:57:04,234] - step: [300/391], train_loss: 0.942 | train_acc: 70.052% | lr: 0.020000
[2020-03-03 08:57:04,722] - --- cost time: 2.1349s ---
[2020-03-03 08:57:04,723] - *************** test ***************
[2020-03-03 08:57:05,244] - test_loss: 0.843 | test_acc: 73.280%
[2020-03-03 08:57:05,244] - ************************************

[2020-03-03 08:57:05,266] - ========== epoch: [38/50] ==========
[2020-03-03 08:57:05,873] - step: [100/391], train_loss: 0.945 | train_acc: 70.250% | lr: 0.020000
[2020-03-03 08:57:06,396] - step: [200/391], train_loss: 0.945 | train_acc: 70.277% | lr: 0.020000
[2020-03-03 08:57:06,922] - step: [300/391], train_loss: 0.939 | train_acc: 70.445% | lr: 0.020000
[2020-03-03 08:57:07,415] - --- cost time: 2.1484s ---
[2020-03-03 08:57:07,415] - *************** test ***************
[2020-03-03 08:57:07,950] - test_loss: 0.904 | test_acc: 71.250%
[2020-03-03 08:57:07,950] - ************************************

[2020-03-03 08:57:07,962] - ========== epoch: [39/50] ==========
[2020-03-03 08:57:08,565] - step: [100/391], train_loss: 0.929 | train_acc: 69.961% | lr: 0.020000
[2020-03-03 08:57:09,085] - step: [200/391], train_loss: 0.932 | train_acc: 70.059% | lr: 0.020000
[2020-03-03 08:57:09,610] - step: [300/391], train_loss: 0.923 | train_acc: 70.284% | lr: 0.020000
[2020-03-03 08:57:10,099] - --- cost time: 2.1367s ---
[2020-03-03 08:57:10,099] - *************** test ***************
[2020-03-03 08:57:10,625] - test_loss: 0.936 | test_acc: 71.770%
[2020-03-03 08:57:10,625] - ************************************

[2020-03-03 08:57:10,637] - ========== epoch: [40/50] ==========
[2020-03-03 08:57:11,248] - step: [100/391], train_loss: 0.846 | train_acc: 73.195% | lr: 0.002000
[2020-03-03 08:57:11,773] - step: [200/391], train_loss: 0.819 | train_acc: 74.113% | lr: 0.002000
[2020-03-03 08:57:12,299] - step: [300/391], train_loss: 0.807 | train_acc: 74.471% | lr: 0.002000
[2020-03-03 08:57:12,796] - --- cost time: 2.1582s ---
[2020-03-03 08:57:12,796] - *************** test ***************
[2020-03-03 08:57:13,320] - test_loss: 0.748 | test_acc: 76.550%
[2020-03-03 08:57:13,320] - ************************************

[2020-03-03 08:57:15,312] - ========== epoch: [41/50] ==========
[2020-03-03 08:57:15,945] - step: [100/391], train_loss: 0.769 | train_acc: 75.617% | lr: 0.002000
[2020-03-03 08:57:16,470] - step: [200/391], train_loss: 0.766 | train_acc: 75.887% | lr: 0.002000
[2020-03-03 08:57:16,995] - step: [300/391], train_loss: 0.764 | train_acc: 75.875% | lr: 0.002000
[2020-03-03 08:57:17,491] - --- cost time: 2.1778s ---
[2020-03-03 08:57:17,491] - *************** test ***************
[2020-03-03 08:57:18,059] - test_loss: 0.726 | test_acc: 77.310%
[2020-03-03 08:57:18,060] - ************************************

[2020-03-03 08:57:18,082] - ========== epoch: [42/50] ==========
[2020-03-03 08:57:18,700] - step: [100/391], train_loss: 0.734 | train_acc: 77.625% | lr: 0.002000
[2020-03-03 08:57:19,233] - step: [200/391], train_loss: 0.740 | train_acc: 77.117% | lr: 0.002000
[2020-03-03 08:57:19,766] - step: [300/391], train_loss: 0.738 | train_acc: 77.096% | lr: 0.002000
[2020-03-03 08:57:20,264] - --- cost time: 2.1823s ---
[2020-03-03 08:57:20,265] - *************** test ***************
[2020-03-03 08:57:20,784] - test_loss: 0.712 | test_acc: 77.630%
[2020-03-03 08:57:20,785] - ************************************

[2020-03-03 08:57:20,807] - ========== epoch: [43/50] ==========
[2020-03-03 08:57:21,412] - step: [100/391], train_loss: 0.734 | train_acc: 76.852% | lr: 0.002000
[2020-03-03 08:57:21,933] - step: [200/391], train_loss: 0.744 | train_acc: 76.500% | lr: 0.002000
[2020-03-03 08:57:22,458] - step: [300/391], train_loss: 0.732 | train_acc: 76.943% | lr: 0.002000
[2020-03-03 08:57:22,962] - --- cost time: 2.1544s ---
[2020-03-03 08:57:22,962] - *************** test ***************
[2020-03-03 08:57:23,489] - test_loss: 0.709 | test_acc: 78.120%
[2020-03-03 08:57:23,490] - ************************************

[2020-03-03 08:57:23,512] - ========== epoch: [44/50] ==========
[2020-03-03 08:57:24,117] - step: [100/391], train_loss: 0.706 | train_acc: 77.633% | lr: 0.002000
[2020-03-03 08:57:24,643] - step: [200/391], train_loss: 0.714 | train_acc: 77.520% | lr: 0.002000
[2020-03-03 08:57:25,167] - step: [300/391], train_loss: 0.717 | train_acc: 77.560% | lr: 0.002000
[2020-03-03 08:57:25,656] - --- cost time: 2.1440s ---
[2020-03-03 08:57:25,657] - *************** test ***************
[2020-03-03 08:57:26,184] - test_loss: 0.712 | test_acc: 77.840%
[2020-03-03 08:57:26,185] - ************************************

[2020-03-03 08:57:26,197] - ========== epoch: [45/50] ==========
[2020-03-03 08:57:26,803] - step: [100/391], train_loss: 0.685 | train_acc: 78.141% | lr: 0.002000
[2020-03-03 08:57:27,330] - step: [200/391], train_loss: 0.704 | train_acc: 77.754% | lr: 0.002000
[2020-03-03 08:57:27,848] - step: [300/391], train_loss: 0.709 | train_acc: 77.714% | lr: 0.002000
[2020-03-03 08:57:28,341] - --- cost time: 2.1436s ---
[2020-03-03 08:57:28,342] - *************** test ***************
[2020-03-03 08:57:28,872] - test_loss: 0.715 | test_acc: 78.160%
[2020-03-03 08:57:28,872] - ************************************

[2020-03-03 08:57:28,890] - ========== epoch: [46/50] ==========
[2020-03-03 08:57:29,498] - step: [100/391], train_loss: 0.705 | train_acc: 77.484% | lr: 0.002000
[2020-03-03 08:57:30,030] - step: [200/391], train_loss: 0.711 | train_acc: 77.605% | lr: 0.002000
[2020-03-03 08:57:30,555] - step: [300/391], train_loss: 0.713 | train_acc: 77.654% | lr: 0.002000
[2020-03-03 08:57:31,040] - --- cost time: 2.1497s ---
[2020-03-03 08:57:31,040] - *************** test ***************
[2020-03-03 08:57:31,577] - test_loss: 0.710 | test_acc: 77.870%
[2020-03-03 08:57:31,578] - ************************************

[2020-03-03 08:57:31,590] - ========== epoch: [47/50] ==========
[2020-03-03 08:57:32,198] - step: [100/391], train_loss: 0.683 | train_acc: 78.320% | lr: 0.002000
[2020-03-03 08:57:32,720] - step: [200/391], train_loss: 0.697 | train_acc: 78.035% | lr: 0.002000
[2020-03-03 08:57:33,245] - step: [300/391], train_loss: 0.695 | train_acc: 78.130% | lr: 0.002000
[2020-03-03 08:57:33,734] - --- cost time: 2.1439s ---
[2020-03-03 08:57:33,734] - *************** test ***************
[2020-03-03 08:57:34,253] - test_loss: 0.720 | test_acc: 77.960%
[2020-03-03 08:57:34,253] - ************************************

[2020-03-03 08:57:34,265] - ========== epoch: [48/50] ==========
[2020-03-03 08:57:34,871] - step: [100/391], train_loss: 0.712 | train_acc: 77.695% | lr: 0.002000
[2020-03-03 08:57:35,405] - step: [200/391], train_loss: 0.698 | train_acc: 78.113% | lr: 0.002000
[2020-03-03 08:57:35,930] - step: [300/391], train_loss: 0.694 | train_acc: 78.312% | lr: 0.002000
[2020-03-03 08:57:36,427] - --- cost time: 2.1616s ---
[2020-03-03 08:57:36,427] - *************** test ***************
[2020-03-03 08:57:36,950] - test_loss: 0.706 | test_acc: 78.230%
[2020-03-03 08:57:36,950] - ************************************

[2020-03-03 08:57:36,972] - ========== epoch: [49/50] ==========
[2020-03-03 08:57:37,577] - step: [100/391], train_loss: 0.695 | train_acc: 78.477% | lr: 0.002000
[2020-03-03 08:57:38,109] - step: [200/391], train_loss: 0.686 | train_acc: 78.484% | lr: 0.002000
[2020-03-03 08:57:38,630] - step: [300/391], train_loss: 0.690 | train_acc: 78.349% | lr: 0.002000
[2020-03-03 08:57:39,130] - --- cost time: 2.1575s ---
[2020-03-03 08:57:39,130] - *************** test ***************
[2020-03-03 08:57:39,692] - test_loss: 0.708 | test_acc: 79.020%
[2020-03-03 08:57:39,692] - ************************************

[2020-03-03 08:57:39,714] - ========== epoch: [50/50] ==========
[2020-03-03 08:57:40,322] - step: [100/391], train_loss: 0.690 | train_acc: 78.422% | lr: 0.002000
[2020-03-03 08:57:40,848] - step: [200/391], train_loss: 0.688 | train_acc: 78.414% | lr: 0.002000
[2020-03-03 08:57:41,368] - step: [300/391], train_loss: 0.687 | train_acc: 78.477% | lr: 0.002000
[2020-03-03 08:57:41,874] - --- cost time: 2.1594s ---
[2020-03-03 08:57:41,874] - *************** test ***************
[2020-03-03 08:57:42,398] - test_loss: 0.717 | test_acc: 78.550%
[2020-03-03 08:57:42,398] - ************************************

[2020-03-03 08:57:48,717] - Training Finished ==> best accuracy: 79.020%
[2020-03-03 08:59:30,411] - {'architecture': 'alexnet', 'ckpt_path': './', 'ckpt_name': 'alexnet', 'log_path': './', 'log_name': 'cifar10', 'log_color': {'train': 'blue', 'cost_time': 'yellow', 'time': 'purple', 'test': 'red'}, 'data_name': 'CIFAR10', 'num_classes': 10, 'train_set_path': './data/cifar-10', 'test_set_path': './data/cifar-10', 'augmentation': {'normalize': True, 'random_crop': True, 'random_horizontal_filp': True}, 'device': 'cuda', 'input_size': 32, 'batch_size': 128, 'num_epochs': 50, 'num_print': 100, 'num_workers': 4, 'eval_freq': 1, 'test_batch': 200, 'optimizer': {'name': 'SGD', 'params': {'lr': 0.02, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': True}}, 'lr_scheduler': {'type': 'STEP', 'lr_epochs': [40], 'lr_mults': 0.1}, 'learning_curve': {'style': 'ggplot', 'xtick_step': 5, 'draw_freq': 5, 'save_path': './'}}
AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace)
    (10): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace)
  )
  (classifier): Sequential(
    (0): Linear(in_features=1152, out_features=32, bias=True)
    (1): ReLU(inplace)
    (2): Dropout(p=0.5)
    (3): Linear(in_features=32, out_features=32, bias=True)
    (4): ReLU(inplace)
    (5): Dropout(p=0.5)
    (6): Linear(in_features=32, out_features=10, bias=True)
  )
)
-------------------- Training parameters: 1432970 --------------------
[2020-03-03 08:59:30,412] - ========== epoch: [1/50] ==========
[2020-03-03 08:59:31,186] - step: [100/391], train_loss: 2.304 | train_acc: 10.273% | lr: 0.020000
[2020-03-03 08:59:31,706] - step: [200/391], train_loss: 2.303 | train_acc: 10.453% | lr: 0.020000
[2020-03-03 08:59:32,222] - step: [300/391], train_loss: 2.300 | train_acc: 10.969% | lr: 0.020000
[2020-03-03 08:59:32,711] - --- cost time: 2.2991s ---
[2020-03-03 08:59:32,711] - *************** test ***************
[2020-03-03 08:59:33,227] - test_loss: 2.091 | test_acc: 17.980%
[2020-03-03 08:59:33,227] - ************************************

[2020-03-03 08:59:33,250] - ========== epoch: [2/50] ==========
[2020-03-03 08:59:33,854] - step: [100/391], train_loss: 2.046 | train_acc: 18.258% | lr: 0.020000
[2020-03-03 08:59:34,372] - step: [200/391], train_loss: 2.020 | train_acc: 18.648% | lr: 0.020000
[2020-03-03 08:59:34,893] - step: [300/391], train_loss: 1.999 | train_acc: 18.799% | lr: 0.020000
[2020-03-03 08:59:35,382] - --- cost time: 2.1324s ---
[2020-03-03 08:59:35,383] - *************** test ***************
[2020-03-03 08:59:35,901] - test_loss: 1.875 | test_acc: 20.070%
[2020-03-03 08:59:35,901] - ************************************

[2020-03-03 08:59:35,918] - ========== epoch: [3/50] ==========
[2020-03-03 08:59:36,522] - step: [100/391], train_loss: 1.906 | train_acc: 21.430% | lr: 0.020000
[2020-03-03 08:59:37,040] - step: [200/391], train_loss: 1.915 | train_acc: 21.324% | lr: 0.020000
[2020-03-03 08:59:37,560] - step: [300/391], train_loss: 1.910 | train_acc: 21.646% | lr: 0.020000
[2020-03-03 08:59:38,055] - --- cost time: 2.1364s ---
[2020-03-03 08:59:38,055] - *************** test ***************
[2020-03-03 08:59:38,570] - test_loss: 1.849 | test_acc: 24.770%
[2020-03-03 08:59:38,570] - ************************************

[2020-03-03 08:59:38,592] - ========== epoch: [4/50] ==========
[2020-03-03 08:59:39,191] - step: [100/391], train_loss: 1.883 | train_acc: 24.703% | lr: 0.020000
[2020-03-03 08:59:39,716] - step: [200/391], train_loss: 1.877 | train_acc: 24.461% | lr: 0.020000
[2020-03-03 08:59:40,241] - step: [300/391], train_loss: 1.867 | train_acc: 25.073% | lr: 0.020000
[2020-03-03 08:59:40,725] - --- cost time: 2.1329s ---
[2020-03-03 08:59:40,726] - *************** test ***************
[2020-03-03 08:59:41,243] - test_loss: 1.802 | test_acc: 28.140%
[2020-03-03 08:59:41,244] - ************************************

[2020-03-03 08:59:41,265] - ========== epoch: [5/50] ==========
[2020-03-03 08:59:41,867] - step: [100/391], train_loss: 1.789 | train_acc: 29.555% | lr: 0.020000
[2020-03-03 08:59:42,388] - step: [200/391], train_loss: 1.777 | train_acc: 30.242% | lr: 0.020000
[2020-03-03 08:59:42,915] - step: [300/391], train_loss: 1.755 | train_acc: 31.042% | lr: 0.020000
[2020-03-03 08:59:43,405] - --- cost time: 2.1399s ---
[2020-03-03 08:59:43,406] - *************** test ***************
[2020-03-03 08:59:43,924] - test_loss: 1.611 | test_acc: 34.720%
[2020-03-03 08:59:43,924] - ************************************

[2020-03-03 08:59:44,020] - ========== epoch: [6/50] ==========
[2020-03-03 08:59:44,628] - step: [100/391], train_loss: 1.666 | train_acc: 34.977% | lr: 0.020000
[2020-03-03 08:59:45,152] - step: [200/391], train_loss: 1.668 | train_acc: 34.773% | lr: 0.020000
[2020-03-03 08:59:45,678] - step: [300/391], train_loss: 1.667 | train_acc: 35.120% | lr: 0.020000
[2020-03-03 08:59:46,172] - --- cost time: 2.1522s ---
[2020-03-03 08:59:46,173] - *************** test ***************
[2020-03-03 08:59:46,703] - test_loss: 1.540 | test_acc: 40.600%
[2020-03-03 08:59:46,703] - ************************************

[2020-03-03 08:59:46,724] - ========== epoch: [7/50] ==========
[2020-03-03 08:59:47,340] - step: [100/391], train_loss: 1.619 | train_acc: 37.484% | lr: 0.020000
[2020-03-03 08:59:47,867] - step: [200/391], train_loss: 1.610 | train_acc: 38.266% | lr: 0.020000
[2020-03-03 08:59:48,391] - step: [300/391], train_loss: 1.601 | train_acc: 38.615% | lr: 0.020000
[2020-03-03 08:59:48,886] - --- cost time: 2.1620s ---
[2020-03-03 08:59:48,887] - *************** test ***************
[2020-03-03 08:59:49,411] - test_loss: 1.488 | test_acc: 42.880%
[2020-03-03 08:59:49,411] - ************************************

[2020-03-03 08:59:49,438] - ========== epoch: [8/50] ==========
[2020-03-03 08:59:50,050] - step: [100/391], train_loss: 1.550 | train_acc: 40.852% | lr: 0.020000
[2020-03-03 08:59:50,575] - step: [200/391], train_loss: 1.555 | train_acc: 41.242% | lr: 0.020000
[2020-03-03 08:59:51,098] - step: [300/391], train_loss: 1.546 | train_acc: 41.688% | lr: 0.020000
[2020-03-03 08:59:51,604] - --- cost time: 2.1664s ---
[2020-03-03 08:59:51,605] - *************** test ***************
[2020-03-03 08:59:52,184] - test_loss: 1.486 | test_acc: 46.800%
[2020-03-03 08:59:52,184] - ************************************

[2020-03-03 08:59:52,203] - ========== epoch: [9/50] ==========
[2020-03-03 08:59:52,812] - step: [100/391], train_loss: 1.497 | train_acc: 44.125% | lr: 0.020000
[2020-03-03 08:59:53,335] - step: [200/391], train_loss: 1.495 | train_acc: 44.051% | lr: 0.020000
[2020-03-03 08:59:53,859] - step: [300/391], train_loss: 1.492 | train_acc: 44.260% | lr: 0.020000
[2020-03-03 08:59:54,360] - --- cost time: 2.1570s ---
[2020-03-03 08:59:54,360] - *************** test ***************
[2020-03-03 08:59:54,886] - test_loss: 1.341 | test_acc: 49.120%
[2020-03-03 08:59:54,886] - ************************************

[2020-03-03 08:59:54,908] - ========== epoch: [10/50] ==========
[2020-03-03 08:59:55,515] - step: [100/391], train_loss: 1.469 | train_acc: 45.359% | lr: 0.020000
[2020-03-03 08:59:56,039] - step: [200/391], train_loss: 1.460 | train_acc: 45.812% | lr: 0.020000
[2020-03-03 08:59:56,565] - step: [300/391], train_loss: 1.450 | train_acc: 46.190% | lr: 0.020000
[2020-03-03 08:59:57,056] - --- cost time: 2.1481s ---
[2020-03-03 08:59:57,056] - *************** test ***************
[2020-03-03 08:59:57,606] - test_loss: 1.330 | test_acc: 51.030%
[2020-03-03 08:59:57,607] - ************************************

[2020-03-03 08:59:57,674] - ========== epoch: [11/50] ==========
[2020-03-03 08:59:58,283] - step: [100/391], train_loss: 1.421 | train_acc: 47.875% | lr: 0.020000
[2020-03-03 08:59:58,809] - step: [200/391], train_loss: 1.426 | train_acc: 47.645% | lr: 0.020000
[2020-03-03 08:59:59,336] - step: [300/391], train_loss: 1.413 | train_acc: 48.276% | lr: 0.020000
[2020-03-03 08:59:59,832] - --- cost time: 2.1579s ---
[2020-03-03 08:59:59,832] - *************** test ***************
[2020-03-03 09:00:00,372] - test_loss: 1.249 | test_acc: 55.230%
[2020-03-03 09:00:00,372] - ************************************

[2020-03-03 09:00:00,394] - ========== epoch: [12/50] ==========
[2020-03-03 09:00:01,003] - step: [100/391], train_loss: 1.381 | train_acc: 50.484% | lr: 0.020000
[2020-03-03 09:00:01,530] - step: [200/391], train_loss: 1.363 | train_acc: 50.457% | lr: 0.020000
[2020-03-03 09:00:02,058] - step: [300/391], train_loss: 1.370 | train_acc: 50.159% | lr: 0.020000
[2020-03-03 09:00:02,550] - --- cost time: 2.1555s ---
[2020-03-03 09:00:02,550] - *************** test ***************
[2020-03-03 09:00:03,072] - test_loss: 1.218 | test_acc: 56.780%
[2020-03-03 09:00:03,072] - ************************************

[2020-03-03 09:00:03,089] - ========== epoch: [13/50] ==========
[2020-03-03 09:00:03,694] - step: [100/391], train_loss: 1.358 | train_acc: 50.695% | lr: 0.020000
[2020-03-03 09:00:04,216] - step: [200/391], train_loss: 1.363 | train_acc: 50.859% | lr: 0.020000
[2020-03-03 09:00:04,736] - step: [300/391], train_loss: 1.360 | train_acc: 50.802% | lr: 0.020000
[2020-03-03 09:00:05,232] - --- cost time: 2.1431s ---
[2020-03-03 09:00:05,233] - *************** test ***************
[2020-03-03 09:00:05,752] - test_loss: 1.250 | test_acc: 56.130%
[2020-03-03 09:00:05,752] - ************************************

[2020-03-03 09:00:05,764] - ========== epoch: [14/50] ==========
[2020-03-03 09:00:06,369] - step: [100/391], train_loss: 1.312 | train_acc: 53.539% | lr: 0.020000
[2020-03-03 09:00:06,891] - step: [200/391], train_loss: 1.310 | train_acc: 53.188% | lr: 0.020000
[2020-03-03 09:00:07,418] - step: [300/391], train_loss: 1.325 | train_acc: 52.833% | lr: 0.020000
[2020-03-03 09:00:07,912] - --- cost time: 2.1475s ---
[2020-03-03 09:00:07,912] - *************** test ***************
[2020-03-03 09:00:08,434] - test_loss: 1.224 | test_acc: 56.170%
[2020-03-03 09:00:08,434] - ************************************

[2020-03-03 09:00:08,447] - ========== epoch: [15/50] ==========
[2020-03-03 09:00:09,057] - step: [100/391], train_loss: 1.309 | train_acc: 54.305% | lr: 0.020000
[2020-03-03 09:00:09,581] - step: [200/391], train_loss: 1.297 | train_acc: 54.320% | lr: 0.020000
[2020-03-03 09:00:10,105] - step: [300/391], train_loss: 1.298 | train_acc: 54.320% | lr: 0.020000
[2020-03-03 09:00:10,598] - --- cost time: 2.1513s ---
[2020-03-03 09:00:10,598] - *************** test ***************
[2020-03-03 09:00:11,128] - test_loss: 1.132 | test_acc: 61.370%
[2020-03-03 09:00:11,128] - ************************************

[2020-03-03 09:00:11,206] - ========== epoch: [16/50] ==========
[2020-03-03 09:00:11,818] - step: [100/391], train_loss: 1.265 | train_acc: 55.719% | lr: 0.020000
[2020-03-03 09:00:12,340] - step: [200/391], train_loss: 1.280 | train_acc: 55.348% | lr: 0.020000
[2020-03-03 09:00:12,863] - step: [300/391], train_loss: 1.274 | train_acc: 55.706% | lr: 0.020000
[2020-03-03 09:00:13,358] - --- cost time: 2.1511s ---
[2020-03-03 09:00:13,358] - *************** test ***************
[2020-03-03 09:00:13,919] - test_loss: 1.116 | test_acc: 63.220%
[2020-03-03 09:00:13,919] - ************************************

[2020-03-03 09:00:13,941] - ========== epoch: [17/50] ==========
[2020-03-03 09:00:14,556] - step: [100/391], train_loss: 1.250 | train_acc: 56.812% | lr: 0.020000
[2020-03-03 09:00:15,081] - step: [200/391], train_loss: 1.240 | train_acc: 57.320% | lr: 0.020000
[2020-03-03 09:00:15,608] - step: [300/391], train_loss: 1.242 | train_acc: 56.927% | lr: 0.020000
[2020-03-03 09:00:16,112] - --- cost time: 2.1706s ---
[2020-03-03 09:00:16,112] - *************** test ***************
[2020-03-03 09:00:16,637] - test_loss: 1.314 | test_acc: 55.310%
[2020-03-03 09:00:16,637] - ************************************

[2020-03-03 09:00:16,649] - ========== epoch: [18/50] ==========
[2020-03-03 09:00:17,261] - step: [100/391], train_loss: 1.219 | train_acc: 57.594% | lr: 0.020000
[2020-03-03 09:00:17,783] - step: [200/391], train_loss: 1.230 | train_acc: 57.570% | lr: 0.020000
[2020-03-03 09:00:18,301] - step: [300/391], train_loss: 1.222 | train_acc: 57.953% | lr: 0.020000
[2020-03-03 09:00:18,803] - --- cost time: 2.1537s ---
[2020-03-03 09:00:18,803] - *************** test ***************
[2020-03-03 09:00:19,360] - test_loss: 1.048 | test_acc: 65.370%
[2020-03-03 09:00:19,360] - ************************************

[2020-03-03 09:00:19,382] - ========== epoch: [19/50] ==========
[2020-03-03 09:00:19,996] - step: [100/391], train_loss: 1.197 | train_acc: 59.406% | lr: 0.020000
[2020-03-03 09:00:20,517] - step: [200/391], train_loss: 1.208 | train_acc: 58.844% | lr: 0.020000
[2020-03-03 09:00:21,043] - step: [300/391], train_loss: 1.202 | train_acc: 59.091% | lr: 0.020000
[2020-03-03 09:00:21,548] - --- cost time: 2.1657s ---
[2020-03-03 09:00:21,548] - *************** test ***************
[2020-03-03 09:00:22,077] - test_loss: 1.042 | test_acc: 66.070%
[2020-03-03 09:00:22,077] - ************************************

[2020-03-03 09:00:22,099] - ========== epoch: [20/50] ==========
[2020-03-03 09:00:22,715] - step: [100/391], train_loss: 1.166 | train_acc: 60.578% | lr: 0.020000
[2020-03-03 09:00:23,245] - step: [200/391], train_loss: 1.180 | train_acc: 60.262% | lr: 0.020000
[2020-03-03 09:00:23,770] - step: [300/391], train_loss: 1.180 | train_acc: 60.560% | lr: 0.020000
[2020-03-03 09:00:24,272] - --- cost time: 2.1727s ---
[2020-03-03 09:00:24,272] - *************** test ***************
[2020-03-03 09:00:24,797] - test_loss: 1.041 | test_acc: 65.880%
[2020-03-03 09:00:24,797] - ************************************

[2020-03-03 09:00:24,910] - ========== epoch: [21/50] ==========
[2020-03-03 09:00:25,523] - step: [100/391], train_loss: 1.162 | train_acc: 60.781% | lr: 0.020000
[2020-03-03 09:00:26,053] - step: [200/391], train_loss: 1.174 | train_acc: 60.527% | lr: 0.020000
[2020-03-03 09:00:26,584] - step: [300/391], train_loss: 1.163 | train_acc: 61.115% | lr: 0.020000
[2020-03-03 09:00:27,088] - --- cost time: 2.1775s ---
[2020-03-03 09:00:27,088] - *************** test ***************
[2020-03-03 09:00:27,614] - test_loss: 1.076 | test_acc: 65.580%
[2020-03-03 09:00:27,614] - ************************************

[2020-03-03 09:00:27,626] - ========== epoch: [22/50] ==========
[2020-03-03 09:00:28,238] - step: [100/391], train_loss: 1.142 | train_acc: 62.367% | lr: 0.020000
[2020-03-03 09:00:28,761] - step: [200/391], train_loss: 1.137 | train_acc: 62.371% | lr: 0.020000
[2020-03-03 09:00:29,288] - step: [300/391], train_loss: 1.130 | train_acc: 62.685% | lr: 0.020000
[2020-03-03 09:00:52,178] - {'architecture': 'alexnet', 'ckpt_path': './', 'ckpt_name': 'alexnet', 'log_path': './', 'log_name': 'cifar10', 'log_color': {'train': 'blue', 'cost_time': 'yellow', 'time': 'purple', 'test': 'red'}, 'data_name': 'CIFAR10', 'num_classes': 10, 'train_set_path': './data/cifar-10', 'test_set_path': './data/cifar-10', 'augmentation': {'normalize': True, 'random_crop': True, 'random_horizontal_filp': True}, 'device': 'cuda', 'input_size': 32, 'batch_size': 128, 'num_epochs': 50, 'num_print': 100, 'num_workers': 4, 'eval_freq': 1, 'test_batch': 200, 'optimizer': {'name': 'SGD', 'params': {'lr': 0.02, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': True}}, 'lr_scheduler': {'type': 'STEP', 'lr_epochs': [40], 'lr_mults': 0.1}, 'learning_curve': {'style': 'ggplot', 'xtick_step': 5, 'draw_freq': 5, 'save_path': './'}}
AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace)
    (10): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace)
  )
  (classifier): Sequential(
    (0): Linear(in_features=1152, out_features=32, bias=True)
    (1): ReLU(inplace)
    (2): Dropout(p=0.5)
    (3): Linear(in_features=32, out_features=32, bias=True)
    (4): ReLU(inplace)
    (5): Dropout(p=0.5)
    (6): Linear(in_features=32, out_features=10, bias=True)
  )
)
-------------------- Training parameters: 1432970 --------------------
[2020-03-03 09:00:52,178] - ========== epoch: [1/50] ==========
[2020-03-03 09:00:52,956] - step: [100/391], train_loss: 2.303 | train_acc: 10.203% | lr: 0.020000
[2020-03-03 09:00:53,477] - step: [200/391], train_loss: 2.293 | train_acc: 11.574% | lr: 0.020000
[2020-03-03 09:00:54,001] - step: [300/391], train_loss: 2.233 | train_acc: 13.630% | lr: 0.020000
[2020-03-03 09:00:54,488] - --- cost time: 2.3092s ---
[2020-03-03 09:00:54,488] - *************** test ***************
[2020-03-03 09:00:55,008] - test_loss: 1.923 | test_acc: 22.880%
[2020-03-03 09:00:55,008] - ************************************

[2020-03-03 09:00:55,030] - ========== epoch: [2/50] ==========
[2020-03-03 09:00:55,632] - step: [100/391], train_loss: 1.955 | train_acc: 21.328% | lr: 0.020000
[2020-03-03 09:00:56,152] - step: [200/391], train_loss: 1.941 | train_acc: 21.988% | lr: 0.020000
[2020-03-03 09:00:56,673] - step: [300/391], train_loss: 1.918 | train_acc: 22.872% | lr: 0.020000
[2020-03-03 09:00:57,155] - --- cost time: 2.1250s ---
[2020-03-03 09:00:57,155] - *************** test ***************
[2020-03-03 09:00:57,676] - test_loss: 1.748 | test_acc: 26.970%
[2020-03-03 09:00:57,677] - ************************************

[2020-03-03 09:00:57,699] - ========== epoch: [3/50] ==========
[2020-03-03 09:00:58,296] - step: [100/391], train_loss: 1.831 | train_acc: 27.289% | lr: 0.020000
[2020-03-03 09:00:58,814] - step: [200/391], train_loss: 1.809 | train_acc: 27.949% | lr: 0.020000
[2020-03-03 09:00:59,335] - step: [300/391], train_loss: 1.795 | train_acc: 28.724% | lr: 0.020000
[2020-03-03 09:00:59,818] - --- cost time: 2.1195s ---
[2020-03-03 09:00:59,819] - *************** test ***************
[2020-03-03 09:01:00,337] - test_loss: 1.603 | test_acc: 37.100%
[2020-03-03 09:01:00,337] - ************************************

[2020-03-03 09:01:00,358] - ========== epoch: [4/50] ==========
[2020-03-03 09:01:00,962] - step: [100/391], train_loss: 1.714 | train_acc: 33.117% | lr: 0.020000
[2020-03-03 09:01:01,482] - step: [200/391], train_loss: 1.718 | train_acc: 32.359% | lr: 0.020000
[2020-03-03 09:01:02,001] - step: [300/391], train_loss: 1.710 | train_acc: 32.747% | lr: 0.020000
[2020-03-03 09:01:02,491] - --- cost time: 2.1331s ---
[2020-03-03 09:01:02,492] - *************** test ***************
[2020-03-03 09:01:03,011] - test_loss: 1.504 | test_acc: 41.730%
[2020-03-03 09:01:03,012] - ************************************

[2020-03-03 09:01:03,033] - ========== epoch: [5/50] ==========
[2020-03-03 09:01:03,637] - step: [100/391], train_loss: 1.621 | train_acc: 37.484% | lr: 0.020000
[2020-03-03 09:01:04,153] - step: [200/391], train_loss: 1.611 | train_acc: 38.371% | lr: 0.020000
[2020-03-03 09:01:04,669] - step: [300/391], train_loss: 1.607 | train_acc: 38.469% | lr: 0.020000
[2020-03-03 09:01:05,158] - --- cost time: 2.1255s ---
[2020-03-03 09:01:05,159] - *************** test ***************
[2020-03-03 09:01:05,723] - test_loss: 1.405 | test_acc: 47.560%
[2020-03-03 09:01:05,723] - ************************************

[2020-03-03 09:01:05,917] - ========== epoch: [6/50] ==========
[2020-03-03 09:01:06,522] - step: [100/391], train_loss: 1.568 | train_acc: 41.188% | lr: 0.020000
[2020-03-03 09:01:07,045] - step: [200/391], train_loss: 1.557 | train_acc: 41.543% | lr: 0.020000
[2020-03-03 09:01:07,565] - step: [300/391], train_loss: 1.547 | train_acc: 41.875% | lr: 0.020000
[2020-03-03 09:01:08,051] - --- cost time: 2.1332s ---
[2020-03-03 09:01:08,051] - *************** test ***************
[2020-03-03 09:01:08,569] - test_loss: 1.390 | test_acc: 47.280%
[2020-03-03 09:01:08,570] - ************************************

[2020-03-03 09:01:08,582] - ========== epoch: [7/50] ==========
[2020-03-03 09:01:09,188] - step: [100/391], train_loss: 1.518 | train_acc: 42.766% | lr: 0.020000
[2020-03-03 09:01:09,713] - step: [200/391], train_loss: 1.504 | train_acc: 43.605% | lr: 0.020000
[2020-03-03 09:01:10,236] - step: [300/391], train_loss: 1.495 | train_acc: 44.039% | lr: 0.020000
[2020-03-03 09:01:10,728] - --- cost time: 2.1454s ---
[2020-03-03 09:01:10,728] - *************** test ***************
[2020-03-03 09:01:11,272] - test_loss: 1.344 | test_acc: 51.370%
[2020-03-03 09:01:11,272] - ************************************

[2020-03-03 09:01:11,293] - ========== epoch: [8/50] ==========
[2020-03-03 09:01:11,899] - step: [100/391], train_loss: 1.450 | train_acc: 46.844% | lr: 0.020000
[2020-03-03 09:01:12,422] - step: [200/391], train_loss: 1.448 | train_acc: 46.574% | lr: 0.020000
[2020-03-03 09:01:12,944] - step: [300/391], train_loss: 1.439 | train_acc: 47.070% | lr: 0.020000
[2020-03-03 09:01:13,436] - --- cost time: 2.1423s ---
[2020-03-03 09:01:13,436] - *************** test ***************
[2020-03-03 09:01:13,967] - test_loss: 1.292 | test_acc: 53.210%
[2020-03-03 09:01:13,967] - ************************************

[2020-03-03 09:01:13,989] - ========== epoch: [9/50] ==========
[2020-03-03 09:01:14,598] - step: [100/391], train_loss: 1.409 | train_acc: 48.219% | lr: 0.020000
[2020-03-03 09:01:15,116] - step: [200/391], train_loss: 1.417 | train_acc: 48.000% | lr: 0.020000
[2020-03-03 09:01:15,638] - step: [300/391], train_loss: 1.403 | train_acc: 48.435% | lr: 0.020000
[2020-03-03 09:01:16,135] - --- cost time: 2.1456s ---
[2020-03-03 09:01:16,135] - *************** test ***************
[2020-03-03 09:01:16,664] - test_loss: 1.265 | test_acc: 54.660%
[2020-03-03 09:01:16,664] - ************************************

[2020-03-03 09:01:16,685] - ========== epoch: [10/50] ==========
[2020-03-03 09:01:17,288] - step: [100/391], train_loss: 1.382 | train_acc: 49.555% | lr: 0.020000
[2020-03-03 09:01:17,810] - step: [200/391], train_loss: 1.384 | train_acc: 49.789% | lr: 0.020000
[2020-03-03 09:01:18,335] - step: [300/391], train_loss: 1.370 | train_acc: 50.443% | lr: 0.020000
[2020-03-03 09:01:18,826] - --- cost time: 2.1401s ---
[2020-03-03 09:01:18,826] - *************** test ***************
[2020-03-03 09:01:19,352] - test_loss: 1.200 | test_acc: 56.250%
[2020-03-03 09:01:19,352] - ************************************

[2020-03-03 09:01:19,492] - ========== epoch: [11/50] ==========
[2020-03-03 09:01:20,111] - step: [100/391], train_loss: 1.336 | train_acc: 51.797% | lr: 0.020000
[2020-03-03 09:01:20,634] - step: [200/391], train_loss: 1.325 | train_acc: 52.461% | lr: 0.020000
[2020-03-03 09:01:21,154] - step: [300/391], train_loss: 1.320 | train_acc: 52.945% | lr: 0.020000
[2020-03-03 09:01:21,654] - --- cost time: 2.1609s ---
[2020-03-03 09:01:21,654] - *************** test ***************
[2020-03-03 09:01:22,180] - test_loss: 1.135 | test_acc: 60.830%
[2020-03-03 09:01:22,180] - ************************************

[2020-03-03 09:01:22,201] - ========== epoch: [12/50] ==========
[2020-03-03 09:01:22,808] - step: [100/391], train_loss: 1.296 | train_acc: 53.906% | lr: 0.020000
[2020-03-03 09:01:23,334] - step: [200/391], train_loss: 1.285 | train_acc: 54.543% | lr: 0.020000
[2020-03-03 09:01:23,860] - step: [300/391], train_loss: 1.285 | train_acc: 54.685% | lr: 0.020000
[2020-03-03 09:01:24,353] - --- cost time: 2.1519s ---
[2020-03-03 09:01:24,354] - *************** test ***************
[2020-03-03 09:01:24,884] - test_loss: 1.138 | test_acc: 60.840%
[2020-03-03 09:01:24,884] - ************************************

[2020-03-03 09:01:24,901] - ========== epoch: [13/50] ==========
[2020-03-03 09:01:25,509] - step: [100/391], train_loss: 1.269 | train_acc: 56.320% | lr: 0.020000
[2020-03-03 09:01:26,037] - step: [200/391], train_loss: 1.253 | train_acc: 56.605% | lr: 0.020000
[2020-03-03 09:01:26,562] - step: [300/391], train_loss: 1.243 | train_acc: 56.909% | lr: 0.020000
[2020-03-03 09:01:27,058] - --- cost time: 2.1568s ---
[2020-03-03 09:01:27,058] - *************** test ***************
[2020-03-03 09:01:27,599] - test_loss: 1.089 | test_acc: 63.130%
[2020-03-03 09:01:27,599] - ************************************

[2020-03-03 09:01:27,621] - ========== epoch: [14/50] ==========
[2020-03-03 09:01:28,227] - step: [100/391], train_loss: 1.215 | train_acc: 58.016% | lr: 0.020000
[2020-03-03 09:01:28,748] - step: [200/391], train_loss: 1.224 | train_acc: 57.633% | lr: 0.020000
[2020-03-03 09:01:29,267] - step: [300/391], train_loss: 1.222 | train_acc: 57.904% | lr: 0.020000
[2020-03-03 09:01:29,756] - --- cost time: 2.1346s ---
[2020-03-03 09:01:29,756] - *************** test ***************
[2020-03-03 09:01:30,278] - test_loss: 1.034 | test_acc: 64.560%
[2020-03-03 09:01:30,278] - ************************************

[2020-03-03 09:01:30,300] - ========== epoch: [15/50] ==========
[2020-03-03 09:01:30,905] - step: [100/391], train_loss: 1.161 | train_acc: 60.508% | lr: 0.020000
[2020-03-03 09:01:31,422] - step: [200/391], train_loss: 1.167 | train_acc: 60.434% | lr: 0.020000
[2020-03-03 09:01:31,942] - step: [300/391], train_loss: 1.175 | train_acc: 60.151% | lr: 0.020000
[2020-03-03 09:01:32,431] - --- cost time: 2.1307s ---
[2020-03-03 09:01:32,431] - *************** test ***************
[2020-03-03 09:01:32,987] - test_loss: 1.081 | test_acc: 64.600%
[2020-03-03 09:01:32,988] - ************************************

[2020-03-03 09:01:33,136] - ========== epoch: [16/50] ==========
[2020-03-03 09:01:33,746] - step: [100/391], train_loss: 1.213 | train_acc: 59.312% | lr: 0.020000
[2020-03-03 09:01:34,267] - step: [200/391], train_loss: 1.185 | train_acc: 60.375% | lr: 0.020000
[2020-03-03 09:01:34,787] - step: [300/391], train_loss: 1.172 | train_acc: 60.539% | lr: 0.020000
[2020-03-03 09:01:35,299] - --- cost time: 2.1628s ---
[2020-03-03 09:01:35,299] - *************** test ***************
[2020-03-03 09:01:35,826] - test_loss: 1.011 | test_acc: 65.940%
[2020-03-03 09:01:35,826] - ************************************

[2020-03-03 09:01:35,843] - ========== epoch: [17/50] ==========
[2020-03-03 09:01:36,453] - step: [100/391], train_loss: 1.147 | train_acc: 61.891% | lr: 0.020000
[2020-03-03 09:01:36,975] - step: [200/391], train_loss: 1.137 | train_acc: 61.953% | lr: 0.020000
[2020-03-03 09:01:37,502] - step: [300/391], train_loss: 1.137 | train_acc: 62.023% | lr: 0.020000
[2020-03-03 09:01:37,997] - --- cost time: 2.1536s ---
[2020-03-03 09:01:37,997] - *************** test ***************
[2020-03-03 09:01:38,531] - test_loss: 1.017 | test_acc: 65.370%
[2020-03-03 09:01:38,531] - ************************************

[2020-03-03 09:01:38,543] - ========== epoch: [18/50] ==========
[2020-03-03 09:01:39,147] - step: [100/391], train_loss: 1.111 | train_acc: 62.836% | lr: 0.020000
[2020-03-03 09:01:39,670] - step: [200/391], train_loss: 1.109 | train_acc: 63.090% | lr: 0.020000
[2020-03-03 09:01:40,189] - step: [300/391], train_loss: 1.117 | train_acc: 62.786% | lr: 0.020000
[2020-03-03 09:01:40,680] - --- cost time: 2.1367s ---
[2020-03-03 09:01:40,680] - *************** test ***************
[2020-03-03 09:01:41,222] - test_loss: 0.996 | test_acc: 65.810%
[2020-03-03 09:01:41,222] - ************************************

[2020-03-03 09:01:41,240] - ========== epoch: [19/50] ==========
[2020-03-03 09:01:41,880] - step: [100/391], train_loss: 1.116 | train_acc: 63.305% | lr: 0.020000
[2020-03-03 09:01:42,400] - step: [200/391], train_loss: 1.106 | train_acc: 63.590% | lr: 0.020000
[2020-03-03 09:01:42,922] - step: [300/391], train_loss: 1.108 | train_acc: 63.341% | lr: 0.020000
[2020-03-03 09:01:43,410] - --- cost time: 2.1690s ---
[2020-03-03 09:01:43,410] - *************** test ***************
[2020-03-03 09:01:43,951] - test_loss: 1.069 | test_acc: 65.120%
[2020-03-03 09:01:43,951] - ************************************

[2020-03-03 09:01:43,963] - ========== epoch: [20/50] ==========
[2020-03-03 09:01:44,574] - step: [100/391], train_loss: 1.105 | train_acc: 64.211% | lr: 0.020000
[2020-03-03 09:01:45,101] - step: [200/391], train_loss: 1.097 | train_acc: 64.199% | lr: 0.020000
[2020-03-03 09:01:45,626] - step: [300/391], train_loss: 1.095 | train_acc: 64.036% | lr: 0.020000
[2020-03-03 09:01:46,120] - --- cost time: 2.1574s ---
[2020-03-03 09:01:46,121] - *************** test ***************
[2020-03-03 09:01:46,641] - test_loss: 1.009 | test_acc: 66.430%
[2020-03-03 09:01:46,641] - ************************************

[2020-03-03 09:01:46,793] - ========== epoch: [21/50] ==========
[2020-03-03 09:01:47,404] - step: [100/391], train_loss: 1.079 | train_acc: 64.016% | lr: 0.020000
[2020-03-03 09:01:47,927] - step: [200/391], train_loss: 1.090 | train_acc: 63.887% | lr: 0.020000
[2020-03-03 09:01:48,449] - step: [300/391], train_loss: 1.085 | train_acc: 63.906% | lr: 0.020000
[2020-03-03 09:01:48,959] - --- cost time: 2.1656s ---
[2020-03-03 09:01:48,960] - *************** test ***************
[2020-03-03 09:01:49,478] - test_loss: 0.973 | test_acc: 68.490%
[2020-03-03 09:01:49,478] - ************************************

[2020-03-03 09:01:49,499] - ========== epoch: [22/50] ==========
[2020-03-03 09:01:50,111] - step: [100/391], train_loss: 1.062 | train_acc: 65.164% | lr: 0.020000
[2020-03-03 09:01:50,631] - step: [200/391], train_loss: 1.062 | train_acc: 65.094% | lr: 0.020000
[2020-03-03 09:01:51,158] - step: [300/391], train_loss: 1.062 | train_acc: 65.177% | lr: 0.020000
[2020-03-03 09:01:51,649] - --- cost time: 2.1488s ---
[2020-03-03 09:01:51,649] - *************** test ***************
[2020-03-03 09:01:52,178] - test_loss: 0.941 | test_acc: 69.830%
[2020-03-03 09:01:52,178] - ************************************

[2020-03-03 09:01:52,195] - ========== epoch: [23/50] ==========
[2020-03-03 09:01:52,802] - step: [100/391], train_loss: 1.051 | train_acc: 65.625% | lr: 0.020000
[2020-03-03 09:01:53,323] - step: [200/391], train_loss: 1.063 | train_acc: 65.211% | lr: 0.020000
[2020-03-03 09:01:53,844] - step: [300/391], train_loss: 1.062 | train_acc: 65.206% | lr: 0.020000
[2020-03-03 09:01:54,337] - --- cost time: 2.1425s ---
[2020-03-03 09:01:54,338] - *************** test ***************
[2020-03-03 09:01:54,892] - test_loss: 0.883 | test_acc: 71.040%
[2020-03-03 09:01:54,892] - ************************************

[2020-03-03 09:01:54,914] - ========== epoch: [24/50] ==========
[2020-03-03 09:01:55,517] - step: [100/391], train_loss: 1.038 | train_acc: 66.297% | lr: 0.020000
[2020-03-03 09:01:56,042] - step: [200/391], train_loss: 1.039 | train_acc: 65.957% | lr: 0.020000
[2020-03-03 09:01:56,565] - step: [300/391], train_loss: 1.041 | train_acc: 65.875% | lr: 0.020000
[2020-03-03 09:01:57,055] - --- cost time: 2.1412s ---
[2020-03-03 09:01:57,056] - *************** test ***************
[2020-03-03 09:01:57,588] - test_loss: 0.913 | test_acc: 70.300%
[2020-03-03 09:01:57,588] - ************************************

[2020-03-03 09:01:57,600] - ========== epoch: [25/50] ==========
[2020-03-03 09:01:58,205] - step: [100/391], train_loss: 1.022 | train_acc: 66.617% | lr: 0.020000
[2020-03-03 09:01:58,727] - step: [200/391], train_loss: 1.025 | train_acc: 66.699% | lr: 0.020000
[2020-03-03 09:01:59,253] - step: [300/391], train_loss: 1.029 | train_acc: 66.505% | lr: 0.020000
[2020-03-03 09:01:59,745] - --- cost time: 2.1449s ---
[2020-03-03 09:01:59,745] - *************** test ***************
[2020-03-03 09:02:00,271] - test_loss: 0.939 | test_acc: 69.150%
[2020-03-03 09:02:00,271] - ************************************

[2020-03-03 09:02:00,415] - ========== epoch: [26/50] ==========
[2020-03-03 09:02:01,029] - step: [100/391], train_loss: 1.004 | train_acc: 67.188% | lr: 0.020000
[2020-03-03 09:02:01,553] - step: [200/391], train_loss: 1.020 | train_acc: 66.574% | lr: 0.020000
[2020-03-03 09:02:02,078] - step: [300/391], train_loss: 1.021 | train_acc: 66.674% | lr: 0.020000
[2020-03-03 09:02:02,581] - --- cost time: 2.1659s ---
[2020-03-03 09:02:02,581] - *************** test ***************
[2020-03-03 09:02:03,110] - test_loss: 0.940 | test_acc: 70.490%
[2020-03-03 09:02:03,110] - ************************************

[2020-03-03 09:02:03,119] - ========== epoch: [27/50] ==========
[2020-03-03 09:02:03,728] - step: [100/391], train_loss: 1.017 | train_acc: 67.094% | lr: 0.020000
[2020-03-03 09:02:04,247] - step: [200/391], train_loss: 1.015 | train_acc: 66.898% | lr: 0.020000
[2020-03-03 09:02:04,775] - step: [300/391], train_loss: 1.011 | train_acc: 67.104% | lr: 0.020000
[2020-03-03 09:02:05,262] - --- cost time: 2.1422s ---
[2020-03-03 09:02:05,262] - *************** test ***************
[2020-03-03 09:02:05,795] - test_loss: 0.898 | test_acc: 71.630%
[2020-03-03 09:02:05,795] - ************************************

[2020-03-03 09:02:05,812] - ========== epoch: [28/50] ==========
[2020-03-03 09:02:06,425] - step: [100/391], train_loss: 1.002 | train_acc: 67.609% | lr: 0.020000
[2020-03-03 09:02:06,949] - step: [200/391], train_loss: 1.004 | train_acc: 67.762% | lr: 0.020000
[2020-03-03 09:02:07,470] - step: [300/391], train_loss: 1.001 | train_acc: 67.690% | lr: 0.020000
[2020-03-03 09:02:07,968] - --- cost time: 2.1559s ---
[2020-03-03 09:02:07,968] - *************** test ***************
[2020-03-03 09:02:08,511] - test_loss: 0.869 | test_acc: 72.720%
[2020-03-03 09:02:08,511] - ************************************

[2020-03-03 09:02:08,532] - ========== epoch: [29/50] ==========
[2020-03-03 09:02:09,147] - step: [100/391], train_loss: 1.005 | train_acc: 67.508% | lr: 0.020000
[2020-03-03 09:02:09,667] - step: [200/391], train_loss: 0.999 | train_acc: 67.781% | lr: 0.020000
[2020-03-03 09:02:10,193] - step: [300/391], train_loss: 1.003 | train_acc: 67.648% | lr: 0.020000
[2020-03-03 09:02:10,683] - --- cost time: 2.1511s ---
[2020-03-03 09:02:10,683] - *************** test ***************
[2020-03-03 09:02:11,207] - test_loss: 0.880 | test_acc: 72.410%
[2020-03-03 09:02:11,207] - ************************************

[2020-03-03 09:02:11,219] - ========== epoch: [30/50] ==========
[2020-03-03 09:02:11,833] - step: [100/391], train_loss: 0.988 | train_acc: 68.500% | lr: 0.020000
[2020-03-03 09:02:12,359] - step: [200/391], train_loss: 0.993 | train_acc: 68.156% | lr: 0.020000
[2020-03-03 09:02:12,882] - step: [300/391], train_loss: 0.995 | train_acc: 68.167% | lr: 0.020000
[2020-03-03 09:02:13,388] - --- cost time: 2.1686s ---
[2020-03-03 09:02:13,388] - *************** test ***************
[2020-03-03 09:02:13,928] - test_loss: 0.926 | test_acc: 70.050%
[2020-03-03 09:02:13,928] - ************************************

[2020-03-03 09:02:14,076] - ========== epoch: [31/50] ==========
[2020-03-03 09:02:14,692] - step: [100/391], train_loss: 0.964 | train_acc: 69.227% | lr: 0.020000
[2020-03-03 09:02:15,217] - step: [200/391], train_loss: 0.979 | train_acc: 68.672% | lr: 0.020000
[2020-03-03 09:02:15,740] - step: [300/391], train_loss: 0.985 | train_acc: 68.497% | lr: 0.020000
[2020-03-03 09:02:16,236] - --- cost time: 2.1600s ---
[2020-03-03 09:02:16,237] - *************** test ***************
[2020-03-03 09:02:16,775] - test_loss: 0.861 | test_acc: 71.970%
[2020-03-03 09:02:16,775] - ************************************

[2020-03-03 09:02:16,787] - ========== epoch: [32/50] ==========
[2020-03-03 09:02:17,392] - step: [100/391], train_loss: 0.964 | train_acc: 69.328% | lr: 0.020000
[2020-03-03 09:02:17,918] - step: [200/391], train_loss: 0.971 | train_acc: 68.934% | lr: 0.020000
[2020-03-03 09:02:18,439] - step: [300/391], train_loss: 0.978 | train_acc: 68.576% | lr: 0.020000
[2020-03-03 09:02:18,944] - --- cost time: 2.1564s ---
[2020-03-03 09:02:18,944] - *************** test ***************
[2020-03-03 09:02:19,465] - test_loss: 0.901 | test_acc: 70.650%
[2020-03-03 09:02:19,466] - ************************************

[2020-03-03 09:02:19,476] - ========== epoch: [33/50] ==========
[2020-03-03 09:02:20,092] - step: [100/391], train_loss: 0.968 | train_acc: 68.828% | lr: 0.020000
[2020-03-03 09:02:20,620] - step: [200/391], train_loss: 0.981 | train_acc: 68.500% | lr: 0.020000
[2020-03-03 09:02:21,142] - step: [300/391], train_loss: 0.983 | train_acc: 68.505% | lr: 0.020000
[2020-03-03 09:02:21,662] - --- cost time: 2.1859s ---
[2020-03-03 09:02:21,662] - *************** test ***************
[2020-03-03 09:02:22,231] - test_loss: 0.878 | test_acc: 71.330%
[2020-03-03 09:02:22,231] - ************************************

[2020-03-03 09:02:22,243] - ========== epoch: [34/50] ==========
[2020-03-03 09:02:22,859] - step: [100/391], train_loss: 0.958 | train_acc: 69.531% | lr: 0.020000
[2020-03-03 09:02:23,377] - step: [200/391], train_loss: 0.957 | train_acc: 69.430% | lr: 0.020000
[2020-03-03 09:02:23,900] - step: [300/391], train_loss: 0.962 | train_acc: 69.227% | lr: 0.020000
[2020-03-03 09:02:24,393] - --- cost time: 2.1499s ---
[2020-03-03 09:02:24,394] - *************** test ***************
[2020-03-03 09:02:24,927] - test_loss: 0.843 | test_acc: 73.260%
[2020-03-03 09:02:24,927] - ************************************

[2020-03-03 09:02:24,944] - ========== epoch: [35/50] ==========
[2020-03-03 09:02:25,550] - step: [100/391], train_loss: 0.973 | train_acc: 69.258% | lr: 0.020000
[2020-03-03 09:02:26,077] - step: [200/391], train_loss: 0.964 | train_acc: 69.262% | lr: 0.020000
[2020-03-03 09:02:26,599] - step: [300/391], train_loss: 0.960 | train_acc: 69.201% | lr: 0.020000
[2020-03-03 09:02:27,095] - --- cost time: 2.1510s ---
[2020-03-03 09:02:27,096] - *************** test ***************
[2020-03-03 09:02:27,616] - test_loss: 0.914 | test_acc: 71.190%
[2020-03-03 09:02:27,617] - ************************************

[2020-03-03 09:02:27,766] - ========== epoch: [36/50] ==========
[2020-03-03 09:02:28,381] - step: [100/391], train_loss: 0.950 | train_acc: 69.461% | lr: 0.020000
[2020-03-03 09:02:28,906] - step: [200/391], train_loss: 0.951 | train_acc: 69.668% | lr: 0.020000
[2020-03-03 09:02:41,999] - {'architecture': 'alexnet', 'ckpt_path': './', 'ckpt_name': 'alexnet', 'log_path': './', 'log_name': 'cifar10', 'log_color': {'train': 'blue', 'cost_time': 'yellow', 'time': 'purple', 'test': 'red'}, 'data_name': 'CIFAR10', 'num_classes': 10, 'train_set_path': './data/cifar-10', 'test_set_path': './data/cifar-10', 'augmentation': {'normalize': True, 'random_crop': True, 'random_horizontal_filp': True}, 'device': 'cuda', 'input_size': 32, 'batch_size': 128, 'num_epochs': 50, 'num_print': 100, 'num_workers': 4, 'eval_freq': 1, 'test_batch': 200, 'optimizer': {'name': 'SGD', 'params': {'lr': 0.02, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': True}}, 'lr_scheduler': {'type': 'STEP', 'lr_epochs': [40], 'lr_mults': 0.1}, 'learning_curve': {'style': 'ggplot', 'xtick_step': 5, 'draw_freq': 5, 'save_path': './'}}
AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace)
    (10): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace)
  )
  (classifier): Sequential(
    (0): Linear(in_features=1152, out_features=32, bias=True)
    (1): ReLU(inplace)
    (2): Dropout(p=0.5)
    (3): Linear(in_features=32, out_features=32, bias=True)
    (4): ReLU(inplace)
    (5): Dropout(p=0.5)
    (6): Linear(in_features=32, out_features=10, bias=True)
  )
)
-------------------- Training parameters: 1432970 --------------------
[2020-03-03 09:02:42,000] - ========== epoch: [36/50] ==========
[2020-03-03 09:02:42,777] - step: [100/391], train_loss: 0.969 | train_acc: 68.867% | lr: 0.020000
[2020-03-03 09:02:43,297] - step: [200/391], train_loss: 0.950 | train_acc: 69.758% | lr: 0.020000
[2020-03-03 09:02:43,816] - step: [300/391], train_loss: 0.959 | train_acc: 69.312% | lr: 0.020000
[2020-03-03 09:02:44,305] - --- cost time: 2.3053s ---
[2020-03-03 09:02:44,305] - *************** test ***************
[2020-03-03 09:02:44,830] - test_loss: 0.842 | test_acc: 73.260%
[2020-03-03 09:02:44,830] - ************************************

[2020-03-03 09:02:44,842] - ========== epoch: [37/50] ==========
[2020-03-03 09:02:45,443] - step: [100/391], train_loss: 0.942 | train_acc: 69.672% | lr: 0.020000
[2020-03-03 09:02:45,954] - step: [200/391], train_loss: 0.947 | train_acc: 69.453% | lr: 0.020000
[2020-03-03 09:02:46,467] - step: [300/391], train_loss: 0.954 | train_acc: 69.471% | lr: 0.020000
[2020-03-03 09:02:46,971] - --- cost time: 2.1288s ---
[2020-03-03 09:02:46,971] - *************** test ***************
[2020-03-03 09:02:47,511] - test_loss: 0.853 | test_acc: 71.760%
[2020-03-03 09:02:47,511] - ************************************

[2020-03-03 09:02:47,521] - ========== epoch: [38/50] ==========
[2020-03-03 09:02:48,128] - step: [100/391], train_loss: 0.945 | train_acc: 70.117% | lr: 0.020000
[2020-03-03 09:02:48,650] - step: [200/391], train_loss: 0.947 | train_acc: 69.957% | lr: 0.020000
[2020-03-03 09:02:49,174] - step: [300/391], train_loss: 0.947 | train_acc: 69.688% | lr: 0.020000
[2020-03-03 09:02:49,665] - --- cost time: 2.1436s ---
[2020-03-03 09:02:49,665] - *************** test ***************
[2020-03-03 09:02:50,181] - test_loss: 0.831 | test_acc: 73.860%
[2020-03-03 09:02:50,181] - ************************************

[2020-03-03 09:02:50,203] - ========== epoch: [39/50] ==========
[2020-03-03 09:02:50,804] - step: [100/391], train_loss: 0.954 | train_acc: 70.227% | lr: 0.020000
[2020-03-03 09:02:51,322] - step: [200/391], train_loss: 0.946 | train_acc: 70.176% | lr: 0.020000
[2020-03-03 09:02:51,843] - step: [300/391], train_loss: 0.952 | train_acc: 69.878% | lr: 0.020000
[2020-03-03 09:02:52,329] - --- cost time: 2.1260s ---
[2020-03-03 09:02:52,330] - *************** test ***************
[2020-03-03 09:02:52,843] - test_loss: 0.809 | test_acc: 75.110%
[2020-03-03 09:02:52,844] - ************************************

[2020-03-03 09:02:52,860] - ========== epoch: [40/50] ==========
[2020-03-03 09:02:53,464] - step: [100/391], train_loss: 0.845 | train_acc: 73.203% | lr: 0.002000
[2020-03-03 09:02:53,982] - step: [200/391], train_loss: 0.827 | train_acc: 73.566% | lr: 0.002000
[2020-03-03 09:02:54,502] - step: [300/391], train_loss: 0.813 | train_acc: 73.979% | lr: 0.002000
[2020-03-03 09:02:54,994] - --- cost time: 2.1335s ---
[2020-03-03 09:02:54,995] - *************** test ***************
[2020-03-03 09:02:55,511] - test_loss: 0.723 | test_acc: 77.560%
[2020-03-03 09:02:55,511] - ************************************

[2020-03-03 09:02:55,684] - ========== epoch: [41/50] ==========
[2020-03-03 09:02:56,294] - step: [100/391], train_loss: 0.778 | train_acc: 75.492% | lr: 0.002000
[2020-03-03 09:02:56,810] - step: [200/391], train_loss: 0.774 | train_acc: 75.410% | lr: 0.002000
[2020-03-03 09:02:57,325] - step: [300/391], train_loss: 0.770 | train_acc: 75.630% | lr: 0.002000
[2020-03-03 09:02:57,819] - --- cost time: 2.1346s ---
[2020-03-03 09:02:57,819] - *************** test ***************
[2020-03-03 09:02:58,342] - test_loss: 0.705 | test_acc: 77.760%
[2020-03-03 09:02:58,342] - ************************************

[2020-03-03 09:02:58,363] - ========== epoch: [42/50] ==========
[2020-03-03 09:02:58,966] - step: [100/391], train_loss: 0.765 | train_acc: 75.570% | lr: 0.002000
[2020-03-03 09:02:59,480] - step: [200/391], train_loss: 0.752 | train_acc: 76.152% | lr: 0.002000
[2020-03-03 09:03:00,002] - step: [300/391], train_loss: 0.750 | train_acc: 76.151% | lr: 0.002000
[2020-03-03 09:03:00,511] - --- cost time: 2.1470s ---
[2020-03-03 09:03:00,511] - *************** test ***************
[2020-03-03 09:03:01,035] - test_loss: 0.708 | test_acc: 77.940%
[2020-03-03 09:03:01,035] - ************************************

[2020-03-03 09:03:01,057] - ========== epoch: [43/50] ==========
[2020-03-03 09:03:01,663] - step: [100/391], train_loss: 0.751 | train_acc: 76.109% | lr: 0.002000
[2020-03-03 09:03:02,176] - step: [200/391], train_loss: 0.745 | train_acc: 76.551% | lr: 0.002000
[2020-03-03 09:03:02,695] - step: [300/391], train_loss: 0.741 | train_acc: 76.625% | lr: 0.002000
[2020-03-03 09:03:03,185] - --- cost time: 2.1278s ---
[2020-03-03 09:03:03,185] - *************** test ***************
[2020-03-03 09:03:03,708] - test_loss: 0.690 | test_acc: 78.740%
[2020-03-03 09:03:03,709] - ************************************

[2020-03-03 09:03:03,730] - ========== epoch: [44/50] ==========
[2020-03-03 09:03:04,333] - step: [100/391], train_loss: 0.713 | train_acc: 77.430% | lr: 0.002000
[2020-03-03 09:03:04,848] - step: [200/391], train_loss: 0.720 | train_acc: 77.223% | lr: 0.002000
[2020-03-03 09:03:05,365] - step: [300/391], train_loss: 0.728 | train_acc: 76.935% | lr: 0.002000
[2020-03-03 09:03:05,872] - --- cost time: 2.1418s ---
[2020-03-03 09:03:05,872] - *************** test ***************
[2020-03-03 09:03:06,391] - test_loss: 0.697 | test_acc: 78.710%
[2020-03-03 09:03:06,391] - ************************************

[2020-03-03 09:03:06,403] - ========== epoch: [45/50] ==========
[2020-03-03 09:03:07,002] - step: [100/391], train_loss: 0.712 | train_acc: 77.055% | lr: 0.002000
[2020-03-03 09:03:07,518] - step: [200/391], train_loss: 0.703 | train_acc: 77.320% | lr: 0.002000
[2020-03-03 09:03:08,033] - step: [300/391], train_loss: 0.709 | train_acc: 77.318% | lr: 0.002000
[2020-03-03 09:03:08,520] - --- cost time: 2.1164s ---
[2020-03-03 09:03:08,520] - *************** test ***************
[2020-03-03 09:03:09,041] - test_loss: 0.698 | test_acc: 78.880%
[2020-03-03 09:03:09,041] - ************************************

[2020-03-03 09:03:09,202] - ========== epoch: [46/50] ==========
[2020-03-03 09:03:09,812] - step: [100/391], train_loss: 0.701 | train_acc: 77.875% | lr: 0.002000
[2020-03-03 09:03:10,333] - step: [200/391], train_loss: 0.710 | train_acc: 77.523% | lr: 0.002000
[2020-03-03 09:03:10,856] - step: [300/391], train_loss: 0.710 | train_acc: 77.401% | lr: 0.002000
[2020-03-03 09:03:11,348] - --- cost time: 2.1457s ---
[2020-03-03 09:03:11,348] - *************** test ***************
[2020-03-03 09:03:11,909] - test_loss: 0.681 | test_acc: 79.330%
[2020-03-03 09:03:11,909] - ************************************

[2020-03-03 09:03:11,926] - ========== epoch: [47/50] ==========
[2020-03-03 09:03:12,534] - step: [100/391], train_loss: 0.700 | train_acc: 77.820% | lr: 0.002000
[2020-03-03 09:03:13,058] - step: [200/391], train_loss: 0.705 | train_acc: 77.641% | lr: 0.002000
[2020-03-03 09:03:13,578] - step: [300/391], train_loss: 0.707 | train_acc: 77.591% | lr: 0.002000
[2020-03-03 09:03:14,070] - --- cost time: 2.1438s ---
[2020-03-03 09:03:14,071] - *************** test ***************
[2020-03-03 09:03:14,602] - test_loss: 0.708 | test_acc: 77.940%
[2020-03-03 09:03:14,602] - ************************************

[2020-03-03 09:03:14,614] - ========== epoch: [48/50] ==========
[2020-03-03 09:03:15,217] - step: [100/391], train_loss: 0.687 | train_acc: 77.789% | lr: 0.002000
[2020-03-03 09:03:15,737] - step: [200/391], train_loss: 0.693 | train_acc: 77.773% | lr: 0.002000
[2020-03-03 09:03:16,257] - step: [300/391], train_loss: 0.695 | train_acc: 77.820% | lr: 0.002000
[2020-03-03 09:03:16,749] - --- cost time: 2.1346s ---
[2020-03-03 09:03:16,749] - *************** test ***************
[2020-03-03 09:03:17,278] - test_loss: 0.683 | test_acc: 79.180%
[2020-03-03 09:03:17,278] - ************************************

[2020-03-03 09:03:17,288] - ========== epoch: [49/50] ==========
[2020-03-03 09:03:17,891] - step: [100/391], train_loss: 0.689 | train_acc: 78.195% | lr: 0.002000
[2020-03-03 09:03:18,410] - step: [200/391], train_loss: 0.693 | train_acc: 77.926% | lr: 0.002000
[2020-03-03 09:03:18,928] - step: [300/391], train_loss: 0.695 | train_acc: 77.792% | lr: 0.002000
[2020-03-03 09:03:19,420] - --- cost time: 2.1321s ---
[2020-03-03 09:03:19,420] - *************** test ***************
[2020-03-03 09:03:19,942] - test_loss: 0.702 | test_acc: 78.750%
[2020-03-03 09:03:19,942] - ************************************

[2020-03-03 09:03:19,954] - ========== epoch: [50/50] ==========
[2020-03-03 09:03:20,567] - step: [100/391], train_loss: 0.688 | train_acc: 78.055% | lr: 0.002000
[2020-03-03 09:03:21,090] - step: [200/391], train_loss: 0.681 | train_acc: 78.230% | lr: 0.002000
[2020-03-03 09:03:21,614] - step: [300/391], train_loss: 0.688 | train_acc: 78.055% | lr: 0.002000
[2020-03-03 09:03:22,106] - --- cost time: 2.1517s ---
[2020-03-03 09:03:22,106] - *************** test ***************
[2020-03-03 09:03:22,626] - test_loss: 0.685 | test_acc: 79.090%
[2020-03-03 09:03:22,626] - ************************************

[2020-03-03 09:03:22,784] - Training Finished ==> best accuracy: 79.330%
[2020-03-03 09:05:12,647] - {'architecture': 'alexnet', 'ckpt_path': './', 'ckpt_name': 'alexnet', 'log_path': './', 'log_name': 'cifar10', 'log_color': {'train': 'blue', 'cost_time': 'yellow', 'time': 'purple', 'test': 'red'}, 'data_name': 'CIFAR10', 'num_classes': 10, 'train_set_path': './data/cifar-10', 'test_set_path': './data/cifar-10', 'augmentation': {'normalize': True, 'random_crop': True, 'random_horizontal_filp': True}, 'device': 'cuda', 'input_size': 32, 'batch_size': 128, 'num_epochs': 50, 'num_print': 100, 'num_workers': 4, 'eval_freq': 1, 'test_batch': 200, 'optimizer': {'name': 'SGD', 'params': {'lr': 0.02, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': True}}, 'lr_scheduler': {'type': 'STEP', 'lr_epochs': [40], 'lr_mults': 0.1}, 'learning_curve': {'style': 'ggplot', 'xtick_step': 5, 'draw_freq': 5, 'save_path': './'}}
AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace)
    (10): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace)
  )
  (classifier): Sequential(
    (0): Linear(in_features=1152, out_features=32, bias=True)
    (1): ReLU(inplace)
    (2): Dropout(p=0.5)
    (3): Linear(in_features=32, out_features=32, bias=True)
    (4): ReLU(inplace)
    (5): Dropout(p=0.5)
    (6): Linear(in_features=32, out_features=10, bias=True)
  )
)
-------------------- Training parameters: 1432970 --------------------
[2020-03-03 09:05:12,647] - Training Finished ==> best accuracy: 79.330%
[2020-03-03 09:08:16,588] - {'architecture': 'alexnet', 'ckpt_path': './', 'ckpt_name': 'alexnet', 'log_path': './', 'log_name': 'cifar10', 'log_color': {'train': 'blue', 'cost_time': 'yellow', 'time': 'purple', 'test': 'red'}, 'data_name': 'CIFAR10', 'num_classes': 10, 'train_set_path': './data/cifar-10', 'test_set_path': './data/cifar-10', 'augmentation': {'normalize': True, 'random_crop': True, 'random_horizontal_filp': True}, 'device': 'cuda', 'input_size': 32, 'batch_size': 128, 'num_epochs': 50, 'num_print': 100, 'num_workers': 4, 'eval_freq': 1, 'test_batch': 200, 'optimizer': {'name': 'SGD', 'params': {'lr': 0.02, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': True}}, 'lr_scheduler': {'type': 'STEP', 'lr_epochs': [40], 'lr_mults': 0.1}, 'learning_curve': {'style': 'ggplot', 'xtick_step': 5, 'draw_freq': 5, 'save_path': './'}}
AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace)
    (10): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace)
  )
  (classifier): Sequential(
    (0): Linear(in_features=1152, out_features=32, bias=True)
    (1): ReLU(inplace)
    (2): Dropout(p=0.5)
    (3): Linear(in_features=32, out_features=32, bias=True)
    (4): ReLU(inplace)
    (5): Dropout(p=0.5)
    (6): Linear(in_features=32, out_features=10, bias=True)
  )
)
-------------------- Training parameters: 1432970 --------------------
[2020-03-03 09:08:16,588] - Training Finished ==> best accuracy: 79.330%
