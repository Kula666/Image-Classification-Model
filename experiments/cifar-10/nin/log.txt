[2020-03-03 09:16:01,830] - {'architecture': 'nin', 'ckpt_path': './', 'ckpt_name': 'nin', 'log_path': './', 'log_name': 'cifar10', 'log_color': {'train': 'blue', 'cost_time': 'yellow', 'time': 'purple', 'test': 'red'}, 'data_name': 'CIFAR10', 'num_classes': 10, 'train_set_path': './data/cifar-10', 'test_set_path': './data/cifar-10', 'augmentation': {'normalize': True, 'random_crop': True, 'random_horizontal_filp': True}, 'device': 'cuda', 'input_size': 32, 'batch_size': 128, 'num_epochs': 50, 'num_print': 100, 'num_workers': 4, 'eval_freq': 1, 'test_batch': 200, 'optimizer': {'name': 'Adam', 'params': {'lr': 0.002}}, 'lr_scheduler': {'type': 'STEP', 'lr_epochs': [20, 40], 'lr_mults': 0.1}, 'learning_curve': {'style': 'ggplot', 'xtick_step': 5, 'draw_freq': 10, 'save_path': './'}}
NiN(
  (features): Sequential(
    (0): Sequential(
      (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2))
      (1): ReLU(inplace)
      (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU(inplace)
      (4): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
      (5): ReLU(inplace)
    )
    (1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (2): Sequential(
      (0): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
      (1): ReLU(inplace)
      (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU(inplace)
      (4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (5): ReLU(inplace)
    )
    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Sequential(
      (0): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace)
      (2): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU(inplace)
      (4): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
      (5): ReLU(inplace)
    )
    (5): Dropout(p=0.5)
    (6): Sequential(
      (0): Conv2d(384, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace)
      (2): Conv2d(10, 10, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU(inplace)
      (4): Conv2d(10, 10, kernel_size=(1, 1), stride=(1, 1))
      (5): ReLU(inplace)
    )
  )
  (classifier): AdaptiveAvgPool2d(output_size=(1, 1))
)
-------------------- Training parameters: 1994662 --------------------
[2020-03-03 09:16:01,830] - ========== epoch: [1/50] ==========
[2020-03-03 09:16:02,970] - step: [100/391], train_loss: 2.288 | train_acc: 14.320% | lr: 0.002000
[2020-03-03 09:16:03,811] - step: [200/391], train_loss: 2.231 | train_acc: 15.980% | lr: 0.002000
[2020-03-03 09:16:04,653] - step: [300/391], train_loss: 2.171 | train_acc: 16.898% | lr: 0.002000
[2020-03-03 09:16:05,430] - --- cost time: 3.5996s ---
[2020-03-03 09:16:05,430] - *************** test ***************
[2020-03-03 09:16:05,954] - test_loss: 2.006 | test_acc: 22.510%
[2020-03-03 09:16:05,954] - ************************************

[2020-03-03 09:16:05,982] - ========== epoch: [2/50] ==========
[2020-03-03 09:16:06,906] - step: [100/391], train_loss: 1.973 | train_acc: 22.852% | lr: 0.002000
[2020-03-03 09:16:07,740] - step: [200/391], train_loss: 1.961 | train_acc: 24.477% | lr: 0.002000
[2020-03-03 09:16:08,576] - step: [300/391], train_loss: 1.944 | train_acc: 25.518% | lr: 0.002000
[2020-03-03 09:16:09,349] - --- cost time: 3.3667s ---
[2020-03-03 09:16:09,349] - *************** test ***************
[2020-03-03 09:16:09,869] - test_loss: 1.869 | test_acc: 31.000%
[2020-03-03 09:16:09,869] - ************************************

[2020-03-03 09:16:09,921] - ========== epoch: [3/50] ==========
[2020-03-03 09:16:10,863] - step: [100/391], train_loss: 1.829 | train_acc: 32.305% | lr: 0.002000
[2020-03-03 09:16:11,721] - step: [200/391], train_loss: 1.829 | train_acc: 32.477% | lr: 0.002000
[2020-03-03 09:16:12,565] - step: [300/391], train_loss: 1.822 | train_acc: 32.940% | lr: 0.002000
[2020-03-03 09:16:13,360] - --- cost time: 3.4385s ---
[2020-03-03 09:16:13,360] - *************** test ***************
[2020-03-03 09:16:13,876] - test_loss: 1.753 | test_acc: 37.810%
[2020-03-03 09:16:13,876] - ************************************

[2020-03-03 09:16:13,922] - ========== epoch: [4/50] ==========
[2020-03-03 09:16:14,843] - step: [100/391], train_loss: 1.762 | train_acc: 35.680% | lr: 0.002000
[2020-03-03 09:16:15,681] - step: [200/391], train_loss: 1.742 | train_acc: 37.047% | lr: 0.002000
[2020-03-03 09:16:16,516] - step: [300/391], train_loss: 1.723 | train_acc: 37.901% | lr: 0.002000
[2020-03-03 09:16:17,306] - --- cost time: 3.3834s ---
[2020-03-03 09:16:17,306] - *************** test ***************
[2020-03-03 09:16:17,830] - test_loss: 1.627 | test_acc: 42.720%
[2020-03-03 09:16:17,830] - ************************************

[2020-03-03 09:16:17,876] - ========== epoch: [5/50] ==========
[2020-03-03 09:16:18,799] - step: [100/391], train_loss: 1.622 | train_acc: 42.688% | lr: 0.002000
[2020-03-03 09:16:19,634] - step: [200/391], train_loss: 1.618 | train_acc: 43.008% | lr: 0.002000
[2020-03-03 09:16:20,471] - step: [300/391], train_loss: 1.598 | train_acc: 43.503% | lr: 0.002000
[2020-03-03 09:16:21,251] - --- cost time: 3.3746s ---
[2020-03-03 09:16:21,251] - *************** test ***************
[2020-03-03 09:16:21,808] - test_loss: 1.568 | test_acc: 46.460%
[2020-03-03 09:16:21,808] - ************************************

[2020-03-03 09:16:21,873] - ========== epoch: [6/50] ==========
[2020-03-03 09:16:22,802] - step: [100/391], train_loss: 1.542 | train_acc: 46.062% | lr: 0.002000
[2020-03-03 09:16:23,639] - step: [200/391], train_loss: 1.519 | train_acc: 46.586% | lr: 0.002000
[2020-03-03 09:16:24,489] - step: [300/391], train_loss: 1.507 | train_acc: 47.159% | lr: 0.002000
[2020-03-03 09:16:25,287] - --- cost time: 3.4143s ---
[2020-03-03 09:16:25,288] - *************** test ***************
[2020-03-03 09:16:25,817] - test_loss: 1.435 | test_acc: 48.350%
[2020-03-03 09:16:25,817] - ************************************

[2020-03-03 09:16:25,864] - ========== epoch: [7/50] ==========
[2020-03-03 09:16:26,823] - step: [100/391], train_loss: 1.449 | train_acc: 49.328% | lr: 0.002000
[2020-03-03 09:16:27,688] - step: [200/391], train_loss: 1.445 | train_acc: 49.414% | lr: 0.002000
[2020-03-03 09:16:28,542] - step: [300/391], train_loss: 1.433 | train_acc: 49.794% | lr: 0.002000
[2020-03-03 09:16:29,358] - --- cost time: 3.4942s ---
[2020-03-03 09:16:29,359] - *************** test ***************
[2020-03-03 09:16:29,877] - test_loss: 1.380 | test_acc: 51.820%
[2020-03-03 09:16:29,877] - ************************************

[2020-03-03 09:16:29,928] - ========== epoch: [8/50] ==========
[2020-03-03 09:16:30,878] - step: [100/391], train_loss: 1.380 | train_acc: 51.430% | lr: 0.002000
[2020-03-03 09:16:31,744] - step: [200/391], train_loss: 1.377 | train_acc: 51.656% | lr: 0.002000
[2020-03-03 09:16:32,589] - step: [300/391], train_loss: 1.374 | train_acc: 51.878% | lr: 0.002000
[2020-03-03 09:16:33,375] - --- cost time: 3.4463s ---
[2020-03-03 09:16:33,375] - *************** test ***************
[2020-03-03 09:16:33,893] - test_loss: 1.353 | test_acc: 53.560%
[2020-03-03 09:16:33,893] - ************************************

[2020-03-03 09:16:33,940] - ========== epoch: [9/50] ==========
[2020-03-03 09:16:34,878] - step: [100/391], train_loss: 1.326 | train_acc: 53.547% | lr: 0.002000
[2020-03-03 09:16:35,721] - step: [200/391], train_loss: 1.318 | train_acc: 54.066% | lr: 0.002000
[2020-03-03 09:16:36,580] - step: [300/391], train_loss: 1.320 | train_acc: 54.091% | lr: 0.002000
[2020-03-03 09:16:37,390] - --- cost time: 3.4490s ---
[2020-03-03 09:16:37,390] - *************** test ***************
[2020-03-03 09:16:37,924] - test_loss: 1.294 | test_acc: 54.650%
[2020-03-03 09:16:37,924] - ************************************

[2020-03-03 09:16:37,970] - ========== epoch: [10/50] ==========
[2020-03-03 09:16:38,925] - step: [100/391], train_loss: 1.277 | train_acc: 55.781% | lr: 0.002000
[2020-03-03 09:16:39,815] - step: [200/391], train_loss: 1.261 | train_acc: 56.527% | lr: 0.002000
[2020-03-03 09:16:40,723] - step: [300/391], train_loss: 1.215 | train_acc: 58.250% | lr: 0.002000
[2020-03-03 09:16:41,580] - --- cost time: 3.6090s ---
[2020-03-03 09:16:41,580] - *************** test ***************
[2020-03-03 09:16:42,104] - test_loss: 1.107 | test_acc: 61.830%
[2020-03-03 09:16:42,104] - ************************************

[2020-03-03 09:16:42,293] - ========== epoch: [11/50] ==========
[2020-03-03 09:16:43,260] - step: [100/391], train_loss: 1.089 | train_acc: 62.578% | lr: 0.002000
[2020-03-03 09:16:44,147] - step: [200/391], train_loss: 1.089 | train_acc: 62.375% | lr: 0.002000
[2020-03-03 09:16:45,005] - step: [300/391], train_loss: 1.084 | train_acc: 62.503% | lr: 0.002000
[2020-03-03 09:16:45,789] - --- cost time: 3.4962s ---
[2020-03-03 09:16:45,790] - *************** test ***************
[2020-03-03 09:16:46,320] - test_loss: 1.092 | test_acc: 62.500%
[2020-03-03 09:16:46,320] - ************************************

[2020-03-03 09:16:46,364] - ========== epoch: [12/50] ==========
[2020-03-03 09:16:47,327] - step: [100/391], train_loss: 1.041 | train_acc: 63.383% | lr: 0.002000
[2020-03-03 09:16:48,181] - step: [200/391], train_loss: 1.040 | train_acc: 63.941% | lr: 0.002000
[2020-03-03 09:16:49,088] - step: [300/391], train_loss: 1.039 | train_acc: 64.174% | lr: 0.002000
[2020-03-03 09:16:49,955] - --- cost time: 3.5908s ---
[2020-03-03 09:16:49,956] - *************** test ***************
[2020-03-03 09:16:50,490] - test_loss: 1.065 | test_acc: 63.620%
[2020-03-03 09:16:50,490] - ************************************

[2020-03-03 09:16:50,537] - ========== epoch: [13/50] ==========
[2020-03-03 09:16:51,530] - step: [100/391], train_loss: 1.009 | train_acc: 65.250% | lr: 0.002000
[2020-03-03 09:16:52,425] - step: [200/391], train_loss: 1.006 | train_acc: 65.512% | lr: 0.002000
[2020-03-03 09:16:53,306] - step: [300/391], train_loss: 1.013 | train_acc: 65.172% | lr: 0.002000
[2020-03-03 09:16:54,199] - --- cost time: 3.6611s ---
[2020-03-03 09:16:54,199] - *************** test ***************
[2020-03-03 09:16:54,745] - test_loss: 1.048 | test_acc: 64.410%
[2020-03-03 09:16:54,745] - ************************************

[2020-03-03 09:16:54,819] - ========== epoch: [14/50] ==========
[2020-03-03 09:16:55,752] - step: [100/391], train_loss: 0.985 | train_acc: 66.266% | lr: 0.002000
[2020-03-03 09:16:56,601] - step: [200/391], train_loss: 0.987 | train_acc: 66.211% | lr: 0.002000
[2020-03-03 09:16:57,526] - step: [300/391], train_loss: 0.982 | train_acc: 66.320% | lr: 0.002000
[2020-03-03 09:16:58,381] - --- cost time: 3.5613s ---
[2020-03-03 09:16:58,381] - *************** test ***************
[2020-03-03 09:16:58,912] - test_loss: 0.993 | test_acc: 66.410%
[2020-03-03 09:16:58,912] - ************************************

[2020-03-03 09:16:58,958] - ========== epoch: [15/50] ==========
[2020-03-03 09:16:59,886] - step: [100/391], train_loss: 0.947 | train_acc: 67.625% | lr: 0.002000
[2020-03-03 09:17:00,725] - step: [200/391], train_loss: 0.953 | train_acc: 67.527% | lr: 0.002000
[2020-03-03 09:17:01,587] - step: [300/391], train_loss: 0.951 | train_acc: 67.521% | lr: 0.002000
[2020-03-03 09:17:02,369] - --- cost time: 3.4101s ---
[2020-03-03 09:17:02,369] - *************** test ***************
[2020-03-03 09:17:02,902] - test_loss: 0.989 | test_acc: 66.590%
[2020-03-03 09:17:02,902] - ************************************

[2020-03-03 09:17:02,948] - ========== epoch: [16/50] ==========
[2020-03-03 09:17:03,972] - step: [100/391], train_loss: 0.935 | train_acc: 67.516% | lr: 0.002000
[2020-03-03 09:17:05,008] - step: [200/391], train_loss: 0.936 | train_acc: 68.250% | lr: 0.002000
[2020-03-03 09:17:05,882] - step: [300/391], train_loss: 0.938 | train_acc: 67.883% | lr: 0.002000
[2020-03-03 09:17:06,672] - --- cost time: 3.7238s ---
[2020-03-03 09:17:06,673] - *************** test ***************
[2020-03-03 09:17:07,210] - test_loss: 0.983 | test_acc: 66.900%
[2020-03-03 09:17:07,210] - ************************************

[2020-03-03 09:17:07,279] - ========== epoch: [17/50] ==========
[2020-03-03 09:17:08,226] - step: [100/391], train_loss: 0.892 | train_acc: 69.562% | lr: 0.002000
[2020-03-03 09:17:09,091] - step: [200/391], train_loss: 0.912 | train_acc: 69.047% | lr: 0.002000
[2020-03-03 09:17:09,952] - step: [300/391], train_loss: 0.907 | train_acc: 69.122% | lr: 0.002000
[2020-03-03 09:17:10,742] - --- cost time: 3.4621s ---
[2020-03-03 09:17:10,742] - *************** test ***************
[2020-03-03 09:17:11,310] - test_loss: 0.938 | test_acc: 68.040%
[2020-03-03 09:17:11,310] - ************************************

[2020-03-03 09:17:11,356] - ========== epoch: [18/50] ==========
[2020-03-03 09:17:12,293] - step: [100/391], train_loss: 0.890 | train_acc: 69.516% | lr: 0.002000
[2020-03-03 09:17:13,140] - step: [200/391], train_loss: 0.885 | train_acc: 70.066% | lr: 0.002000
[2020-03-03 09:17:13,988] - step: [300/391], train_loss: 0.892 | train_acc: 69.688% | lr: 0.002000
[2020-03-03 09:17:14,786] - --- cost time: 3.4300s ---
[2020-03-03 09:17:14,787] - *************** test ***************
[2020-03-03 09:17:15,310] - test_loss: 0.974 | test_acc: 67.440%
[2020-03-03 09:17:15,311] - ************************************

[2020-03-03 09:17:15,335] - ========== epoch: [19/50] ==========
[2020-03-03 09:17:16,269] - step: [100/391], train_loss: 0.877 | train_acc: 70.344% | lr: 0.002000
[2020-03-03 09:17:17,118] - step: [200/391], train_loss: 0.884 | train_acc: 70.328% | lr: 0.002000
[2020-03-03 09:17:17,966] - step: [300/391], train_loss: 0.886 | train_acc: 70.076% | lr: 0.002000
[2020-03-03 09:17:18,752] - --- cost time: 3.4173s ---
[2020-03-03 09:17:18,753] - *************** test ***************
[2020-03-03 09:17:19,274] - test_loss: 0.926 | test_acc: 68.840%
[2020-03-03 09:17:19,274] - ************************************

[2020-03-03 09:17:19,327] - ========== epoch: [20/50] ==========
[2020-03-03 09:17:20,279] - step: [100/391], train_loss: 0.815 | train_acc: 72.102% | lr: 0.000200
[2020-03-03 09:17:21,126] - step: [200/391], train_loss: 0.792 | train_acc: 73.039% | lr: 0.000200
[2020-03-03 09:17:21,973] - step: [300/391], train_loss: 0.781 | train_acc: 73.286% | lr: 0.000200
[2020-03-03 09:17:22,757] - --- cost time: 3.4289s ---
[2020-03-03 09:17:22,757] - *************** test ***************
[2020-03-03 09:17:23,276] - test_loss: 0.830 | test_acc: 72.030%
[2020-03-03 09:17:23,276] - ************************************

[2020-03-03 09:17:23,451] - ========== epoch: [21/50] ==========
[2020-03-03 09:17:24,391] - step: [100/391], train_loss: 0.756 | train_acc: 74.141% | lr: 0.000200
[2020-03-03 09:17:25,239] - step: [200/391], train_loss: 0.754 | train_acc: 74.238% | lr: 0.000200
[2020-03-03 09:17:26,089] - step: [300/391], train_loss: 0.755 | train_acc: 74.138% | lr: 0.000200
[2020-03-03 09:17:26,880] - --- cost time: 3.4282s ---
[2020-03-03 09:17:26,880] - *************** test ***************
[2020-03-03 09:17:27,413] - test_loss: 0.839 | test_acc: 72.200%
[2020-03-03 09:17:27,413] - ************************************

[2020-03-03 09:17:27,457] - ========== epoch: [22/50] ==========
[2020-03-03 09:17:28,395] - step: [100/391], train_loss: 0.729 | train_acc: 74.531% | lr: 0.000200
[2020-03-03 09:17:29,246] - step: [200/391], train_loss: 0.736 | train_acc: 74.578% | lr: 0.000200
[2020-03-03 09:17:30,095] - step: [300/391], train_loss: 0.739 | train_acc: 74.573% | lr: 0.000200
[2020-03-03 09:17:30,884] - --- cost time: 3.4270s ---
[2020-03-03 09:17:30,885] - *************** test ***************
[2020-03-03 09:17:31,408] - test_loss: 0.818 | test_acc: 72.170%
[2020-03-03 09:17:31,408] - ************************************

[2020-03-03 09:17:31,438] - ========== epoch: [23/50] ==========
[2020-03-03 09:17:32,402] - step: [100/391], train_loss: 0.743 | train_acc: 74.516% | lr: 0.000200
[2020-03-03 09:17:33,250] - step: [200/391], train_loss: 0.739 | train_acc: 74.867% | lr: 0.000200
[2020-03-03 09:17:34,098] - step: [300/391], train_loss: 0.736 | train_acc: 74.846% | lr: 0.000200
[2020-03-03 09:17:34,888] - --- cost time: 3.4476s ---
[2020-03-03 09:17:34,888] - *************** test ***************
[2020-03-03 09:17:35,419] - test_loss: 0.807 | test_acc: 72.540%
[2020-03-03 09:17:35,419] - ************************************

[2020-03-03 09:17:35,465] - ========== epoch: [24/50] ==========
[2020-03-03 09:17:36,401] - step: [100/391], train_loss: 0.715 | train_acc: 75.523% | lr: 0.000200
[2020-03-03 09:17:37,247] - step: [200/391], train_loss: 0.724 | train_acc: 74.992% | lr: 0.000200
[2020-03-03 09:17:38,095] - step: [300/391], train_loss: 0.724 | train_acc: 75.086% | lr: 0.000200
[2020-03-03 09:17:38,889] - --- cost time: 3.4239s ---
[2020-03-03 09:17:38,889] - *************** test ***************
[2020-03-03 09:17:39,422] - test_loss: 0.821 | test_acc: 72.610%
[2020-03-03 09:17:39,422] - ************************************

[2020-03-03 09:17:39,468] - ========== epoch: [25/50] ==========
[2020-03-03 09:17:40,403] - step: [100/391], train_loss: 0.712 | train_acc: 75.852% | lr: 0.000200
[2020-03-03 09:17:41,251] - step: [200/391], train_loss: 0.717 | train_acc: 75.555% | lr: 0.000200
[2020-03-03 09:17:42,100] - step: [300/391], train_loss: 0.718 | train_acc: 75.401% | lr: 0.000200
[2020-03-03 09:17:42,890] - --- cost time: 3.4219s ---
[2020-03-03 09:17:42,891] - *************** test ***************
[2020-03-03 09:17:43,414] - test_loss: 0.809 | test_acc: 72.870%
[2020-03-03 09:17:43,414] - ************************************

[2020-03-03 09:17:43,467] - ========== epoch: [26/50] ==========
[2020-03-03 09:17:44,422] - step: [100/391], train_loss: 0.711 | train_acc: 75.688% | lr: 0.000200
[2020-03-03 09:17:45,284] - step: [200/391], train_loss: 0.706 | train_acc: 75.738% | lr: 0.000200
[2020-03-03 09:17:46,146] - step: [300/391], train_loss: 0.707 | train_acc: 75.755% | lr: 0.000200
[2020-03-03 09:17:46,939] - --- cost time: 3.4708s ---
[2020-03-03 09:17:46,939] - *************** test ***************
[2020-03-03 09:17:47,471] - test_loss: 0.799 | test_acc: 73.910%
[2020-03-03 09:17:47,471] - ************************************

[2020-03-03 09:17:47,515] - ========== epoch: [27/50] ==========
[2020-03-03 09:17:48,451] - step: [100/391], train_loss: 0.706 | train_acc: 75.461% | lr: 0.000200
[2020-03-03 09:17:49,299] - step: [200/391], train_loss: 0.702 | train_acc: 75.773% | lr: 0.000200
[2020-03-03 09:17:50,147] - step: [300/391], train_loss: 0.707 | train_acc: 75.698% | lr: 0.000200
[2020-03-03 09:17:50,938] - --- cost time: 3.4230s ---
[2020-03-03 09:17:50,938] - *************** test ***************
[2020-03-03 09:17:51,460] - test_loss: 0.788 | test_acc: 73.730%
[2020-03-03 09:17:51,460] - ************************************

[2020-03-03 09:17:51,485] - ========== epoch: [28/50] ==========
[2020-03-03 09:17:52,424] - step: [100/391], train_loss: 0.701 | train_acc: 76.047% | lr: 0.000200
[2020-03-03 09:17:53,272] - step: [200/391], train_loss: 0.697 | train_acc: 76.250% | lr: 0.000200
[2020-03-03 09:17:54,122] - step: [300/391], train_loss: 0.699 | train_acc: 76.036% | lr: 0.000200
[2020-03-03 09:17:54,912] - --- cost time: 3.4268s ---
[2020-03-03 09:17:54,913] - *************** test ***************
[2020-03-03 09:17:55,437] - test_loss: 0.795 | test_acc: 73.600%
[2020-03-03 09:17:55,437] - ************************************

[2020-03-03 09:17:55,462] - ========== epoch: [29/50] ==========
[2020-03-03 09:17:56,399] - step: [100/391], train_loss: 0.691 | train_acc: 76.180% | lr: 0.000200
[2020-03-03 09:17:57,248] - step: [200/391], train_loss: 0.687 | train_acc: 76.473% | lr: 0.000200
[2020-03-03 09:17:58,096] - step: [300/391], train_loss: 0.691 | train_acc: 76.367% | lr: 0.000200
[2020-03-03 09:17:58,884] - --- cost time: 3.4220s ---
[2020-03-03 09:17:58,884] - *************** test ***************
[2020-03-03 09:17:59,415] - test_loss: 0.801 | test_acc: 73.810%
[2020-03-03 09:17:59,415] - ************************************

[2020-03-03 09:17:59,446] - ========== epoch: [30/50] ==========
[2020-03-03 09:18:00,413] - step: [100/391], train_loss: 0.688 | train_acc: 76.352% | lr: 0.000200
[2020-03-03 09:18:01,261] - step: [200/391], train_loss: 0.682 | train_acc: 76.488% | lr: 0.000200
[2020-03-03 09:18:02,107] - step: [300/391], train_loss: 0.689 | train_acc: 76.214% | lr: 0.000200
[2020-03-03 09:18:02,894] - --- cost time: 3.4472s ---
[2020-03-03 09:18:02,895] - *************** test ***************
[2020-03-03 09:18:03,425] - test_loss: 0.788 | test_acc: 73.570%
[2020-03-03 09:18:03,425] - ************************************

[2020-03-03 09:18:03,585] - ========== epoch: [31/50] ==========
[2020-03-03 09:18:04,527] - step: [100/391], train_loss: 0.691 | train_acc: 76.500% | lr: 0.000200
[2020-03-03 09:18:05,374] - step: [200/391], train_loss: 0.679 | train_acc: 77.082% | lr: 0.000200
[2020-03-03 09:18:06,221] - step: [300/391], train_loss: 0.688 | train_acc: 76.661% | lr: 0.000200
[2020-03-03 09:18:07,009] - --- cost time: 3.4231s ---
[2020-03-03 09:18:07,009] - *************** test ***************
[2020-03-03 09:18:07,538] - test_loss: 0.784 | test_acc: 73.570%
[2020-03-03 09:18:07,538] - ************************************

[2020-03-03 09:18:07,564] - ========== epoch: [32/50] ==========
[2020-03-03 09:18:08,499] - step: [100/391], train_loss: 0.680 | train_acc: 76.633% | lr: 0.000200
[2020-03-03 09:18:09,347] - step: [200/391], train_loss: 0.682 | train_acc: 76.738% | lr: 0.000200
[2020-03-03 09:18:10,195] - step: [300/391], train_loss: 0.680 | train_acc: 76.763% | lr: 0.000200
[2020-03-03 09:18:10,983] - --- cost time: 3.4191s ---
[2020-03-03 09:18:10,983] - *************** test ***************
[2020-03-03 09:18:11,523] - test_loss: 0.777 | test_acc: 73.860%
[2020-03-03 09:18:11,523] - ************************************

[2020-03-03 09:18:11,549] - ========== epoch: [33/50] ==========
[2020-03-03 09:18:12,485] - step: [100/391], train_loss: 0.666 | train_acc: 77.188% | lr: 0.000200
[2020-03-03 09:18:13,333] - step: [200/391], train_loss: 0.673 | train_acc: 76.949% | lr: 0.000200
[2020-03-03 09:18:14,191] - step: [300/391], train_loss: 0.678 | train_acc: 76.815% | lr: 0.000200
[2020-03-03 09:18:36,272] - {'architecture': 'nin', 'ckpt_path': './', 'ckpt_name': 'nin', 'log_path': './', 'log_name': 'cifar10', 'log_color': {'train': 'blue', 'cost_time': 'yellow', 'time': 'purple', 'test': 'red'}, 'data_name': 'CIFAR10', 'num_classes': 10, 'train_set_path': './data/cifar-10', 'test_set_path': './data/cifar-10', 'augmentation': {'normalize': True, 'random_crop': True, 'random_horizontal_filp': True}, 'device': 'cuda', 'input_size': 32, 'batch_size': 128, 'num_epochs': 50, 'num_print': 100, 'num_workers': 4, 'eval_freq': 1, 'test_batch': 200, 'optimizer': {'name': 'Adam', 'params': {'lr': 0.002}}, 'lr_scheduler': {'type': 'STEP', 'lr_epochs': [40], 'lr_mults': 0.1}, 'learning_curve': {'style': 'ggplot', 'xtick_step': 5, 'draw_freq': 10, 'save_path': './'}}
NiN(
  (features): Sequential(
    (0): Sequential(
      (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2))
      (1): ReLU(inplace)
      (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU(inplace)
      (4): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
      (5): ReLU(inplace)
    )
    (1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (2): Sequential(
      (0): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
      (1): ReLU(inplace)
      (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU(inplace)
      (4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (5): ReLU(inplace)
    )
    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Sequential(
      (0): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace)
      (2): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU(inplace)
      (4): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
      (5): ReLU(inplace)
    )
    (5): Dropout(p=0.5)
    (6): Sequential(
      (0): Conv2d(384, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace)
      (2): Conv2d(10, 10, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU(inplace)
      (4): Conv2d(10, 10, kernel_size=(1, 1), stride=(1, 1))
      (5): ReLU(inplace)
    )
  )
  (classifier): AdaptiveAvgPool2d(output_size=(1, 1))
)
-------------------- Training parameters: 1994662 --------------------
[2020-03-03 09:18:36,272] - ========== epoch: [1/50] ==========
[2020-03-03 09:18:37,452] - step: [100/391], train_loss: 2.285 | train_acc: 12.180% | lr: 0.002000
[2020-03-03 09:18:38,310] - step: [200/391], train_loss: 2.199 | train_acc: 15.910% | lr: 0.002000
[2020-03-03 09:18:39,155] - step: [300/391], train_loss: 2.141 | train_acc: 18.586% | lr: 0.002000
[2020-03-03 09:18:39,939] - --- cost time: 3.6662s ---
[2020-03-03 09:18:39,939] - *************** test ***************
[2020-03-03 09:18:40,459] - test_loss: 1.951 | test_acc: 27.290%
[2020-03-03 09:18:40,459] - ************************************

[2020-03-03 09:18:40,512] - ========== epoch: [2/50] ==========
[2020-03-03 09:18:41,437] - step: [100/391], train_loss: 1.953 | train_acc: 28.250% | lr: 0.002000
[2020-03-03 09:18:42,277] - step: [200/391], train_loss: 1.933 | train_acc: 29.469% | lr: 0.002000
[2020-03-03 09:18:43,119] - step: [300/391], train_loss: 1.914 | train_acc: 30.716% | lr: 0.002000
[2020-03-03 09:18:43,904] - --- cost time: 3.3919s ---
[2020-03-03 09:18:43,904] - *************** test ***************
[2020-03-03 09:18:44,433] - test_loss: 1.858 | test_acc: 35.480%
[2020-03-03 09:18:44,433] - ************************************

[2020-03-03 09:18:44,478] - ========== epoch: [3/50] ==========
[2020-03-03 09:18:45,403] - step: [100/391], train_loss: 1.824 | train_acc: 35.422% | lr: 0.002000
[2020-03-03 09:18:46,247] - step: [200/391], train_loss: 1.810 | train_acc: 35.848% | lr: 0.002000
[2020-03-03 09:18:47,089] - step: [300/391], train_loss: 1.789 | train_acc: 36.693% | lr: 0.002000
[2020-03-03 09:18:47,873] - --- cost time: 3.3942s ---
[2020-03-03 09:18:47,873] - *************** test ***************
[2020-03-03 09:18:48,396] - test_loss: 1.648 | test_acc: 38.960%
[2020-03-03 09:18:48,396] - ************************************

[2020-03-03 09:18:48,443] - ========== epoch: [4/50] ==========
[2020-03-03 09:18:49,370] - step: [100/391], train_loss: 1.634 | train_acc: 41.336% | lr: 0.002000
[2020-03-03 09:18:50,208] - step: [200/391], train_loss: 1.603 | train_acc: 42.355% | lr: 0.002000
[2020-03-03 09:18:51,049] - step: [300/391], train_loss: 1.576 | train_acc: 43.404% | lr: 0.002000
[2020-03-03 09:18:51,833] - --- cost time: 3.3900s ---
[2020-03-03 09:18:51,833] - *************** test ***************
[2020-03-03 09:18:52,351] - test_loss: 1.391 | test_acc: 50.280%
[2020-03-03 09:18:52,352] - ************************************

[2020-03-03 09:18:52,398] - ========== epoch: [5/50] ==========
[2020-03-03 09:18:53,325] - step: [100/391], train_loss: 1.381 | train_acc: 50.133% | lr: 0.002000
[2020-03-03 09:18:54,171] - step: [200/391], train_loss: 1.361 | train_acc: 51.230% | lr: 0.002000
[2020-03-03 09:18:55,017] - step: [300/391], train_loss: 1.336 | train_acc: 52.255% | lr: 0.002000
[2020-03-03 09:18:55,799] - --- cost time: 3.4010s ---
[2020-03-03 09:18:55,800] - *************** test ***************
[2020-03-03 09:18:56,349] - test_loss: 1.244 | test_acc: 56.370%
[2020-03-03 09:18:56,350] - ************************************

[2020-03-03 09:18:56,394] - ========== epoch: [6/50] ==========
[2020-03-03 09:18:57,323] - step: [100/391], train_loss: 1.226 | train_acc: 56.977% | lr: 0.002000
[2020-03-03 09:18:58,166] - step: [200/391], train_loss: 1.229 | train_acc: 57.227% | lr: 0.002000
[2020-03-03 09:18:59,008] - step: [300/391], train_loss: 1.223 | train_acc: 57.221% | lr: 0.002000
[2020-03-03 09:18:59,793] - --- cost time: 3.3989s ---
[2020-03-03 09:18:59,793] - *************** test ***************
[2020-03-03 09:19:00,319] - test_loss: 1.219 | test_acc: 59.200%
[2020-03-03 09:19:00,319] - ************************************

[2020-03-03 09:19:00,365] - ========== epoch: [7/50] ==========
[2020-03-03 09:19:01,295] - step: [100/391], train_loss: 1.149 | train_acc: 60.102% | lr: 0.002000
[2020-03-03 09:19:02,136] - step: [200/391], train_loss: 1.143 | train_acc: 60.324% | lr: 0.002000
[2020-03-03 09:19:02,979] - step: [300/391], train_loss: 1.139 | train_acc: 60.526% | lr: 0.002000
[2020-03-03 09:19:03,764] - --- cost time: 3.3982s ---
[2020-03-03 09:19:03,764] - *************** test ***************
[2020-03-03 09:19:04,284] - test_loss: 1.116 | test_acc: 62.460%
[2020-03-03 09:19:04,285] - ************************************

[2020-03-03 09:19:04,356] - ========== epoch: [8/50] ==========
[2020-03-03 09:19:05,284] - step: [100/391], train_loss: 1.074 | train_acc: 62.813% | lr: 0.002000
[2020-03-03 09:19:06,126] - step: [200/391], train_loss: 1.082 | train_acc: 62.676% | lr: 0.002000
[2020-03-03 09:19:06,969] - step: [300/391], train_loss: 1.082 | train_acc: 62.367% | lr: 0.002000
[2020-03-03 09:19:07,755] - --- cost time: 3.3987s ---
[2020-03-03 09:19:07,755] - *************** test ***************
[2020-03-03 09:19:08,274] - test_loss: 1.106 | test_acc: 62.570%
[2020-03-03 09:19:08,275] - ************************************

[2020-03-03 09:19:08,321] - ========== epoch: [9/50] ==========
[2020-03-03 09:19:09,251] - step: [100/391], train_loss: 1.039 | train_acc: 64.602% | lr: 0.002000
[2020-03-03 09:19:10,093] - step: [200/391], train_loss: 1.025 | train_acc: 65.023% | lr: 0.002000
[2020-03-03 09:19:10,937] - step: [300/391], train_loss: 1.021 | train_acc: 64.961% | lr: 0.002000
[2020-03-03 09:19:11,720] - --- cost time: 3.3979s ---
[2020-03-03 09:19:11,720] - *************** test ***************
[2020-03-03 09:19:12,244] - test_loss: 1.000 | test_acc: 65.630%
[2020-03-03 09:19:12,245] - ************************************

[2020-03-03 09:19:12,291] - ========== epoch: [10/50] ==========
[2020-03-03 09:19:13,221] - step: [100/391], train_loss: 0.995 | train_acc: 65.539% | lr: 0.002000
[2020-03-03 09:19:14,064] - step: [200/391], train_loss: 0.983 | train_acc: 66.391% | lr: 0.002000
[2020-03-03 09:19:14,907] - step: [300/391], train_loss: 0.984 | train_acc: 66.331% | lr: 0.002000
[2020-03-03 09:19:15,692] - --- cost time: 3.4009s ---
[2020-03-03 09:19:15,693] - *************** test ***************
[2020-03-03 09:19:16,220] - test_loss: 1.013 | test_acc: 65.260%
[2020-03-03 09:19:16,220] - ************************************

[2020-03-03 09:19:16,406] - ========== epoch: [11/50] ==========
[2020-03-03 09:19:17,347] - step: [100/391], train_loss: 0.949 | train_acc: 67.445% | lr: 0.002000
[2020-03-03 09:19:18,193] - step: [200/391], train_loss: 0.954 | train_acc: 67.414% | lr: 0.002000
[2020-03-03 09:19:19,040] - step: [300/391], train_loss: 0.954 | train_acc: 67.471% | lr: 0.002000
[2020-03-03 09:19:19,825] - --- cost time: 3.4188s ---
[2020-03-03 09:19:19,825] - *************** test ***************
[2020-03-03 09:19:20,352] - test_loss: 0.938 | test_acc: 67.680%
[2020-03-03 09:19:20,353] - ************************************

[2020-03-03 09:19:20,399] - ========== epoch: [12/50] ==========
[2020-03-03 09:19:21,334] - step: [100/391], train_loss: 0.907 | train_acc: 68.914% | lr: 0.002000
[2020-03-03 09:19:22,182] - step: [200/391], train_loss: 0.910 | train_acc: 68.980% | lr: 0.002000
[2020-03-03 09:19:23,032] - step: [300/391], train_loss: 0.914 | train_acc: 68.891% | lr: 0.002000
[2020-03-03 09:19:23,819] - --- cost time: 3.4199s ---
[2020-03-03 09:19:23,820] - *************** test ***************
[2020-03-03 09:19:24,376] - test_loss: 0.937 | test_acc: 68.060%
[2020-03-03 09:19:24,376] - ************************************

[2020-03-03 09:19:24,421] - ========== epoch: [13/50] ==========
[2020-03-03 09:19:25,360] - step: [100/391], train_loss: 0.909 | train_acc: 69.078% | lr: 0.002000
[2020-03-03 09:19:26,209] - step: [200/391], train_loss: 0.910 | train_acc: 69.004% | lr: 0.002000
[2020-03-03 09:19:27,055] - step: [300/391], train_loss: 0.903 | train_acc: 69.323% | lr: 0.002000
[2020-03-03 09:19:27,841] - --- cost time: 3.4199s ---
[2020-03-03 09:19:27,841] - *************** test ***************
[2020-03-03 09:19:28,383] - test_loss: 0.907 | test_acc: 69.330%
[2020-03-03 09:19:28,383] - ************************************

[2020-03-03 09:19:28,455] - ========== epoch: [14/50] ==========
[2020-03-03 09:19:29,392] - step: [100/391], train_loss: 0.857 | train_acc: 70.828% | lr: 0.002000
[2020-03-03 09:19:30,238] - step: [200/391], train_loss: 0.869 | train_acc: 70.234% | lr: 0.002000
[2020-03-03 09:19:31,087] - step: [300/391], train_loss: 0.873 | train_acc: 70.190% | lr: 0.002000
[2020-03-03 09:19:31,877] - --- cost time: 3.4213s ---
[2020-03-03 09:19:31,877] - *************** test ***************
[2020-03-03 09:19:32,404] - test_loss: 0.887 | test_acc: 69.910%
[2020-03-03 09:19:32,404] - ************************************

[2020-03-03 09:19:32,451] - ========== epoch: [15/50] ==========
[2020-03-03 09:19:33,386] - step: [100/391], train_loss: 0.849 | train_acc: 71.109% | lr: 0.002000
[2020-03-03 09:19:34,234] - step: [200/391], train_loss: 0.853 | train_acc: 70.867% | lr: 0.002000
[2020-03-03 09:19:35,082] - step: [300/391], train_loss: 0.849 | train_acc: 71.034% | lr: 0.002000
[2020-03-03 09:19:35,869] - --- cost time: 3.4178s ---
[2020-03-03 09:19:35,869] - *************** test ***************
[2020-03-03 09:19:36,410] - test_loss: 0.856 | test_acc: 71.290%
[2020-03-03 09:19:36,410] - ************************************

[2020-03-03 09:19:36,456] - ========== epoch: [16/50] ==========
[2020-03-03 09:19:37,391] - step: [100/391], train_loss: 0.837 | train_acc: 71.555% | lr: 0.002000
[2020-03-03 09:19:38,237] - step: [200/391], train_loss: 0.831 | train_acc: 71.898% | lr: 0.002000
[2020-03-03 09:19:39,084] - step: [300/391], train_loss: 0.835 | train_acc: 71.690% | lr: 0.002000
[2020-03-03 09:19:39,868] - --- cost time: 3.4120s ---
[2020-03-03 09:19:39,869] - *************** test ***************
[2020-03-03 09:19:40,397] - test_loss: 0.878 | test_acc: 70.650%
[2020-03-03 09:19:40,397] - ************************************

[2020-03-03 09:19:40,429] - ========== epoch: [17/50] ==========
[2020-03-03 09:19:41,386] - step: [100/391], train_loss: 0.799 | train_acc: 72.672% | lr: 0.002000
[2020-03-03 09:19:42,234] - step: [200/391], train_loss: 0.805 | train_acc: 72.496% | lr: 0.002000
[2020-03-03 09:19:43,079] - step: [300/391], train_loss: 0.810 | train_acc: 72.357% | lr: 0.002000
[2020-03-03 09:19:43,867] - --- cost time: 3.4364s ---
[2020-03-03 09:19:43,867] - *************** test ***************
[2020-03-03 09:19:44,402] - test_loss: 0.861 | test_acc: 71.080%
[2020-03-03 09:19:44,402] - ************************************

[2020-03-03 09:19:44,427] - ========== epoch: [18/50] ==========
[2020-03-03 09:19:45,361] - step: [100/391], train_loss: 0.805 | train_acc: 72.852% | lr: 0.002000
[2020-03-03 09:19:46,207] - step: [200/391], train_loss: 0.808 | train_acc: 72.699% | lr: 0.002000
[2020-03-03 09:19:47,056] - step: [300/391], train_loss: 0.808 | train_acc: 72.852% | lr: 0.002000
[2020-03-03 09:19:47,844] - --- cost time: 3.4161s ---
[2020-03-03 09:19:47,844] - *************** test ***************
[2020-03-03 09:19:48,370] - test_loss: 0.850 | test_acc: 71.760%
[2020-03-03 09:19:48,370] - ************************************

[2020-03-03 09:19:48,416] - ========== epoch: [19/50] ==========
[2020-03-03 09:19:49,353] - step: [100/391], train_loss: 0.782 | train_acc: 73.617% | lr: 0.002000
[2020-03-03 09:19:50,202] - step: [200/391], train_loss: 0.792 | train_acc: 73.215% | lr: 0.002000
[2020-03-03 09:19:51,052] - step: [300/391], train_loss: 0.795 | train_acc: 73.135% | lr: 0.002000
[2020-03-03 09:19:51,840] - --- cost time: 3.4238s ---
[2020-03-03 09:19:51,841] - *************** test ***************
[2020-03-03 09:19:52,366] - test_loss: 0.845 | test_acc: 71.840%
[2020-03-03 09:19:52,366] - ************************************

[2020-03-03 09:19:52,411] - ========== epoch: [20/50] ==========
[2020-03-03 09:19:53,348] - step: [100/391], train_loss: 0.775 | train_acc: 74.188% | lr: 0.002000
[2020-03-03 09:19:54,194] - step: [200/391], train_loss: 0.776 | train_acc: 73.984% | lr: 0.002000
[2020-03-03 09:19:55,041] - step: [300/391], train_loss: 0.783 | train_acc: 73.612% | lr: 0.002000
[2020-03-03 09:19:55,833] - --- cost time: 3.4220s ---
[2020-03-03 09:19:55,833] - *************** test ***************
[2020-03-03 09:19:56,368] - test_loss: 0.836 | test_acc: 71.970%
[2020-03-03 09:19:56,368] - ************************************

[2020-03-03 09:19:56,543] - ========== epoch: [21/50] ==========
[2020-03-03 09:19:57,486] - step: [100/391], train_loss: 0.753 | train_acc: 74.508% | lr: 0.002000
[2020-03-03 09:19:58,333] - step: [200/391], train_loss: 0.765 | train_acc: 74.195% | lr: 0.002000
[2020-03-03 09:19:59,182] - step: [300/391], train_loss: 0.771 | train_acc: 73.987% | lr: 0.002000
[2020-03-03 09:19:59,971] - --- cost time: 3.4279s ---
[2020-03-03 09:19:59,971] - *************** test ***************
[2020-03-03 09:20:00,502] - test_loss: 0.812 | test_acc: 72.810%
[2020-03-03 09:20:00,502] - ************************************

[2020-03-03 09:20:00,549] - ========== epoch: [22/50] ==========
[2020-03-03 09:20:01,484] - step: [100/391], train_loss: 0.751 | train_acc: 74.719% | lr: 0.002000
[2020-03-03 09:20:02,331] - step: [200/391], train_loss: 0.760 | train_acc: 74.496% | lr: 0.002000
[2020-03-03 09:20:03,176] - step: [300/391], train_loss: 0.759 | train_acc: 74.424% | lr: 0.002000
[2020-03-03 09:20:03,963] - --- cost time: 3.4137s ---
[2020-03-03 09:20:03,963] - *************** test ***************
[2020-03-03 09:20:04,499] - test_loss: 0.847 | test_acc: 72.820%
[2020-03-03 09:20:04,499] - ************************************

[2020-03-03 09:20:04,552] - ========== epoch: [23/50] ==========
[2020-03-03 09:20:05,506] - step: [100/391], train_loss: 0.752 | train_acc: 74.320% | lr: 0.002000
[2020-03-03 09:20:06,354] - step: [200/391], train_loss: 0.750 | train_acc: 74.684% | lr: 0.002000
[2020-03-03 09:20:07,200] - step: [300/391], train_loss: 0.747 | train_acc: 74.875% | lr: 0.002000
[2020-03-03 09:20:07,986] - --- cost time: 3.4334s ---
[2020-03-03 09:20:07,987] - *************** test ***************
[2020-03-03 09:20:08,510] - test_loss: 0.795 | test_acc: 73.370%
[2020-03-03 09:20:08,510] - ************************************

[2020-03-03 09:20:08,557] - ========== epoch: [24/50] ==========
[2020-03-03 09:20:09,492] - step: [100/391], train_loss: 0.735 | train_acc: 75.219% | lr: 0.002000
[2020-03-03 09:20:10,339] - step: [200/391], train_loss: 0.738 | train_acc: 75.102% | lr: 0.002000
[2020-03-03 09:20:11,186] - step: [300/391], train_loss: 0.731 | train_acc: 75.339% | lr: 0.002000
[2020-03-03 09:20:11,975] - --- cost time: 3.4183s ---
[2020-03-03 09:20:11,976] - *************** test ***************
[2020-03-03 09:20:12,511] - test_loss: 0.805 | test_acc: 73.670%
[2020-03-03 09:20:12,512] - ************************************

[2020-03-03 09:20:12,559] - ========== epoch: [25/50] ==========
[2020-03-03 09:20:13,493] - step: [100/391], train_loss: 0.724 | train_acc: 75.438% | lr: 0.002000
[2020-03-03 09:20:14,343] - step: [200/391], train_loss: 0.732 | train_acc: 75.352% | lr: 0.002000
[2020-03-03 09:20:15,190] - step: [300/391], train_loss: 0.733 | train_acc: 75.380% | lr: 0.002000
[2020-03-03 09:20:15,977] - --- cost time: 3.4186s ---
[2020-03-03 09:20:15,978] - *************** test ***************
[2020-03-03 09:20:16,544] - test_loss: 0.798 | test_acc: 73.910%
[2020-03-03 09:20:16,544] - ************************************

[2020-03-03 09:20:16,591] - ========== epoch: [26/50] ==========
[2020-03-03 09:20:17,524] - step: [100/391], train_loss: 0.724 | train_acc: 75.789% | lr: 0.002000
[2020-03-03 09:20:18,366] - step: [200/391], train_loss: 0.723 | train_acc: 75.648% | lr: 0.002000
[2020-03-03 09:20:19,214] - step: [300/391], train_loss: 0.727 | train_acc: 75.549% | lr: 0.002000
[2020-03-03 09:20:20,003] - --- cost time: 3.4117s ---
[2020-03-03 09:20:20,003] - *************** test ***************
[2020-03-03 09:20:20,561] - test_loss: 0.778 | test_acc: 74.040%
[2020-03-03 09:20:20,561] - ************************************

[2020-03-03 09:20:20,606] - ========== epoch: [27/50] ==========
[2020-03-03 09:20:21,543] - step: [100/391], train_loss: 0.703 | train_acc: 76.383% | lr: 0.002000
[2020-03-03 09:20:22,391] - step: [200/391], train_loss: 0.703 | train_acc: 76.441% | lr: 0.002000
[2020-03-03 09:20:23,237] - step: [300/391], train_loss: 0.708 | train_acc: 76.370% | lr: 0.002000
[2020-03-03 09:20:24,025] - --- cost time: 3.4194s ---
[2020-03-03 09:20:24,026] - *************** test ***************
[2020-03-03 09:20:24,555] - test_loss: 0.777 | test_acc: 74.120%
[2020-03-03 09:20:24,555] - ************************************

[2020-03-03 09:20:24,602] - ========== epoch: [28/50] ==========
[2020-03-03 09:20:25,536] - step: [100/391], train_loss: 0.688 | train_acc: 76.672% | lr: 0.002000
[2020-03-03 09:20:26,383] - step: [200/391], train_loss: 0.697 | train_acc: 76.500% | lr: 0.002000
[2020-03-03 09:20:27,227] - step: [300/391], train_loss: 0.700 | train_acc: 76.495% | lr: 0.002000
[2020-03-03 09:20:28,015] - --- cost time: 3.4127s ---
[2020-03-03 09:20:28,015] - *************** test ***************
[2020-03-03 09:20:28,548] - test_loss: 0.761 | test_acc: 74.800%
[2020-03-03 09:20:28,549] - ************************************

[2020-03-03 09:20:28,622] - ========== epoch: [29/50] ==========
[2020-03-03 09:20:29,560] - step: [100/391], train_loss: 0.692 | train_acc: 76.570% | lr: 0.002000
[2020-03-03 09:20:30,405] - step: [200/391], train_loss: 0.689 | train_acc: 76.809% | lr: 0.002000
[2020-03-03 09:20:31,250] - step: [300/391], train_loss: 0.695 | train_acc: 76.596% | lr: 0.002000
[2020-03-03 09:20:32,037] - --- cost time: 3.4144s ---
[2020-03-03 09:20:32,037] - *************** test ***************
[2020-03-03 09:20:32,565] - test_loss: 0.776 | test_acc: 73.960%
[2020-03-03 09:20:32,565] - ************************************

[2020-03-03 09:20:32,590] - ========== epoch: [30/50] ==========
[2020-03-03 09:20:33,522] - step: [100/391], train_loss: 0.687 | train_acc: 76.477% | lr: 0.002000
[2020-03-03 09:20:34,366] - step: [200/391], train_loss: 0.690 | train_acc: 76.695% | lr: 0.002000
[2020-03-03 09:20:35,212] - step: [300/391], train_loss: 0.695 | train_acc: 76.583% | lr: 0.002000
[2020-03-03 09:20:35,998] - --- cost time: 3.4077s ---
[2020-03-03 09:20:35,998] - *************** test ***************
[2020-03-03 09:20:36,541] - test_loss: 0.786 | test_acc: 74.320%
[2020-03-03 09:20:36,541] - ************************************

[2020-03-03 09:20:36,720] - ========== epoch: [31/50] ==========
[2020-03-03 09:20:37,659] - step: [100/391], train_loss: 0.675 | train_acc: 77.273% | lr: 0.002000
[2020-03-03 09:20:38,504] - step: [200/391], train_loss: 0.676 | train_acc: 77.207% | lr: 0.002000
[2020-03-03 09:20:39,352] - step: [300/391], train_loss: 0.682 | train_acc: 76.961% | lr: 0.002000
[2020-03-03 09:20:40,141] - --- cost time: 3.4206s ---
[2020-03-03 09:20:40,141] - *************** test ***************
[2020-03-03 09:20:40,671] - test_loss: 0.772 | test_acc: 74.640%
[2020-03-03 09:20:40,671] - ************************************

[2020-03-03 09:20:40,697] - ========== epoch: [32/50] ==========
[2020-03-03 09:20:41,633] - step: [100/391], train_loss: 0.690 | train_acc: 76.758% | lr: 0.002000
[2020-03-03 09:20:42,479] - step: [200/391], train_loss: 0.675 | train_acc: 77.207% | lr: 0.002000
[2020-03-03 09:20:43,324] - step: [300/391], train_loss: 0.675 | train_acc: 77.253% | lr: 0.002000
[2020-03-03 09:20:44,112] - --- cost time: 3.4149s ---
[2020-03-03 09:20:44,112] - *************** test ***************
[2020-03-03 09:20:44,645] - test_loss: 0.785 | test_acc: 74.530%
[2020-03-03 09:20:44,645] - ************************************

[2020-03-03 09:20:44,671] - ========== epoch: [33/50] ==========
[2020-03-03 09:20:45,607] - step: [100/391], train_loss: 0.669 | train_acc: 77.219% | lr: 0.002000
[2020-03-03 09:20:46,463] - step: [200/391], train_loss: 0.670 | train_acc: 77.395% | lr: 0.002000
[2020-03-03 09:20:47,309] - step: [300/391], train_loss: 0.669 | train_acc: 77.458% | lr: 0.002000
[2020-03-03 09:20:48,096] - --- cost time: 3.4256s ---
[2020-03-03 09:20:48,097] - *************** test ***************
[2020-03-03 09:20:48,618] - test_loss: 0.748 | test_acc: 75.800%
[2020-03-03 09:20:48,618] - ************************************

[2020-03-03 09:20:48,688] - ========== epoch: [34/50] ==========
[2020-03-03 09:20:49,630] - step: [100/391], train_loss: 0.684 | train_acc: 77.281% | lr: 0.002000
[2020-03-03 09:20:50,476] - step: [200/391], train_loss: 0.676 | train_acc: 77.445% | lr: 0.002000
[2020-03-03 09:20:51,322] - step: [300/391], train_loss: 0.666 | train_acc: 77.740% | lr: 0.002000
[2020-03-03 09:20:52,109] - --- cost time: 3.4204s ---
[2020-03-03 09:20:52,109] - *************** test ***************
[2020-03-03 09:20:52,639] - test_loss: 0.761 | test_acc: 75.330%
[2020-03-03 09:20:52,639] - ************************************

[2020-03-03 09:20:52,663] - ========== epoch: [35/50] ==========
[2020-03-03 09:20:53,600] - step: [100/391], train_loss: 0.649 | train_acc: 77.773% | lr: 0.002000
[2020-03-03 09:20:54,446] - step: [200/391], train_loss: 0.655 | train_acc: 77.844% | lr: 0.002000
[2020-03-03 09:20:55,291] - step: [300/391], train_loss: 0.656 | train_acc: 77.880% | lr: 0.002000
[2020-03-03 09:20:56,077] - --- cost time: 3.4137s ---
[2020-03-03 09:20:56,078] - *************** test ***************
[2020-03-03 09:20:56,598] - test_loss: 0.757 | test_acc: 75.400%
[2020-03-03 09:20:56,598] - ************************************

[2020-03-03 09:20:56,624] - ========== epoch: [36/50] ==========
[2020-03-03 09:20:57,559] - step: [100/391], train_loss: 0.640 | train_acc: 78.836% | lr: 0.002000
[2020-03-03 09:20:58,406] - step: [200/391], train_loss: 0.641 | train_acc: 78.816% | lr: 0.002000
[2020-03-03 09:20:59,253] - step: [300/391], train_loss: 0.649 | train_acc: 78.362% | lr: 0.002000
[2020-03-03 09:21:00,040] - --- cost time: 3.4158s ---
[2020-03-03 09:21:00,040] - *************** test ***************
[2020-03-03 09:21:00,564] - test_loss: 0.745 | test_acc: 75.470%
[2020-03-03 09:21:00,564] - ************************************

[2020-03-03 09:21:00,589] - ========== epoch: [37/50] ==========
[2020-03-03 09:21:01,523] - step: [100/391], train_loss: 0.646 | train_acc: 78.281% | lr: 0.002000
[2020-03-03 09:21:02,370] - step: [200/391], train_loss: 0.649 | train_acc: 78.254% | lr: 0.002000
[2020-03-03 09:21:03,215] - step: [300/391], train_loss: 0.648 | train_acc: 78.219% | lr: 0.002000
[2020-03-03 09:21:04,000] - --- cost time: 3.4111s ---
[2020-03-03 09:21:04,001] - *************** test ***************
[2020-03-03 09:21:04,532] - test_loss: 0.726 | test_acc: 76.310%
[2020-03-03 09:21:04,532] - ************************************

[2020-03-03 09:21:04,610] - ========== epoch: [38/50] ==========
[2020-03-03 09:21:05,547] - step: [100/391], train_loss: 0.632 | train_acc: 78.609% | lr: 0.002000
[2020-03-03 09:21:06,392] - step: [200/391], train_loss: 0.634 | train_acc: 78.773% | lr: 0.002000
[2020-03-03 09:21:07,237] - step: [300/391], train_loss: 0.635 | train_acc: 78.794% | lr: 0.002000
[2020-03-03 09:21:08,023] - --- cost time: 3.4129s ---
[2020-03-03 09:21:08,024] - *************** test ***************
[2020-03-03 09:21:08,553] - test_loss: 0.743 | test_acc: 75.690%
[2020-03-03 09:21:08,553] - ************************************

[2020-03-03 09:21:08,579] - ========== epoch: [39/50] ==========
[2020-03-03 09:21:09,513] - step: [100/391], train_loss: 0.638 | train_acc: 78.656% | lr: 0.002000
[2020-03-03 09:21:10,361] - step: [200/391], train_loss: 0.638 | train_acc: 78.570% | lr: 0.002000
[2020-03-03 09:21:11,206] - step: [300/391], train_loss: 0.638 | train_acc: 78.516% | lr: 0.002000
[2020-03-03 09:21:11,993] - --- cost time: 3.4143s ---
[2020-03-03 09:21:11,994] - *************** test ***************
[2020-03-03 09:21:12,525] - test_loss: 0.789 | test_acc: 75.170%
[2020-03-03 09:21:12,525] - ************************************

[2020-03-03 09:21:12,550] - ========== epoch: [40/50] ==========
[2020-03-03 09:21:13,486] - step: [100/391], train_loss: 0.585 | train_acc: 80.367% | lr: 0.000200
[2020-03-03 09:21:14,330] - step: [200/391], train_loss: 0.563 | train_acc: 80.840% | lr: 0.000200
[2020-03-03 09:21:15,176] - step: [300/391], train_loss: 0.556 | train_acc: 80.969% | lr: 0.000200
[2020-03-03 09:21:15,965] - --- cost time: 3.4141s ---
[2020-03-03 09:21:15,965] - *************** test ***************
[2020-03-03 09:21:16,528] - test_loss: 0.670 | test_acc: 77.930%
[2020-03-03 09:21:16,528] - ************************************

[2020-03-03 09:21:16,713] - ========== epoch: [41/50] ==========
[2020-03-03 09:21:17,655] - step: [100/391], train_loss: 0.525 | train_acc: 81.953% | lr: 0.000200
[2020-03-03 09:21:18,499] - step: [200/391], train_loss: 0.527 | train_acc: 82.195% | lr: 0.000200
[2020-03-03 09:21:19,347] - step: [300/391], train_loss: 0.526 | train_acc: 82.154% | lr: 0.000200
[2020-03-03 09:21:20,141] - --- cost time: 3.4274s ---
[2020-03-03 09:21:20,141] - *************** test ***************
[2020-03-03 09:21:20,692] - test_loss: 0.671 | test_acc: 78.210%
[2020-03-03 09:21:20,692] - ************************************

[2020-03-03 09:21:20,762] - ========== epoch: [42/50] ==========
[2020-03-03 09:21:21,702] - step: [100/391], train_loss: 0.516 | train_acc: 82.367% | lr: 0.000200
[2020-03-03 09:21:22,551] - step: [200/391], train_loss: 0.511 | train_acc: 82.465% | lr: 0.000200
[2020-03-03 09:21:23,397] - step: [300/391], train_loss: 0.509 | train_acc: 82.695% | lr: 0.000200
[2020-03-03 09:21:24,185] - --- cost time: 3.4223s ---
[2020-03-03 09:21:24,185] - *************** test ***************
[2020-03-03 09:21:24,714] - test_loss: 0.659 | test_acc: 78.590%
[2020-03-03 09:21:24,714] - ************************************

[2020-03-03 09:21:24,758] - ========== epoch: [43/50] ==========
[2020-03-03 09:21:25,695] - step: [100/391], train_loss: 0.508 | train_acc: 82.555% | lr: 0.000200
[2020-03-03 09:21:26,541] - step: [200/391], train_loss: 0.500 | train_acc: 82.953% | lr: 0.000200
[2020-03-03 09:21:27,386] - step: [300/391], train_loss: 0.505 | train_acc: 82.792% | lr: 0.000200
[2020-03-03 09:21:28,176] - --- cost time: 3.4174s ---
[2020-03-03 09:21:28,176] - *************** test ***************
[2020-03-03 09:21:28,704] - test_loss: 0.658 | test_acc: 78.830%
[2020-03-03 09:21:28,704] - ************************************

[2020-03-03 09:21:28,750] - ========== epoch: [44/50] ==========
[2020-03-03 09:21:29,686] - step: [100/391], train_loss: 0.502 | train_acc: 82.914% | lr: 0.000200
[2020-03-03 09:21:30,530] - step: [200/391], train_loss: 0.496 | train_acc: 83.211% | lr: 0.000200
[2020-03-03 09:21:31,375] - step: [300/391], train_loss: 0.495 | train_acc: 83.159% | lr: 0.000200
[2020-03-03 09:21:32,160] - --- cost time: 3.4090s ---
[2020-03-03 09:21:32,160] - *************** test ***************
[2020-03-03 09:21:32,696] - test_loss: 0.660 | test_acc: 78.750%
[2020-03-03 09:21:32,696] - ************************************

[2020-03-03 09:21:32,721] - ========== epoch: [45/50] ==========
[2020-03-03 09:21:33,655] - step: [100/391], train_loss: 0.496 | train_acc: 83.148% | lr: 0.000200
[2020-03-03 09:21:34,501] - step: [200/391], train_loss: 0.488 | train_acc: 83.223% | lr: 0.000200
[2020-03-03 09:21:35,348] - step: [300/391], train_loss: 0.494 | train_acc: 83.141% | lr: 0.000200
[2020-03-03 09:21:36,135] - --- cost time: 3.4138s ---
[2020-03-03 09:21:36,135] - *************** test ***************
[2020-03-03 09:21:36,666] - test_loss: 0.644 | test_acc: 78.960%
[2020-03-03 09:21:36,666] - ************************************

[2020-03-03 09:21:36,713] - ========== epoch: [46/50] ==========
[2020-03-03 09:21:37,648] - step: [100/391], train_loss: 0.494 | train_acc: 83.297% | lr: 0.000200
[2020-03-03 09:21:38,494] - step: [200/391], train_loss: 0.489 | train_acc: 83.359% | lr: 0.000200
[2020-03-03 09:21:39,343] - step: [300/391], train_loss: 0.489 | train_acc: 83.380% | lr: 0.000200
[2020-03-03 09:21:40,129] - --- cost time: 3.4164s ---
[2020-03-03 09:21:40,130] - *************** test ***************
[2020-03-03 09:21:40,651] - test_loss: 0.645 | test_acc: 79.080%
[2020-03-03 09:21:40,651] - ************************************

[2020-03-03 09:21:40,697] - ========== epoch: [47/50] ==========
[2020-03-03 09:21:41,635] - step: [100/391], train_loss: 0.476 | train_acc: 84.094% | lr: 0.000200
[2020-03-03 09:21:42,481] - step: [200/391], train_loss: 0.480 | train_acc: 83.848% | lr: 0.000200
[2020-03-03 09:21:43,327] - step: [300/391], train_loss: 0.485 | train_acc: 83.620% | lr: 0.000200
[2020-03-03 09:21:44,113] - --- cost time: 3.4153s ---
[2020-03-03 09:21:44,113] - *************** test ***************
[2020-03-03 09:21:44,643] - test_loss: 0.642 | test_acc: 79.380%
[2020-03-03 09:21:44,643] - ************************************

[2020-03-03 09:21:44,715] - ========== epoch: [48/50] ==========
[2020-03-03 09:21:45,650] - step: [100/391], train_loss: 0.483 | train_acc: 83.508% | lr: 0.000200
[2020-03-03 09:21:46,497] - step: [200/391], train_loss: 0.480 | train_acc: 83.652% | lr: 0.000200
[2020-03-03 09:21:47,343] - step: [300/391], train_loss: 0.485 | train_acc: 83.495% | lr: 0.000200
[2020-03-03 09:21:48,132] - --- cost time: 3.4160s ---
[2020-03-03 09:21:48,132] - *************** test ***************
[2020-03-03 09:21:48,655] - test_loss: 0.636 | test_acc: 79.100%
[2020-03-03 09:21:48,655] - ************************************

[2020-03-03 09:21:48,681] - ========== epoch: [49/50] ==========
[2020-03-03 09:21:49,614] - step: [100/391], train_loss: 0.484 | train_acc: 83.578% | lr: 0.000200
[2020-03-03 09:21:50,459] - step: [200/391], train_loss: 0.480 | train_acc: 83.918% | lr: 0.000200
[2020-03-03 09:21:51,302] - step: [300/391], train_loss: 0.479 | train_acc: 83.885% | lr: 0.000200
[2020-03-03 09:21:52,089] - --- cost time: 3.4077s ---
[2020-03-03 09:21:52,089] - *************** test ***************
[2020-03-03 09:21:52,619] - test_loss: 0.650 | test_acc: 79.070%
[2020-03-03 09:21:52,619] - ************************************

[2020-03-03 09:21:52,644] - ========== epoch: [50/50] ==========
[2020-03-03 09:21:53,583] - step: [100/391], train_loss: 0.480 | train_acc: 83.859% | lr: 0.000200
[2020-03-03 09:21:54,431] - step: [200/391], train_loss: 0.474 | train_acc: 83.777% | lr: 0.000200
[2020-03-03 09:21:55,279] - step: [300/391], train_loss: 0.476 | train_acc: 83.771% | lr: 0.000200
[2020-03-03 09:21:56,071] - --- cost time: 3.4266s ---
[2020-03-03 09:21:56,071] - *************** test ***************
[2020-03-03 09:21:56,597] - test_loss: 0.640 | test_acc: 79.240%
[2020-03-03 09:21:56,597] - ************************************

[2020-03-03 09:21:56,763] - Training Finished ==> best accuracy: 79.380%
[2020-03-03 09:23:21,856] - {'architecture': 'nin', 'ckpt_path': './', 'ckpt_name': 'nin', 'log_path': './', 'log_name': 'cifar10', 'log_color': {'train': 'blue', 'cost_time': 'yellow', 'time': 'purple', 'test': 'red'}, 'data_name': 'CIFAR10', 'num_classes': 10, 'train_set_path': './data/cifar-10', 'test_set_path': './data/cifar-10', 'augmentation': {'normalize': True, 'random_crop': True, 'random_horizontal_filp': True}, 'device': 'cuda', 'input_size': 32, 'batch_size': 128, 'num_epochs': 50, 'num_print': 100, 'num_workers': 4, 'eval_freq': 1, 'test_batch': 200, 'optimizer': {'name': 'Adam', 'params': {'lr': 0.01}}, 'lr_scheduler': {'type': 'STEP', 'lr_epochs': [40], 'lr_mults': 0.1}, 'learning_curve': {'style': 'ggplot', 'xtick_step': 5, 'draw_freq': 10, 'save_path': './'}}
NiN(
  (features): Sequential(
    (0): Sequential(
      (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2))
      (1): ReLU(inplace)
      (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU(inplace)
      (4): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
      (5): ReLU(inplace)
    )
    (1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (2): Sequential(
      (0): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
      (1): ReLU(inplace)
      (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU(inplace)
      (4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (5): ReLU(inplace)
    )
    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Sequential(
      (0): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace)
      (2): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU(inplace)
      (4): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
      (5): ReLU(inplace)
    )
    (5): Dropout(p=0.5)
    (6): Sequential(
      (0): Conv2d(384, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace)
      (2): Conv2d(10, 10, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU(inplace)
      (4): Conv2d(10, 10, kernel_size=(1, 1), stride=(1, 1))
      (5): ReLU(inplace)
    )
  )
  (classifier): AdaptiveAvgPool2d(output_size=(1, 1))
)
-------------------- Training parameters: 1994662 --------------------
[2020-03-03 09:23:21,857] - ========== epoch: [1/50] ==========
[2020-03-03 09:23:23,022] - step: [100/391], train_loss: 2.326 | train_acc:  9.680% | lr: 0.010000
[2020-03-03 09:23:23,863] - step: [200/391], train_loss: 2.314 | train_acc:  9.688% | lr: 0.010000
[2020-03-03 09:23:24,699] - step: [300/391], train_loss: 2.310 | train_acc:  9.885% | lr: 0.010000
[2020-03-03 09:23:25,479] - --- cost time: 3.6222s ---
[2020-03-03 09:23:25,480] - *************** test ***************
[2020-03-03 09:23:25,992] - test_loss: 2.303 | test_acc: 10.000%
[2020-03-03 09:23:25,992] - ************************************

[2020-03-03 09:23:26,065] - ========== epoch: [2/50] ==========
[2020-03-03 09:23:26,991] - step: [100/391], train_loss: 2.303 | train_acc: 10.102% | lr: 0.010000
[2020-03-03 09:23:27,831] - step: [200/391], train_loss: 2.303 | train_acc: 10.109% | lr: 0.010000
[2020-03-03 09:23:28,674] - step: [300/391], train_loss: 2.303 | train_acc:  9.938% | lr: 0.010000
[2020-03-03 09:23:29,457] - --- cost time: 3.3911s ---
[2020-03-03 09:23:29,457] - *************** test ***************
[2020-03-03 09:23:29,973] - test_loss: 2.303 | test_acc: 10.000%
[2020-03-03 09:23:29,973] - ************************************

[2020-03-03 09:23:29,999] - ========== epoch: [3/50] ==========
[2020-03-03 09:23:30,935] - step: [100/391], train_loss: 2.303 | train_acc:  9.781% | lr: 0.010000
[2020-03-03 09:23:31,797] - step: [200/391], train_loss: 2.303 | train_acc:  9.863% | lr: 0.010000
[2020-03-03 09:23:32,643] - step: [300/391], train_loss: 2.303 | train_acc:  9.982% | lr: 0.010000
[2020-03-03 09:23:33,451] - --- cost time: 3.4522s ---
[2020-03-03 09:23:33,452] - *************** test ***************
[2020-03-03 09:23:33,978] - test_loss: 2.303 | test_acc: 10.000%
[2020-03-03 09:23:33,978] - ************************************

[2020-03-03 09:23:34,004] - ========== epoch: [4/50] ==========
[2020-03-03 09:23:49,814] - {'architecture': 'nin', 'ckpt_path': './', 'ckpt_name': 'nin', 'log_path': './', 'log_name': 'cifar10', 'log_color': {'train': 'blue', 'cost_time': 'yellow', 'time': 'purple', 'test': 'red'}, 'data_name': 'CIFAR10', 'num_classes': 10, 'train_set_path': './data/cifar-10', 'test_set_path': './data/cifar-10', 'augmentation': {'normalize': True, 'random_crop': True, 'random_horizontal_filp': True}, 'device': 'cuda', 'input_size': 32, 'batch_size': 128, 'num_epochs': 50, 'num_print': 100, 'num_workers': 4, 'eval_freq': 1, 'test_batch': 200, 'optimizer': {'name': 'SGD', 'params': {'lr': 0.02, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': True}}, 'lr_scheduler': {'type': 'STEP', 'lr_epochs': [40], 'lr_mults': 0.1}, 'learning_curve': {'style': 'ggplot', 'xtick_step': 5, 'draw_freq': 10, 'save_path': './'}}
NiN(
  (features): Sequential(
    (0): Sequential(
      (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2))
      (1): ReLU(inplace)
      (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU(inplace)
      (4): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
      (5): ReLU(inplace)
    )
    (1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (2): Sequential(
      (0): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
      (1): ReLU(inplace)
      (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU(inplace)
      (4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (5): ReLU(inplace)
    )
    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Sequential(
      (0): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace)
      (2): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU(inplace)
      (4): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
      (5): ReLU(inplace)
    )
    (5): Dropout(p=0.5)
    (6): Sequential(
      (0): Conv2d(384, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace)
      (2): Conv2d(10, 10, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU(inplace)
      (4): Conv2d(10, 10, kernel_size=(1, 1), stride=(1, 1))
      (5): ReLU(inplace)
    )
  )
  (classifier): AdaptiveAvgPool2d(output_size=(1, 1))
)
-------------------- Training parameters: 1994662 --------------------
[2020-03-03 09:23:49,814] - ========== epoch: [1/50] ==========
[2020-03-03 09:23:50,981] - step: [100/391], train_loss: 2.305 | train_acc: 10.227% | lr: 0.020000
[2020-03-03 09:23:51,817] - step: [200/391], train_loss: 2.304 | train_acc:  9.941% | lr: 0.020000
[2020-03-03 09:23:52,656] - step: [300/391], train_loss: 2.304 | train_acc:  9.867% | lr: 0.020000
[2020-03-03 09:23:53,431] - --- cost time: 3.6162s ---
[2020-03-03 09:23:53,431] - *************** test ***************
[2020-03-03 09:23:53,953] - test_loss: 2.303 | test_acc: 10.000%
[2020-03-03 09:23:53,953] - ************************************

[2020-03-03 09:23:53,982] - ========== epoch: [2/50] ==========
[2020-03-03 09:23:54,905] - step: [100/391], train_loss: 2.303 | train_acc:  9.719% | lr: 0.020000
[2020-03-03 09:23:55,746] - step: [200/391], train_loss: 2.303 | train_acc:  9.875% | lr: 0.020000
[2020-03-03 09:23:56,616] - step: [300/391], train_loss: 2.303 | train_acc:  9.862% | lr: 0.020000
[2020-03-03 09:23:57,420] - --- cost time: 3.4379s ---
[2020-03-03 09:23:57,421] - *************** test ***************
[2020-03-03 09:23:57,942] - test_loss: 2.303 | test_acc: 10.000%
[2020-03-03 09:23:57,942] - ************************************

[2020-03-03 09:23:57,964] - ========== epoch: [3/50] ==========
[2020-03-03 09:23:58,901] - step: [100/391], train_loss: 2.303 | train_acc: 10.156% | lr: 0.020000
[2020-03-03 09:23:59,742] - step: [200/391], train_loss: 2.303 | train_acc: 10.074% | lr: 0.020000
[2020-03-03 09:24:00,584] - step: [300/391], train_loss: 2.303 | train_acc:  9.982% | lr: 0.020000
[2020-03-03 09:24:01,375] - --- cost time: 3.4112s ---
[2020-03-03 09:24:01,376] - *************** test ***************
[2020-03-03 09:24:01,938] - test_loss: 2.303 | test_acc: 10.000%
[2020-03-03 09:24:01,938] - ************************************

[2020-03-03 09:24:01,955] - ========== epoch: [4/50] ==========
[2020-03-03 09:24:02,886] - step: [100/391], train_loss: 2.303 | train_acc:  9.836% | lr: 0.020000
[2020-03-03 09:24:03,732] - step: [200/391], train_loss: 2.303 | train_acc:  9.891% | lr: 0.020000
[2020-03-03 09:24:04,578] - step: [300/391], train_loss: 2.303 | train_acc:  9.958% | lr: 0.020000
[2020-03-03 09:24:05,369] - --- cost time: 3.4141s ---
[2020-03-03 09:24:05,369] - *************** test ***************
[2020-03-03 09:24:05,901] - test_loss: 2.303 | test_acc: 10.000%
[2020-03-03 09:24:05,901] - ************************************

[2020-03-03 09:24:05,919] - ========== epoch: [5/50] ==========
[2020-03-03 09:24:06,874] - step: [100/391], train_loss: 2.303 | train_acc: 10.172% | lr: 0.020000
[2020-03-03 09:24:07,715] - step: [200/391], train_loss: 2.303 | train_acc: 10.211% | lr: 0.020000
[2020-03-03 09:24:08,593] - step: [300/391], train_loss: 2.303 | train_acc: 10.023% | lr: 0.020000
[2020-03-03 09:24:09,412] - --- cost time: 3.4925s ---
[2020-03-03 09:24:09,412] - *************** test ***************
[2020-03-03 09:24:09,930] - test_loss: 2.303 | test_acc: 10.000%
[2020-03-03 09:24:09,930] - ************************************

[2020-03-03 09:24:09,946] - ========== epoch: [6/50] ==========
[2020-03-03 09:24:10,880] - step: [100/391], train_loss: 2.303 | train_acc:  9.914% | lr: 0.020000
[2020-03-03 09:24:11,733] - step: [200/391], train_loss: 2.303 | train_acc: 10.012% | lr: 0.020000
[2020-03-03 09:24:12,590] - step: [300/391], train_loss: 2.303 | train_acc: 10.013% | lr: 0.020000
[2020-03-03 09:24:13,374] - --- cost time: 3.4285s ---
[2020-03-03 09:24:13,375] - *************** test ***************
[2020-03-03 09:24:13,902] - test_loss: 2.303 | test_acc: 10.000%
[2020-03-03 09:24:13,902] - ************************************

[2020-03-03 09:24:13,919] - ========== epoch: [7/50] ==========
[2020-03-03 09:24:14,847] - step: [100/391], train_loss: 2.303 | train_acc: 10.094% | lr: 0.020000
[2020-03-03 09:24:15,686] - step: [200/391], train_loss: 2.303 | train_acc: 10.230% | lr: 0.020000
[2020-03-03 09:24:16,525] - step: [300/391], train_loss: 2.303 | train_acc: 10.182% | lr: 0.020000
[2020-03-03 09:24:17,305] - --- cost time: 3.3857s ---
[2020-03-03 09:24:17,305] - *************** test ***************
[2020-03-03 09:24:17,832] - test_loss: 2.303 | test_acc: 10.000%
[2020-03-03 09:24:17,832] - ************************************

[2020-03-03 09:24:17,848] - ========== epoch: [8/50] ==========
[2020-03-03 09:24:18,773] - step: [100/391], train_loss: 2.303 | train_acc:  9.898% | lr: 0.020000
[2020-03-03 09:24:19,612] - step: [200/391], train_loss: 2.303 | train_acc:  9.980% | lr: 0.020000
[2020-03-03 09:24:20,447] - step: [300/391], train_loss: 2.303 | train_acc:  9.956% | lr: 0.020000
[2020-03-03 09:24:21,227] - --- cost time: 3.3787s ---
[2020-03-03 09:24:21,228] - *************** test ***************
[2020-03-03 09:24:21,747] - test_loss: 2.303 | test_acc: 10.000%
[2020-03-03 09:24:21,747] - ************************************

[2020-03-03 09:24:21,761] - ========== epoch: [9/50] ==========
[2020-03-03 09:24:22,686] - step: [100/391], train_loss: 2.303 | train_acc: 10.141% | lr: 0.020000
[2020-03-03 09:24:23,524] - step: [200/391], train_loss: 2.303 | train_acc: 10.172% | lr: 0.020000
[2020-03-03 09:24:24,363] - step: [300/391], train_loss: 2.303 | train_acc: 10.102% | lr: 0.020000
[2020-03-03 09:24:25,141] - --- cost time: 3.3805s ---
[2020-03-03 09:24:25,142] - *************** test ***************
[2020-03-03 09:24:25,691] - test_loss: 2.303 | test_acc: 10.000%
[2020-03-03 09:24:25,692] - ************************************

[2020-03-03 09:24:25,708] - ========== epoch: [10/50] ==========
[2020-03-03 09:24:26,632] - step: [100/391], train_loss: 2.303 | train_acc: 10.297% | lr: 0.020000
[2020-03-03 09:24:27,469] - step: [200/391], train_loss: 2.303 | train_acc: 10.168% | lr: 0.020000
[2020-03-03 09:24:28,311] - step: [300/391], train_loss: 2.303 | train_acc:  9.922% | lr: 0.020000
[2020-03-03 09:24:29,097] - --- cost time: 3.3883s ---
[2020-03-03 09:24:29,097] - *************** test ***************
[2020-03-03 09:24:29,620] - test_loss: 2.303 | test_acc: 10.000%
[2020-03-03 09:24:29,620] - ************************************

[2020-03-03 09:24:29,810] - ========== epoch: [11/50] ==========
[2020-03-03 09:24:30,740] - step: [100/391], train_loss: 2.303 | train_acc:  9.734% | lr: 0.020000
[2020-03-03 09:24:31,578] - step: [200/391], train_loss: 2.303 | train_acc:  9.895% | lr: 0.020000
[2020-03-03 09:24:32,417] - step: [300/391], train_loss: 2.303 | train_acc:  9.961% | lr: 0.020000
[2020-03-03 09:24:33,198] - --- cost time: 3.3875s ---
[2020-03-03 09:24:33,198] - *************** test ***************
[2020-03-03 09:24:33,730] - test_loss: 2.303 | test_acc: 10.000%
[2020-03-03 09:24:33,730] - ************************************

[2020-03-03 09:24:33,746] - ========== epoch: [12/50] ==========
[2020-03-03 09:24:34,681] - step: [100/391], train_loss: 2.303 | train_acc:  9.938% | lr: 0.020000
[2020-03-03 09:24:35,529] - step: [200/391], train_loss: 2.303 | train_acc: 10.012% | lr: 0.020000
[2020-03-03 09:24:36,386] - step: [300/391], train_loss: 2.303 | train_acc: 10.034% | lr: 0.020000
[2020-03-03 09:24:37,170] - --- cost time: 3.4239s ---
[2020-03-03 09:24:37,171] - *************** test ***************
[2020-03-03 09:24:37,701] - test_loss: 2.303 | test_acc: 10.000%
[2020-03-03 09:24:37,702] - ************************************

[2020-03-03 09:24:37,718] - ========== epoch: [13/50] ==========
[2020-03-03 09:24:38,653] - step: [100/391], train_loss: 2.303 | train_acc: 10.062% | lr: 0.020000
[2020-03-03 09:24:39,507] - step: [200/391], train_loss: 2.303 | train_acc: 10.137% | lr: 0.020000
[2020-03-03 09:24:58,839] - {'architecture': 'nin', 'ckpt_path': './', 'ckpt_name': 'nin', 'log_path': './', 'log_name': 'cifar10', 'log_color': {'train': 'blue', 'cost_time': 'yellow', 'time': 'purple', 'test': 'red'}, 'data_name': 'CIFAR10', 'num_classes': 10, 'train_set_path': './data/cifar-10', 'test_set_path': './data/cifar-10', 'augmentation': {'normalize': True, 'random_crop': True, 'random_horizontal_filp': True}, 'device': 'cuda', 'input_size': 32, 'batch_size': 128, 'num_epochs': 50, 'num_print': 100, 'num_workers': 4, 'eval_freq': 1, 'test_batch': 200, 'optimizer': {'name': 'Adam', 'params': {'lr': 0.005}}, 'lr_scheduler': {'type': 'STEP', 'lr_epochs': [40], 'lr_mults': 0.1}, 'learning_curve': {'style': 'ggplot', 'xtick_step': 5, 'draw_freq': 10, 'save_path': './'}}
NiN(
  (features): Sequential(
    (0): Sequential(
      (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2))
      (1): ReLU(inplace)
      (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU(inplace)
      (4): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
      (5): ReLU(inplace)
    )
    (1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (2): Sequential(
      (0): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
      (1): ReLU(inplace)
      (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU(inplace)
      (4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (5): ReLU(inplace)
    )
    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Sequential(
      (0): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace)
      (2): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU(inplace)
      (4): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
      (5): ReLU(inplace)
    )
    (5): Dropout(p=0.5)
    (6): Sequential(
      (0): Conv2d(384, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace)
      (2): Conv2d(10, 10, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU(inplace)
      (4): Conv2d(10, 10, kernel_size=(1, 1), stride=(1, 1))
      (5): ReLU(inplace)
    )
  )
  (classifier): AdaptiveAvgPool2d(output_size=(1, 1))
)
-------------------- Training parameters: 1994662 --------------------
[2020-03-03 09:24:58,839] - ========== epoch: [1/50] ==========
[2020-03-03 09:25:00,002] - step: [100/391], train_loss: 2.284 | train_acc: 13.219% | lr: 0.005000
[2020-03-03 09:25:00,848] - step: [200/391], train_loss: 2.264 | train_acc: 15.195% | lr: 0.005000
[2020-03-03 09:25:01,693] - step: [300/391], train_loss: 2.245 | train_acc: 15.964% | lr: 0.005000
[2020-03-03 09:25:02,476] - --- cost time: 3.6368s ---
[2020-03-03 09:25:02,477] - *************** test ***************
[2020-03-03 09:25:03,004] - test_loss: 2.175 | test_acc: 21.170%
[2020-03-03 09:25:03,005] - ************************************

[2020-03-03 09:25:03,048] - ========== epoch: [2/50] ==========
[2020-03-03 09:25:03,978] - step: [100/391], train_loss: 2.153 | train_acc: 20.828% | lr: 0.005000
[2020-03-03 09:25:04,822] - step: [200/391], train_loss: 2.110 | train_acc: 21.742% | lr: 0.005000
[2020-03-03 09:25:05,677] - step: [300/391], train_loss: 2.080 | train_acc: 23.010% | lr: 0.005000
[2020-03-03 09:25:06,457] - --- cost time: 3.4085s ---
[2020-03-03 09:25:06,457] - *************** test ***************
[2020-03-03 09:25:07,012] - test_loss: 1.975 | test_acc: 27.900%
[2020-03-03 09:25:07,012] - ************************************

[2020-03-03 09:25:07,063] - ========== epoch: [3/50] ==========
[2020-03-03 09:25:07,996] - step: [100/391], train_loss: 1.976 | train_acc: 27.523% | lr: 0.005000
[2020-03-03 09:25:08,836] - step: [200/391], train_loss: 1.961 | train_acc: 28.762% | lr: 0.005000
[2020-03-03 09:25:09,678] - step: [300/391], train_loss: 1.944 | train_acc: 29.872% | lr: 0.005000
[2020-03-03 09:25:10,476] - --- cost time: 3.4125s ---
[2020-03-03 09:25:10,476] - *************** test ***************
[2020-03-03 09:25:11,004] - test_loss: 1.900 | test_acc: 32.240%
[2020-03-03 09:25:11,004] - ************************************

[2020-03-03 09:25:11,051] - ========== epoch: [4/50] ==========
[2020-03-03 09:25:11,979] - step: [100/391], train_loss: 1.872 | train_acc: 33.188% | lr: 0.005000
[2020-03-03 09:25:12,823] - step: [200/391], train_loss: 1.870 | train_acc: 33.652% | lr: 0.005000
[2020-03-03 09:25:13,665] - step: [300/391], train_loss: 1.860 | train_acc: 34.318% | lr: 0.005000
[2020-03-03 09:25:14,448] - --- cost time: 3.3971s ---
[2020-03-03 09:25:14,448] - *************** test ***************
[2020-03-03 09:25:14,982] - test_loss: 1.806 | test_acc: 34.870%
[2020-03-03 09:25:14,982] - ************************************

[2020-03-03 09:25:15,029] - ========== epoch: [5/50] ==========
[2020-03-03 09:25:15,962] - step: [100/391], train_loss: 1.805 | train_acc: 37.297% | lr: 0.005000
[2020-03-03 09:25:16,804] - step: [200/391], train_loss: 1.803 | train_acc: 36.957% | lr: 0.005000
[2020-03-03 09:25:17,647] - step: [300/391], train_loss: 1.796 | train_acc: 37.247% | lr: 0.005000
[2020-03-03 09:25:18,432] - --- cost time: 3.4029s ---
[2020-03-03 09:25:18,433] - *************** test ***************
[2020-03-03 09:25:18,973] - test_loss: 1.746 | test_acc: 39.280%
[2020-03-03 09:25:18,973] - ************************************

[2020-03-03 09:25:19,027] - ========== epoch: [6/50] ==========
[2020-03-03 09:25:19,976] - step: [100/391], train_loss: 1.782 | train_acc: 37.922% | lr: 0.005000
[2020-03-03 09:25:20,817] - step: [200/391], train_loss: 1.768 | train_acc: 38.535% | lr: 0.005000
[2020-03-03 09:25:21,657] - step: [300/391], train_loss: 1.767 | train_acc: 38.573% | lr: 0.005000
[2020-03-03 09:25:22,444] - --- cost time: 3.4155s ---
[2020-03-03 09:25:22,444] - *************** test ***************
[2020-03-03 09:25:22,977] - test_loss: 1.804 | test_acc: 38.110%
[2020-03-03 09:25:22,977] - ************************************

[2020-03-03 09:25:23,002] - ========== epoch: [7/50] ==========
[2020-03-03 09:25:23,933] - step: [100/391], train_loss: 1.757 | train_acc: 39.055% | lr: 0.005000
[2020-03-03 09:25:24,776] - step: [200/391], train_loss: 1.745 | train_acc: 39.500% | lr: 0.005000
[2020-03-03 09:25:25,620] - step: [300/391], train_loss: 1.743 | train_acc: 39.685% | lr: 0.005000
[2020-03-03 09:25:26,404] - --- cost time: 3.4014s ---
[2020-03-03 09:25:26,404] - *************** test ***************
[2020-03-03 09:25:26,937] - test_loss: 1.695 | test_acc: 40.770%
[2020-03-03 09:25:26,937] - ************************************

[2020-03-03 09:25:26,983] - ========== epoch: [8/50] ==========
[2020-03-03 09:25:27,914] - step: [100/391], train_loss: 1.730 | train_acc: 39.875% | lr: 0.005000
[2020-03-03 09:25:28,756] - step: [200/391], train_loss: 1.729 | train_acc: 40.254% | lr: 0.005000
[2020-03-03 09:25:29,599] - step: [300/391], train_loss: 1.722 | train_acc: 40.536% | lr: 0.005000
[2020-03-03 09:25:30,384] - --- cost time: 3.4001s ---
[2020-03-03 09:25:30,384] - *************** test ***************
[2020-03-03 09:25:30,923] - test_loss: 1.729 | test_acc: 40.790%
[2020-03-03 09:25:30,923] - ************************************

[2020-03-03 09:25:30,974] - ========== epoch: [9/50] ==========
[2020-03-03 09:25:31,927] - step: [100/391], train_loss: 1.725 | train_acc: 40.711% | lr: 0.005000
[2020-03-03 09:25:32,769] - step: [200/391], train_loss: 1.737 | train_acc: 40.496% | lr: 0.005000
[2020-03-03 09:25:33,614] - step: [300/391], train_loss: 1.736 | train_acc: 40.589% | lr: 0.005000
[2020-03-03 09:25:34,401] - --- cost time: 3.4251s ---
[2020-03-03 09:25:34,401] - *************** test ***************
[2020-03-03 09:25:34,924] - test_loss: 1.703 | test_acc: 41.490%
[2020-03-03 09:25:34,924] - ************************************

[2020-03-03 09:25:34,970] - ========== epoch: [10/50] ==========
[2020-03-03 09:25:35,904] - step: [100/391], train_loss: 1.721 | train_acc: 40.656% | lr: 0.005000
[2020-03-03 09:25:36,750] - step: [200/391], train_loss: 1.736 | train_acc: 40.039% | lr: 0.005000
[2020-03-03 09:25:37,594] - step: [300/391], train_loss: 1.726 | train_acc: 40.664% | lr: 0.005000
[2020-03-03 09:25:38,378] - --- cost time: 3.4075s ---
[2020-03-03 09:25:38,378] - *************** test ***************
[2020-03-03 09:25:38,958] - test_loss: 1.693 | test_acc: 41.770%
[2020-03-03 09:25:38,958] - ************************************

[2020-03-03 09:25:39,140] - ========== epoch: [11/50] ==========
[2020-03-03 09:25:40,081] - step: [100/391], train_loss: 1.749 | train_acc: 39.594% | lr: 0.005000
[2020-03-03 09:25:40,926] - step: [200/391], train_loss: 1.729 | train_acc: 40.582% | lr: 0.005000
[2020-03-03 09:25:41,770] - step: [300/391], train_loss: 1.734 | train_acc: 40.174% | lr: 0.005000
[2020-03-03 09:25:42,558] - --- cost time: 3.4179s ---
[2020-03-03 09:25:42,558] - *************** test ***************
[2020-03-03 09:25:43,086] - test_loss: 1.707 | test_acc: 41.510%
[2020-03-03 09:25:43,086] - ************************************

[2020-03-03 09:25:43,116] - ========== epoch: [12/50] ==========
[2020-03-03 09:25:44,079] - step: [100/391], train_loss: 1.910 | train_acc: 31.516% | lr: 0.005000
[2020-03-03 09:25:44,923] - step: [200/391], train_loss: 2.082 | train_acc: 21.551% | lr: 0.005000
[2020-03-03 09:25:45,769] - step: [300/391], train_loss: 2.156 | train_acc: 17.654% | lr: 0.005000
[2020-03-03 09:25:46,564] - --- cost time: 3.4464s ---
[2020-03-03 09:25:46,565] - *************** test ***************
[2020-03-03 09:25:47,085] - test_loss: 2.303 | test_acc: 10.000%
[2020-03-03 09:25:47,085] - ************************************

[2020-03-03 09:25:47,111] - ========== epoch: [13/50] ==========
[2020-03-03 09:25:48,043] - step: [100/391], train_loss: 2.303 | train_acc: 10.188% | lr: 0.005000
[2020-03-03 09:25:48,891] - step: [200/391], train_loss: 2.303 | train_acc: 10.070% | lr: 0.005000
[2020-03-03 09:25:49,736] - step: [300/391], train_loss: 2.303 | train_acc:  9.992% | lr: 0.005000
[2020-03-03 09:25:50,522] - --- cost time: 3.4116s ---
[2020-03-03 09:25:50,523] - *************** test ***************
[2020-03-03 09:25:51,086] - test_loss: 2.303 | test_acc: 10.000%
[2020-03-03 09:25:51,086] - ************************************

[2020-03-03 09:25:51,112] - ========== epoch: [14/50] ==========
[2020-03-03 09:25:52,046] - step: [100/391], train_loss: 2.303 | train_acc: 10.164% | lr: 0.005000
[2020-03-03 09:25:52,889] - step: [200/391], train_loss: 2.303 | train_acc: 10.035% | lr: 0.005000
[2020-03-03 09:25:53,737] - step: [300/391], train_loss: 2.303 | train_acc:  9.922% | lr: 0.005000
[2020-03-03 09:25:54,522] - --- cost time: 3.4099s ---
[2020-03-03 09:25:54,522] - *************** test ***************
[2020-03-03 09:25:55,055] - test_loss: 2.303 | test_acc: 10.000%
[2020-03-03 09:25:55,055] - ************************************

[2020-03-03 09:25:55,081] - ========== epoch: [15/50] ==========
[2020-03-03 09:25:56,030] - step: [100/391], train_loss: 2.303 | train_acc: 10.180% | lr: 0.005000
[2020-03-03 09:26:05,190] - {'architecture': 'nin', 'ckpt_path': './', 'ckpt_name': 'nin', 'log_path': './', 'log_name': 'cifar10', 'log_color': {'train': 'blue', 'cost_time': 'yellow', 'time': 'purple', 'test': 'red'}, 'data_name': 'CIFAR10', 'num_classes': 10, 'train_set_path': './data/cifar-10', 'test_set_path': './data/cifar-10', 'augmentation': {'normalize': True, 'random_crop': True, 'random_horizontal_filp': True}, 'device': 'cuda', 'input_size': 32, 'batch_size': 128, 'num_epochs': 50, 'num_print': 100, 'num_workers': 4, 'eval_freq': 1, 'test_batch': 200, 'optimizer': {'name': 'Adam', 'params': {'lr': 0.002}}, 'lr_scheduler': {'type': 'STEP', 'lr_epochs': [40], 'lr_mults': 0.1}, 'learning_curve': {'style': 'ggplot', 'xtick_step': 5, 'draw_freq': 10, 'save_path': './'}}
NiN(
  (features): Sequential(
    (0): Sequential(
      (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2))
      (1): ReLU(inplace)
      (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU(inplace)
      (4): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
      (5): ReLU(inplace)
    )
    (1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (2): Sequential(
      (0): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
      (1): ReLU(inplace)
      (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU(inplace)
      (4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (5): ReLU(inplace)
    )
    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Sequential(
      (0): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace)
      (2): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU(inplace)
      (4): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
      (5): ReLU(inplace)
    )
    (5): Dropout(p=0.5)
    (6): Sequential(
      (0): Conv2d(384, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace)
      (2): Conv2d(10, 10, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU(inplace)
      (4): Conv2d(10, 10, kernel_size=(1, 1), stride=(1, 1))
      (5): ReLU(inplace)
    )
  )
  (classifier): AdaptiveAvgPool2d(output_size=(1, 1))
)
-------------------- Training parameters: 1994662 --------------------
[2020-03-03 09:26:05,191] - ========== epoch: [1/50] ==========
[2020-03-03 09:26:06,365] - step: [100/391], train_loss: 2.251 | train_acc: 14.359% | lr: 0.002000
[2020-03-03 09:26:07,218] - step: [200/391], train_loss: 2.184 | train_acc: 17.746% | lr: 0.002000
[2020-03-03 09:26:08,065] - step: [300/391], train_loss: 2.116 | train_acc: 20.336% | lr: 0.002000
[2020-03-03 09:26:08,849] - --- cost time: 3.6577s ---
[2020-03-03 09:26:08,849] - *************** test ***************
[2020-03-03 09:26:09,387] - test_loss: 1.815 | test_acc: 28.570%
[2020-03-03 09:26:09,387] - ************************************

[2020-03-03 09:26:09,432] - ========== epoch: [2/50] ==========
[2020-03-03 09:26:10,369] - step: [100/391], train_loss: 1.776 | train_acc: 30.711% | lr: 0.002000
[2020-03-03 09:26:11,217] - step: [200/391], train_loss: 1.734 | train_acc: 32.320% | lr: 0.002000
[2020-03-03 09:26:12,082] - step: [300/391], train_loss: 1.708 | train_acc: 33.398% | lr: 0.002000
[2020-03-03 09:26:12,879] - --- cost time: 3.4468s ---
[2020-03-03 09:26:12,880] - *************** test ***************
[2020-03-03 09:26:13,435] - test_loss: 1.563 | test_acc: 39.780%
[2020-03-03 09:26:13,435] - ************************************

[2020-03-03 09:26:13,486] - ========== epoch: [3/50] ==========
[2020-03-03 09:26:14,424] - step: [100/391], train_loss: 1.584 | train_acc: 39.055% | lr: 0.002000
[2020-03-03 09:26:15,270] - step: [200/391], train_loss: 1.550 | train_acc: 40.426% | lr: 0.002000
[2020-03-03 09:26:16,117] - step: [300/391], train_loss: 1.535 | train_acc: 41.326% | lr: 0.002000
[2020-03-03 09:26:16,904] - --- cost time: 3.4184s ---
[2020-03-03 09:26:16,905] - *************** test ***************
[2020-03-03 09:26:17,429] - test_loss: 1.419 | test_acc: 46.970%
[2020-03-03 09:26:17,429] - ************************************

[2020-03-03 09:26:17,476] - ========== epoch: [4/50] ==========
[2020-03-03 09:26:18,411] - step: [100/391], train_loss: 1.417 | train_acc: 46.727% | lr: 0.002000
[2020-03-03 09:26:19,265] - step: [200/391], train_loss: 1.412 | train_acc: 47.652% | lr: 0.002000
[2020-03-03 09:26:20,128] - step: [300/391], train_loss: 1.400 | train_acc: 48.289% | lr: 0.002000
[2020-03-03 09:26:20,915] - --- cost time: 3.4390s ---
[2020-03-03 09:26:20,916] - *************** test ***************
[2020-03-03 09:26:21,438] - test_loss: 1.323 | test_acc: 52.640%
[2020-03-03 09:26:21,438] - ************************************

[2020-03-03 09:26:21,490] - ========== epoch: [5/50] ==========
[2020-03-03 09:26:22,462] - step: [100/391], train_loss: 1.312 | train_acc: 52.844% | lr: 0.002000
[2020-03-03 09:26:23,332] - step: [200/391], train_loss: 1.299 | train_acc: 53.164% | lr: 0.002000
[2020-03-03 09:26:24,186] - step: [300/391], train_loss: 1.287 | train_acc: 53.859% | lr: 0.002000
[2020-03-03 09:26:24,981] - --- cost time: 3.4900s ---
[2020-03-03 09:26:24,982] - *************** test ***************
[2020-03-03 09:26:25,508] - test_loss: 1.226 | test_acc: 56.800%
[2020-03-03 09:26:25,508] - ************************************

[2020-03-03 09:26:25,555] - ========== epoch: [6/50] ==========
[2020-03-03 09:26:26,510] - step: [100/391], train_loss: 1.223 | train_acc: 56.023% | lr: 0.002000
[2020-03-03 09:26:27,368] - step: [200/391], train_loss: 1.208 | train_acc: 56.598% | lr: 0.002000
[2020-03-03 09:26:28,216] - step: [300/391], train_loss: 1.197 | train_acc: 57.250% | lr: 0.002000
[2020-03-03 09:26:29,027] - --- cost time: 3.4723s ---
[2020-03-03 09:26:29,027] - *************** test ***************
[2020-03-03 09:26:29,562] - test_loss: 1.166 | test_acc: 59.370%
[2020-03-03 09:26:29,562] - ************************************

[2020-03-03 09:26:29,609] - ========== epoch: [7/50] ==========
[2020-03-03 09:26:30,554] - step: [100/391], train_loss: 1.142 | train_acc: 59.602% | lr: 0.002000
[2020-03-03 09:26:31,410] - step: [200/391], train_loss: 1.145 | train_acc: 59.465% | lr: 0.002000
[2020-03-03 09:26:32,257] - step: [300/391], train_loss: 1.143 | train_acc: 59.643% | lr: 0.002000
[2020-03-03 09:26:33,066] - --- cost time: 3.4563s ---
[2020-03-03 09:26:33,066] - *************** test ***************
[2020-03-03 09:26:33,591] - test_loss: 1.145 | test_acc: 60.010%
[2020-03-03 09:26:33,591] - ************************************

[2020-03-03 09:26:33,643] - ========== epoch: [8/50] ==========
[2020-03-03 09:26:34,583] - step: [100/391], train_loss: 1.108 | train_acc: 60.977% | lr: 0.002000
[2020-03-03 09:26:35,428] - step: [200/391], train_loss: 1.099 | train_acc: 61.309% | lr: 0.002000
[2020-03-03 09:26:36,278] - step: [300/391], train_loss: 1.085 | train_acc: 61.729% | lr: 0.002000
[2020-03-03 09:26:37,067] - --- cost time: 3.4244s ---
[2020-03-03 09:26:37,068] - *************** test ***************
[2020-03-03 09:26:37,589] - test_loss: 1.084 | test_acc: 61.480%
[2020-03-03 09:26:37,589] - ************************************

[2020-03-03 09:26:37,636] - ========== epoch: [9/50] ==========
[2020-03-03 09:26:38,573] - step: [100/391], train_loss: 1.041 | train_acc: 63.211% | lr: 0.002000
[2020-03-03 09:26:39,417] - step: [200/391], train_loss: 1.037 | train_acc: 63.375% | lr: 0.002000
[2020-03-03 09:26:40,264] - step: [300/391], train_loss: 1.037 | train_acc: 63.245% | lr: 0.002000
[2020-03-03 09:26:41,058] - --- cost time: 3.4214s ---
[2020-03-03 09:26:41,058] - *************** test ***************
[2020-03-03 09:26:41,590] - test_loss: 1.046 | test_acc: 63.050%
[2020-03-03 09:26:41,590] - ************************************

[2020-03-03 09:26:41,637] - ========== epoch: [10/50] ==========
[2020-03-03 09:26:42,580] - step: [100/391], train_loss: 0.997 | train_acc: 64.664% | lr: 0.002000
[2020-03-03 09:26:43,431] - step: [200/391], train_loss: 1.000 | train_acc: 64.953% | lr: 0.002000
[2020-03-03 09:26:44,278] - step: [300/391], train_loss: 1.005 | train_acc: 64.771% | lr: 0.002000
[2020-03-03 09:26:45,065] - --- cost time: 3.4280s ---
[2020-03-03 09:26:45,065] - *************** test ***************
[2020-03-03 09:26:45,589] - test_loss: 1.022 | test_acc: 65.030%
[2020-03-03 09:26:45,589] - ************************************

[2020-03-03 09:26:45,777] - ========== epoch: [11/50] ==========
[2020-03-03 09:26:46,718] - step: [100/391], train_loss: 0.990 | train_acc: 65.398% | lr: 0.002000
[2020-03-03 09:26:47,566] - step: [200/391], train_loss: 0.970 | train_acc: 66.145% | lr: 0.002000
[2020-03-03 09:26:48,416] - step: [300/391], train_loss: 0.970 | train_acc: 66.326% | lr: 0.002000
[2020-03-03 09:26:49,205] - --- cost time: 3.4278s ---
[2020-03-03 09:26:49,205] - *************** test ***************
[2020-03-03 09:26:49,747] - test_loss: 1.038 | test_acc: 64.860%
[2020-03-03 09:26:49,747] - ************************************

[2020-03-03 09:26:49,773] - ========== epoch: [12/50] ==========
[2020-03-03 09:26:50,712] - step: [100/391], train_loss: 0.938 | train_acc: 66.586% | lr: 0.002000
[2020-03-03 09:26:51,562] - step: [200/391], train_loss: 0.936 | train_acc: 66.918% | lr: 0.002000
[2020-03-03 09:26:52,414] - step: [300/391], train_loss: 0.939 | train_acc: 66.906% | lr: 0.002000
[2020-03-03 09:26:53,204] - --- cost time: 3.4311s ---
[2020-03-03 09:26:53,205] - *************** test ***************
[2020-03-03 09:26:53,726] - test_loss: 0.960 | test_acc: 66.830%
[2020-03-03 09:26:53,726] - ************************************

[2020-03-03 09:26:53,773] - ========== epoch: [13/50] ==========
[2020-03-03 09:26:54,713] - step: [100/391], train_loss: 0.923 | train_acc: 67.711% | lr: 0.002000
[2020-03-03 09:26:55,564] - step: [200/391], train_loss: 0.917 | train_acc: 67.773% | lr: 0.002000
[2020-03-03 09:26:56,416] - step: [300/391], train_loss: 0.915 | train_acc: 67.932% | lr: 0.002000
[2020-03-03 09:26:57,205] - --- cost time: 3.4313s ---
[2020-03-03 09:26:57,205] - *************** test ***************
[2020-03-03 09:26:57,736] - test_loss: 0.948 | test_acc: 67.340%
[2020-03-03 09:26:57,736] - ************************************

[2020-03-03 09:26:57,789] - ========== epoch: [14/50] ==========
[2020-03-03 09:26:58,745] - step: [100/391], train_loss: 0.889 | train_acc: 68.961% | lr: 0.002000
[2020-03-03 09:26:59,595] - step: [200/391], train_loss: 0.892 | train_acc: 68.980% | lr: 0.002000
[2020-03-03 09:27:00,495] - step: [300/391], train_loss: 0.890 | train_acc: 69.177% | lr: 0.002000
[2020-03-03 09:27:01,290] - --- cost time: 3.4994s ---
[2020-03-03 09:27:01,290] - *************** test ***************
[2020-03-03 09:27:01,821] - test_loss: 0.907 | test_acc: 68.580%
[2020-03-03 09:27:01,821] - ************************************

[2020-03-03 09:27:01,866] - ========== epoch: [15/50] ==========
[2020-03-03 09:27:02,816] - step: [100/391], train_loss: 0.860 | train_acc: 70.234% | lr: 0.002000
[2020-03-03 09:27:03,667] - step: [200/391], train_loss: 0.866 | train_acc: 70.176% | lr: 0.002000
[2020-03-03 09:27:04,518] - step: [300/391], train_loss: 0.863 | train_acc: 70.198% | lr: 0.002000
[2020-03-03 09:27:05,310] - --- cost time: 3.4440s ---
[2020-03-03 09:27:05,311] - *************** test ***************
[2020-03-03 09:27:05,861] - test_loss: 0.910 | test_acc: 69.060%
[2020-03-03 09:27:05,861] - ************************************

[2020-03-03 09:27:05,906] - ========== epoch: [16/50] ==========
[2020-03-03 09:27:06,849] - step: [100/391], train_loss: 0.825 | train_acc: 71.414% | lr: 0.002000
[2020-03-03 09:27:07,699] - step: [200/391], train_loss: 0.837 | train_acc: 70.906% | lr: 0.002000
[2020-03-03 09:27:08,551] - step: [300/391], train_loss: 0.843 | train_acc: 70.622% | lr: 0.002000
[2020-03-03 09:27:09,344] - --- cost time: 3.4378s ---
[2020-03-03 09:27:09,345] - *************** test ***************
[2020-03-03 09:27:09,901] - test_loss: 0.947 | test_acc: 67.930%
[2020-03-03 09:27:09,901] - ************************************

[2020-03-03 09:27:09,932] - ========== epoch: [17/50] ==========
[2020-03-03 09:27:10,877] - step: [100/391], train_loss: 0.825 | train_acc: 71.109% | lr: 0.002000
[2020-03-03 09:27:11,738] - step: [200/391], train_loss: 0.825 | train_acc: 71.141% | lr: 0.002000
[2020-03-03 09:27:12,615] - step: [300/391], train_loss: 0.833 | train_acc: 71.208% | lr: 0.002000
[2020-03-03 09:27:13,417] - --- cost time: 3.4849s ---
[2020-03-03 09:27:13,417] - *************** test ***************
[2020-03-03 09:27:13,979] - test_loss: 0.887 | test_acc: 69.120%
[2020-03-03 09:27:13,980] - ************************************

[2020-03-03 09:27:14,033] - ========== epoch: [18/50] ==========
[2020-03-03 09:27:14,979] - step: [100/391], train_loss: 0.832 | train_acc: 71.383% | lr: 0.002000
[2020-03-03 09:27:15,827] - step: [200/391], train_loss: 0.817 | train_acc: 71.848% | lr: 0.002000
[2020-03-03 09:27:16,676] - step: [300/391], train_loss: 0.814 | train_acc: 72.018% | lr: 0.002000
[2020-03-03 09:27:17,465] - --- cost time: 3.4321s ---
[2020-03-03 09:27:17,466] - *************** test ***************
[2020-03-03 09:27:18,001] - test_loss: 0.884 | test_acc: 69.630%
[2020-03-03 09:27:18,001] - ************************************

[2020-03-03 09:27:18,065] - ========== epoch: [19/50] ==========
[2020-03-03 09:27:19,009] - step: [100/391], train_loss: 0.799 | train_acc: 72.336% | lr: 0.002000
[2020-03-03 09:27:19,861] - step: [200/391], train_loss: 0.793 | train_acc: 72.590% | lr: 0.002000
[2020-03-03 09:27:20,708] - step: [300/391], train_loss: 0.798 | train_acc: 72.255% | lr: 0.002000
[2020-03-03 09:27:21,498] - --- cost time: 3.4324s ---
[2020-03-03 09:27:21,498] - *************** test ***************
[2020-03-03 09:27:22,022] - test_loss: 0.825 | test_acc: 71.540%
[2020-03-03 09:27:22,022] - ************************************

[2020-03-03 09:27:22,074] - ========== epoch: [20/50] ==========
[2020-03-03 09:27:23,014] - step: [100/391], train_loss: 0.804 | train_acc: 72.562% | lr: 0.002000
[2020-03-03 09:27:23,863] - step: [200/391], train_loss: 0.790 | train_acc: 73.031% | lr: 0.002000
[2020-03-03 09:27:24,711] - step: [300/391], train_loss: 0.793 | train_acc: 72.969% | lr: 0.002000
[2020-03-03 09:27:25,501] - --- cost time: 3.4260s ---
[2020-03-03 09:27:25,501] - *************** test ***************
[2020-03-03 09:27:26,023] - test_loss: 0.860 | test_acc: 71.740%
[2020-03-03 09:27:26,023] - ************************************

[2020-03-03 09:27:26,193] - ========== epoch: [21/50] ==========
[2020-03-03 09:27:27,135] - step: [100/391], train_loss: 0.783 | train_acc: 73.008% | lr: 0.002000
[2020-03-03 09:27:27,984] - step: [200/391], train_loss: 0.780 | train_acc: 73.191% | lr: 0.002000
[2020-03-03 09:27:28,831] - step: [300/391], train_loss: 0.785 | train_acc: 73.091% | lr: 0.002000
[2020-03-03 09:27:29,633] - --- cost time: 3.4396s ---
[2020-03-03 09:27:29,633] - *************** test ***************
[2020-03-03 09:27:30,159] - test_loss: 0.839 | test_acc: 71.120%
[2020-03-03 09:27:30,159] - ************************************

[2020-03-03 09:27:30,185] - ========== epoch: [22/50] ==========
[2020-03-03 09:27:31,123] - step: [100/391], train_loss: 0.783 | train_acc: 73.555% | lr: 0.002000
[2020-03-03 09:27:31,972] - step: [200/391], train_loss: 0.776 | train_acc: 73.672% | lr: 0.002000
[2020-03-03 09:27:32,822] - step: [300/391], train_loss: 0.776 | train_acc: 73.630% | lr: 0.002000
[2020-03-03 09:27:33,611] - --- cost time: 3.4258s ---
[2020-03-03 09:27:33,611] - *************** test ***************
[2020-03-03 09:27:34,162] - test_loss: 0.817 | test_acc: 72.730%
[2020-03-03 09:27:34,162] - ************************************

[2020-03-03 09:27:34,206] - ========== epoch: [23/50] ==========
[2020-03-03 09:27:35,146] - step: [100/391], train_loss: 0.746 | train_acc: 74.234% | lr: 0.002000
[2020-03-03 09:27:35,993] - step: [200/391], train_loss: 0.743 | train_acc: 74.496% | lr: 0.002000
[2020-03-03 09:27:36,842] - step: [300/391], train_loss: 0.753 | train_acc: 74.255% | lr: 0.002000
[2020-03-03 09:27:37,632] - --- cost time: 3.4255s ---
[2020-03-03 09:27:37,632] - *************** test ***************
[2020-03-03 09:27:38,157] - test_loss: 0.843 | test_acc: 71.130%
[2020-03-03 09:27:38,158] - ************************************

[2020-03-03 09:27:38,190] - ========== epoch: [24/50] ==========
[2020-03-03 09:27:39,145] - step: [100/391], train_loss: 0.744 | train_acc: 74.422% | lr: 0.002000
[2020-03-03 09:27:39,992] - step: [200/391], train_loss: 0.761 | train_acc: 73.961% | lr: 0.002000
[2020-03-03 09:27:40,840] - step: [300/391], train_loss: 0.757 | train_acc: 73.977% | lr: 0.002000
[2020-03-03 09:27:41,630] - --- cost time: 3.4388s ---
[2020-03-03 09:27:41,630] - *************** test ***************
[2020-03-03 09:27:42,149] - test_loss: 0.815 | test_acc: 72.190%
[2020-03-03 09:27:42,149] - ************************************

[2020-03-03 09:27:42,175] - ========== epoch: [25/50] ==========
[2020-03-03 09:27:43,111] - step: [100/391], train_loss: 0.728 | train_acc: 75.070% | lr: 0.002000
[2020-03-03 09:27:43,958] - step: [200/391], train_loss: 0.738 | train_acc: 74.883% | lr: 0.002000
[2020-03-03 09:27:44,805] - step: [300/391], train_loss: 0.743 | train_acc: 74.690% | lr: 0.002000
[2020-03-03 09:27:45,594] - --- cost time: 3.4193s ---
[2020-03-03 09:27:45,594] - *************** test ***************
[2020-03-03 09:27:46,148] - test_loss: 0.809 | test_acc: 73.180%
[2020-03-03 09:27:46,148] - ************************************

[2020-03-03 09:27:46,195] - ========== epoch: [26/50] ==========
[2020-03-03 09:27:47,135] - step: [100/391], train_loss: 0.734 | train_acc: 74.844% | lr: 0.002000
[2020-03-03 09:27:47,983] - step: [200/391], train_loss: 0.742 | train_acc: 74.590% | lr: 0.002000
[2020-03-03 09:27:48,832] - step: [300/391], train_loss: 0.740 | train_acc: 74.794% | lr: 0.002000
[2020-03-03 09:27:49,622] - --- cost time: 3.4258s ---
[2020-03-03 09:27:49,622] - *************** test ***************
[2020-03-03 09:27:50,149] - test_loss: 0.820 | test_acc: 72.960%
[2020-03-03 09:27:50,149] - ************************************

[2020-03-03 09:27:50,175] - ========== epoch: [27/50] ==========
[2020-03-03 09:27:51,116] - step: [100/391], train_loss: 0.719 | train_acc: 75.906% | lr: 0.002000
[2020-03-03 09:27:51,963] - step: [200/391], train_loss: 0.725 | train_acc: 75.441% | lr: 0.002000
[2020-03-03 09:27:52,810] - step: [300/391], train_loss: 0.725 | train_acc: 75.396% | lr: 0.002000
[2020-03-03 09:27:53,598] - --- cost time: 3.4236s ---
[2020-03-03 09:27:53,599] - *************** test ***************
[2020-03-03 09:27:54,125] - test_loss: 0.793 | test_acc: 73.430%
[2020-03-03 09:27:54,125] - ************************************

[2020-03-03 09:27:54,195] - ========== epoch: [28/50] ==========
[2020-03-03 09:27:55,135] - step: [100/391], train_loss: 0.730 | train_acc: 74.945% | lr: 0.002000
[2020-03-03 09:27:55,986] - step: [200/391], train_loss: 0.718 | train_acc: 75.695% | lr: 0.002000
[2020-03-03 09:27:56,834] - step: [300/391], train_loss: 0.715 | train_acc: 75.729% | lr: 0.002000
[2020-03-03 09:27:57,625] - --- cost time: 3.4298s ---
[2020-03-03 09:27:57,626] - *************** test ***************
[2020-03-03 09:27:58,159] - test_loss: 0.837 | test_acc: 72.890%
[2020-03-03 09:27:58,159] - ************************************

[2020-03-03 09:27:58,185] - ========== epoch: [29/50] ==========
[2020-03-03 09:27:59,124] - step: [100/391], train_loss: 0.696 | train_acc: 76.133% | lr: 0.002000
[2020-03-03 09:27:59,973] - step: [200/391], train_loss: 0.698 | train_acc: 76.133% | lr: 0.002000
[2020-03-03 09:28:00,824] - step: [300/391], train_loss: 0.700 | train_acc: 76.234% | lr: 0.002000
[2020-03-03 09:28:01,613] - --- cost time: 3.4274s ---
[2020-03-03 09:28:01,613] - *************** test ***************
[2020-03-03 09:28:02,143] - test_loss: 0.777 | test_acc: 74.290%
[2020-03-03 09:28:02,143] - ************************************

[2020-03-03 09:28:02,188] - ========== epoch: [30/50] ==========
[2020-03-03 09:28:03,127] - step: [100/391], train_loss: 0.714 | train_acc: 75.680% | lr: 0.002000
[2020-03-03 09:28:03,974] - step: [200/391], train_loss: 0.703 | train_acc: 76.262% | lr: 0.002000
[2020-03-03 09:28:04,820] - step: [300/391], train_loss: 0.702 | train_acc: 76.299% | lr: 0.002000
[2020-03-03 09:28:05,609] - --- cost time: 3.4205s ---
[2020-03-03 09:28:05,609] - *************** test ***************
[2020-03-03 09:28:06,136] - test_loss: 0.789 | test_acc: 73.880%
[2020-03-03 09:28:06,137] - ************************************

[2020-03-03 09:28:06,294] - ========== epoch: [31/50] ==========
[2020-03-03 09:28:07,238] - step: [100/391], train_loss: 0.713 | train_acc: 76.148% | lr: 0.002000
[2020-03-03 09:28:08,088] - step: [200/391], train_loss: 0.700 | train_acc: 76.418% | lr: 0.002000
[2020-03-03 09:28:08,936] - step: [300/391], train_loss: 0.704 | train_acc: 76.411% | lr: 0.002000
[2020-03-03 09:28:09,727] - --- cost time: 3.4326s ---
[2020-03-03 09:28:09,728] - *************** test ***************
[2020-03-03 09:28:10,251] - test_loss: 0.762 | test_acc: 74.130%
[2020-03-03 09:28:10,251] - ************************************

[2020-03-03 09:28:10,276] - ========== epoch: [32/50] ==========
[2020-03-03 09:28:11,214] - step: [100/391], train_loss: 0.680 | train_acc: 76.906% | lr: 0.002000
[2020-03-03 09:28:12,060] - step: [200/391], train_loss: 0.680 | train_acc: 77.043% | lr: 0.002000
[2020-03-03 09:28:12,907] - step: [300/391], train_loss: 0.685 | train_acc: 76.810% | lr: 0.002000
[2020-03-03 09:28:13,701] - --- cost time: 3.4242s ---
[2020-03-03 09:28:13,701] - *************** test ***************
[2020-03-03 09:28:14,231] - test_loss: 0.778 | test_acc: 73.880%
[2020-03-03 09:28:14,231] - ************************************

[2020-03-03 09:28:14,257] - ========== epoch: [33/50] ==========
[2020-03-03 09:28:15,197] - step: [100/391], train_loss: 0.669 | train_acc: 76.906% | lr: 0.002000
[2020-03-03 09:28:16,046] - step: [200/391], train_loss: 0.676 | train_acc: 76.820% | lr: 0.002000
[2020-03-03 09:28:16,893] - step: [300/391], train_loss: 0.676 | train_acc: 76.922% | lr: 0.002000
[2020-03-03 09:28:17,683] - --- cost time: 3.4260s ---
[2020-03-03 09:28:17,683] - *************** test ***************
[2020-03-03 09:28:18,200] - test_loss: 0.740 | test_acc: 75.250%
[2020-03-03 09:28:18,200] - ************************************

[2020-03-03 09:28:18,247] - ========== epoch: [34/50] ==========
[2020-03-03 09:28:19,191] - step: [100/391], train_loss: 0.660 | train_acc: 77.703% | lr: 0.002000
[2020-03-03 09:28:20,034] - step: [200/391], train_loss: 0.667 | train_acc: 77.531% | lr: 0.002000
[2020-03-03 09:28:20,882] - step: [300/391], train_loss: 0.669 | train_acc: 77.398% | lr: 0.002000
[2020-03-03 09:28:21,668] - --- cost time: 3.4212s ---
[2020-03-03 09:28:21,669] - *************** test ***************
[2020-03-03 09:28:22,240] - test_loss: 0.741 | test_acc: 75.190%
[2020-03-03 09:28:22,240] - ************************************

[2020-03-03 09:28:22,265] - ========== epoch: [35/50] ==========
[2020-03-03 09:28:23,203] - step: [100/391], train_loss: 0.660 | train_acc: 77.516% | lr: 0.002000
[2020-03-03 09:28:24,052] - step: [200/391], train_loss: 0.665 | train_acc: 77.418% | lr: 0.002000
[2020-03-03 09:28:24,899] - step: [300/391], train_loss: 0.668 | train_acc: 77.430% | lr: 0.002000
[2020-03-03 09:28:25,690] - --- cost time: 3.4242s ---
[2020-03-03 09:28:25,690] - *************** test ***************
[2020-03-03 09:28:26,213] - test_loss: 0.821 | test_acc: 73.590%
[2020-03-03 09:28:26,214] - ************************************

[2020-03-03 09:28:26,245] - ========== epoch: [36/50] ==========
[2020-03-03 09:28:27,207] - step: [100/391], train_loss: 0.671 | train_acc: 77.523% | lr: 0.002000
[2020-03-03 09:28:28,054] - step: [200/391], train_loss: 0.668 | train_acc: 77.477% | lr: 0.002000
[2020-03-03 09:28:28,903] - step: [300/391], train_loss: 0.668 | train_acc: 77.474% | lr: 0.002000
[2020-03-03 09:28:29,694] - --- cost time: 3.4481s ---
[2020-03-03 09:28:29,694] - *************** test ***************
[2020-03-03 09:28:30,222] - test_loss: 0.768 | test_acc: 74.570%
[2020-03-03 09:28:30,222] - ************************************

[2020-03-03 09:28:30,248] - ========== epoch: [37/50] ==========
[2020-03-03 09:28:31,188] - step: [100/391], train_loss: 0.646 | train_acc: 78.117% | lr: 0.002000
[2020-03-03 09:28:32,034] - step: [200/391], train_loss: 0.647 | train_acc: 78.074% | lr: 0.002000
[2020-03-03 09:28:32,881] - step: [300/391], train_loss: 0.652 | train_acc: 77.896% | lr: 0.002000
[2020-03-03 09:28:33,671] - --- cost time: 3.4229s ---
[2020-03-03 09:28:33,671] - *************** test ***************
[2020-03-03 09:28:34,192] - test_loss: 0.798 | test_acc: 73.780%
[2020-03-03 09:28:34,192] - ************************************

[2020-03-03 09:28:34,218] - ========== epoch: [38/50] ==========
[2020-03-03 09:28:35,159] - step: [100/391], train_loss: 0.644 | train_acc: 78.352% | lr: 0.002000
[2020-03-03 09:28:36,010] - step: [200/391], train_loss: 0.646 | train_acc: 78.215% | lr: 0.002000
[2020-03-03 09:28:36,862] - step: [300/391], train_loss: 0.656 | train_acc: 77.945% | lr: 0.002000
[2020-03-03 09:28:37,652] - --- cost time: 3.4335s ---
[2020-03-03 09:28:37,652] - *************** test ***************
[2020-03-03 09:28:38,182] - test_loss: 0.783 | test_acc: 74.570%
[2020-03-03 09:28:38,182] - ************************************

[2020-03-03 09:28:38,207] - ========== epoch: [39/50] ==========
[2020-03-03 09:28:39,145] - step: [100/391], train_loss: 0.644 | train_acc: 78.109% | lr: 0.002000
[2020-03-03 09:28:39,992] - step: [200/391], train_loss: 0.654 | train_acc: 77.934% | lr: 0.002000
[2020-03-03 09:28:40,838] - step: [300/391], train_loss: 0.665 | train_acc: 77.643% | lr: 0.002000
[2020-03-03 09:28:41,643] - --- cost time: 3.4349s ---
[2020-03-03 09:28:41,643] - *************** test ***************
[2020-03-03 09:28:42,166] - test_loss: 0.757 | test_acc: 74.920%
[2020-03-03 09:28:42,166] - ************************************

[2020-03-03 09:28:42,190] - ========== epoch: [40/50] ==========
[2020-03-03 09:28:43,129] - step: [100/391], train_loss: 0.586 | train_acc: 80.164% | lr: 0.000200
[2020-03-03 09:28:43,977] - step: [200/391], train_loss: 0.575 | train_acc: 80.422% | lr: 0.000200
[2020-03-03 09:28:44,825] - step: [300/391], train_loss: 0.568 | train_acc: 80.719% | lr: 0.000200
[2020-03-03 09:28:45,615] - --- cost time: 3.4248s ---
[2020-03-03 09:28:45,616] - *************** test ***************
[2020-03-03 09:28:46,141] - test_loss: 0.677 | test_acc: 77.750%
[2020-03-03 09:28:46,141] - ************************************

[2020-03-03 09:28:46,341] - ========== epoch: [41/50] ==========
[2020-03-03 09:28:47,286] - step: [100/391], train_loss: 0.540 | train_acc: 81.859% | lr: 0.000200
[2020-03-03 09:28:48,134] - step: [200/391], train_loss: 0.535 | train_acc: 81.836% | lr: 0.000200
[2020-03-03 09:28:48,982] - step: [300/391], train_loss: 0.538 | train_acc: 81.773% | lr: 0.000200
[2020-03-03 09:28:49,770] - --- cost time: 3.4286s ---
[2020-03-03 09:28:49,771] - *************** test ***************
[2020-03-03 09:28:50,298] - test_loss: 0.662 | test_acc: 77.370%
[2020-03-03 09:28:50,299] - ************************************

[2020-03-03 09:28:50,324] - ========== epoch: [42/50] ==========
[2020-03-03 09:28:51,264] - step: [100/391], train_loss: 0.524 | train_acc: 82.188% | lr: 0.000200
[2020-03-03 09:28:52,123] - step: [200/391], train_loss: 0.522 | train_acc: 82.289% | lr: 0.000200
[2020-03-03 09:28:52,982] - step: [300/391], train_loss: 0.526 | train_acc: 82.107% | lr: 0.000200
[2020-03-03 09:28:53,783] - --- cost time: 3.4581s ---
[2020-03-03 09:28:53,783] - *************** test ***************
[2020-03-03 09:28:54,304] - test_loss: 0.671 | test_acc: 78.200%
[2020-03-03 09:28:54,304] - ************************************

[2020-03-03 09:28:54,351] - ========== epoch: [43/50] ==========
[2020-03-03 09:28:55,296] - step: [100/391], train_loss: 0.518 | train_acc: 82.508% | lr: 0.000200
[2020-03-03 09:28:56,146] - step: [200/391], train_loss: 0.518 | train_acc: 82.363% | lr: 0.000200
[2020-03-03 09:28:56,998] - step: [300/391], train_loss: 0.515 | train_acc: 82.396% | lr: 0.000200
[2020-03-03 09:28:57,789] - --- cost time: 3.4371s ---
[2020-03-03 09:28:57,789] - *************** test ***************
[2020-03-03 09:28:58,321] - test_loss: 0.662 | test_acc: 78.190%
[2020-03-03 09:28:58,321] - ************************************

[2020-03-03 09:28:58,346] - ========== epoch: [44/50] ==========
[2020-03-03 09:28:59,291] - step: [100/391], train_loss: 0.511 | train_acc: 82.766% | lr: 0.000200
[2020-03-03 09:29:00,144] - step: [200/391], train_loss: 0.512 | train_acc: 82.555% | lr: 0.000200
[2020-03-03 09:29:01,004] - step: [300/391], train_loss: 0.510 | train_acc: 82.544% | lr: 0.000200
[2020-03-03 09:29:01,799] - --- cost time: 3.4527s ---
[2020-03-03 09:29:01,800] - *************** test ***************
[2020-03-03 09:29:02,328] - test_loss: 0.652 | test_acc: 78.330%
[2020-03-03 09:29:02,328] - ************************************

[2020-03-03 09:29:02,406] - ========== epoch: [45/50] ==========
[2020-03-03 09:29:03,351] - step: [100/391], train_loss: 0.506 | train_acc: 82.719% | lr: 0.000200
[2020-03-03 09:29:04,197] - step: [200/391], train_loss: 0.504 | train_acc: 82.789% | lr: 0.000200
[2020-03-03 09:29:05,045] - step: [300/391], train_loss: 0.504 | train_acc: 82.753% | lr: 0.000200
[2020-03-03 09:29:05,836] - --- cost time: 3.4295s ---
[2020-03-03 09:29:05,836] - *************** test ***************
[2020-03-03 09:29:06,367] - test_loss: 0.653 | test_acc: 78.510%
[2020-03-03 09:29:06,367] - ************************************

[2020-03-03 09:29:06,414] - ========== epoch: [46/50] ==========
[2020-03-03 09:29:07,355] - step: [100/391], train_loss: 0.489 | train_acc: 83.062% | lr: 0.000200
[2020-03-03 09:29:08,206] - step: [200/391], train_loss: 0.493 | train_acc: 83.059% | lr: 0.000200
[2020-03-03 09:29:09,055] - step: [300/391], train_loss: 0.496 | train_acc: 83.023% | lr: 0.000200
[2020-03-03 09:29:09,844] - --- cost time: 3.4300s ---
[2020-03-03 09:29:09,844] - *************** test ***************
[2020-03-03 09:29:10,367] - test_loss: 0.654 | test_acc: 78.420%
[2020-03-03 09:29:10,367] - ************************************

[2020-03-03 09:29:10,391] - ========== epoch: [47/50] ==========
[2020-03-03 09:29:11,333] - step: [100/391], train_loss: 0.497 | train_acc: 82.773% | lr: 0.000200
[2020-03-03 09:29:12,180] - step: [200/391], train_loss: 0.501 | train_acc: 82.871% | lr: 0.000200
[2020-03-03 09:29:13,028] - step: [300/391], train_loss: 0.499 | train_acc: 82.852% | lr: 0.000200
[2020-03-03 09:29:13,818] - --- cost time: 3.4260s ---
[2020-03-03 09:29:13,818] - *************** test ***************
[2020-03-03 09:29:14,348] - test_loss: 0.653 | test_acc: 78.450%
[2020-03-03 09:29:14,348] - ************************************

[2020-03-03 09:29:14,374] - ========== epoch: [48/50] ==========
[2020-03-03 09:29:15,317] - step: [100/391], train_loss: 0.485 | train_acc: 83.414% | lr: 0.000200
[2020-03-03 09:29:16,168] - step: [200/391], train_loss: 0.487 | train_acc: 83.430% | lr: 0.000200
[2020-03-03 09:29:17,015] - step: [300/391], train_loss: 0.490 | train_acc: 83.224% | lr: 0.000200
[2020-03-03 09:29:17,820] - --- cost time: 3.4464s ---
[2020-03-03 09:29:17,821] - *************** test ***************
[2020-03-03 09:29:18,364] - test_loss: 0.656 | test_acc: 78.260%
[2020-03-03 09:29:18,365] - ************************************

[2020-03-03 09:29:18,396] - ========== epoch: [49/50] ==========
[2020-03-03 09:29:19,333] - step: [100/391], train_loss: 0.488 | train_acc: 82.961% | lr: 0.000200
[2020-03-03 09:29:20,180] - step: [200/391], train_loss: 0.489 | train_acc: 83.141% | lr: 0.000200
[2020-03-03 09:29:21,029] - step: [300/391], train_loss: 0.489 | train_acc: 83.240% | lr: 0.000200
[2020-03-03 09:29:21,816] - --- cost time: 3.4204s ---
[2020-03-03 09:29:21,817] - *************** test ***************
[2020-03-03 09:29:22,342] - test_loss: 0.638 | test_acc: 78.810%
[2020-03-03 09:29:22,342] - ************************************

[2020-03-03 09:29:22,389] - ========== epoch: [50/50] ==========
[2020-03-03 09:29:23,331] - step: [100/391], train_loss: 0.480 | train_acc: 83.469% | lr: 0.000200
[2020-03-03 09:29:24,179] - step: [200/391], train_loss: 0.477 | train_acc: 83.539% | lr: 0.000200
[2020-03-03 09:29:25,028] - step: [300/391], train_loss: 0.480 | train_acc: 83.555% | lr: 0.000200
[2020-03-03 09:29:25,819] - --- cost time: 3.4300s ---
[2020-03-03 09:29:25,819] - *************** test ***************
[2020-03-03 09:29:26,340] - test_loss: 0.648 | test_acc: 78.450%
[2020-03-03 09:29:26,340] - ************************************

[2020-03-03 09:29:26,507] - Training Finished ==> best accuracy: 78.810%
[2020-03-03 09:30:10,241] - {'architecture': 'nin', 'ckpt_path': './', 'ckpt_name': 'nin', 'log_path': './', 'log_name': 'cifar10', 'log_color': {'train': 'blue', 'cost_time': 'yellow', 'time': 'purple', 'test': 'red'}, 'data_name': 'CIFAR10', 'num_classes': 10, 'train_set_path': './data/cifar-10', 'test_set_path': './data/cifar-10', 'augmentation': {'normalize': True, 'random_crop': True, 'random_horizontal_filp': True}, 'device': 'cuda', 'input_size': 32, 'batch_size': 128, 'num_epochs': 50, 'num_print': 100, 'num_workers': 4, 'eval_freq': 1, 'test_batch': 200, 'optimizer': {'name': 'Adam', 'params': {'lr': 0.002}}, 'lr_scheduler': {'type': 'STEP', 'lr_epochs': [40], 'lr_mults': 0.1}, 'learning_curve': {'style': 'ggplot', 'xtick_step': 5, 'draw_freq': 10, 'save_path': './'}}
NiN(
  (features): Sequential(
    (0): Sequential(
      (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2))
      (1): ReLU(inplace)
      (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU(inplace)
      (4): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
      (5): ReLU(inplace)
    )
    (1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (2): Sequential(
      (0): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
      (1): ReLU(inplace)
      (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU(inplace)
      (4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (5): ReLU(inplace)
    )
    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Sequential(
      (0): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace)
      (2): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU(inplace)
      (4): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
      (5): ReLU(inplace)
    )
    (5): Dropout(p=0.5)
    (6): Sequential(
      (0): Conv2d(384, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace)
      (2): Conv2d(10, 10, kernel_size=(1, 1), stride=(1, 1))
      (3): ReLU(inplace)
      (4): Conv2d(10, 10, kernel_size=(1, 1), stride=(1, 1))
      (5): ReLU(inplace)
    )
  )
  (classifier): AdaptiveAvgPool2d(output_size=(1, 1))
)
-------------------- Training parameters: 1994662 --------------------
[2020-03-03 09:30:10,242] - ========== epoch: [1/50] ==========
[2020-03-03 09:30:11,391] - step: [100/391], train_loss: 2.242 | train_acc: 16.102% | lr: 0.002000
[2020-03-03 09:30:12,242] - step: [200/391], train_loss: 2.201 | train_acc: 17.719% | lr: 0.002000
[2020-03-03 09:30:13,096] - step: [300/391], train_loss: 2.166 | train_acc: 18.708% | lr: 0.002000
[2020-03-03 09:30:13,884] - --- cost time: 3.6420s ---
[2020-03-03 09:30:13,884] - *************** test ***************
[2020-03-03 09:30:14,415] - test_loss: 2.018 | test_acc: 25.970%
[2020-03-03 09:30:14,415] - ************************************

[2020-03-03 09:30:14,467] - ========== epoch: [2/50] ==========
[2020-03-03 09:30:15,422] - step: [100/391], train_loss: 1.946 | train_acc: 28.742% | lr: 0.002000
[2020-03-03 09:30:16,260] - step: [200/391], train_loss: 1.920 | train_acc: 29.848% | lr: 0.002000
[2020-03-03 09:30:17,103] - step: [300/391], train_loss: 1.878 | train_acc: 31.534% | lr: 0.002000
[2020-03-03 09:30:17,888] - --- cost time: 3.4192s ---
[2020-03-03 09:30:17,888] - *************** test ***************
[2020-03-03 09:30:18,415] - test_loss: 1.720 | test_acc: 36.480%
[2020-03-03 09:30:18,415] - ************************************

[2020-03-03 09:30:18,460] - ========== epoch: [3/50] ==========
[2020-03-03 09:30:19,399] - step: [100/391], train_loss: 1.681 | train_acc: 39.594% | lr: 0.002000
[2020-03-03 09:30:20,243] - step: [200/391], train_loss: 1.658 | train_acc: 40.348% | lr: 0.002000
[2020-03-03 09:30:21,084] - step: [300/391], train_loss: 1.634 | train_acc: 41.555% | lr: 0.002000
[2020-03-03 09:30:21,866] - --- cost time: 3.4056s ---
[2020-03-03 09:30:21,866] - *************** test ***************
[2020-03-03 09:30:22,395] - test_loss: 1.542 | test_acc: 45.630%
[2020-03-03 09:30:22,395] - ************************************

[2020-03-03 09:30:22,452] - ========== epoch: [4/50] ==========
[2020-03-03 09:30:23,389] - step: [100/391], train_loss: 1.540 | train_acc: 46.062% | lr: 0.002000
[2020-03-03 09:30:24,234] - step: [200/391], train_loss: 1.532 | train_acc: 46.516% | lr: 0.002000
[2020-03-03 09:30:25,081] - step: [300/391], train_loss: 1.520 | train_acc: 47.120% | lr: 0.002000
[2020-03-03 09:30:25,867] - --- cost time: 3.4142s ---
[2020-03-03 09:30:25,867] - *************** test ***************
[2020-03-03 09:30:26,386] - test_loss: 1.362 | test_acc: 52.030%
[2020-03-03 09:30:26,386] - ************************************

[2020-03-03 09:30:26,436] - ========== epoch: [5/50] ==========
[2020-03-03 09:30:27,382] - step: [100/391], train_loss: 1.331 | train_acc: 54.172% | lr: 0.002000
[2020-03-03 09:30:28,224] - step: [200/391], train_loss: 1.307 | train_acc: 54.332% | lr: 0.002000
[2020-03-03 09:30:29,069] - step: [300/391], train_loss: 1.277 | train_acc: 55.344% | lr: 0.002000
[2020-03-03 09:30:29,871] - --- cost time: 3.4340s ---
[2020-03-03 09:30:29,871] - *************** test ***************
[2020-03-03 09:30:30,400] - test_loss: 1.184 | test_acc: 58.310%
[2020-03-03 09:30:30,400] - ************************************

[2020-03-03 09:30:30,444] - ========== epoch: [6/50] ==========
[2020-03-03 09:30:31,377] - step: [100/391], train_loss: 1.169 | train_acc: 58.938% | lr: 0.002000
[2020-03-03 09:30:32,221] - step: [200/391], train_loss: 1.160 | train_acc: 59.410% | lr: 0.002000
[2020-03-03 09:30:33,065] - step: [300/391], train_loss: 1.148 | train_acc: 59.740% | lr: 0.002000
[2020-03-03 09:30:33,849] - --- cost time: 3.4044s ---
[2020-03-03 09:30:33,849] - *************** test ***************
[2020-03-03 09:30:34,372] - test_loss: 1.129 | test_acc: 59.990%
[2020-03-03 09:30:34,372] - ************************************

[2020-03-03 09:30:34,418] - ========== epoch: [7/50] ==========
[2020-03-03 09:30:35,352] - step: [100/391], train_loss: 1.076 | train_acc: 63.086% | lr: 0.002000
[2020-03-03 09:30:36,195] - step: [200/391], train_loss: 1.085 | train_acc: 62.531% | lr: 0.002000
[2020-03-03 09:30:37,036] - step: [300/391], train_loss: 1.079 | train_acc: 62.578% | lr: 0.002000
[2020-03-03 09:30:37,819] - --- cost time: 3.4006s ---
[2020-03-03 09:30:37,820] - *************** test ***************
[2020-03-03 09:30:38,348] - test_loss: 1.089 | test_acc: 62.490%
[2020-03-03 09:30:38,348] - ************************************

[2020-03-03 09:30:38,420] - ========== epoch: [8/50] ==========
[2020-03-03 09:30:39,356] - step: [100/391], train_loss: 1.048 | train_acc: 64.148% | lr: 0.002000
[2020-03-03 09:30:40,198] - step: [200/391], train_loss: 1.045 | train_acc: 64.137% | lr: 0.002000
[2020-03-03 09:30:41,043] - step: [300/391], train_loss: 1.041 | train_acc: 64.042% | lr: 0.002000
[2020-03-03 09:30:41,848] - --- cost time: 3.4276s ---
[2020-03-03 09:30:41,848] - *************** test ***************
[2020-03-03 09:30:42,382] - test_loss: 1.026 | test_acc: 64.270%
[2020-03-03 09:30:42,382] - ************************************

[2020-03-03 09:30:42,429] - ========== epoch: [9/50] ==========
[2020-03-03 09:30:43,364] - step: [100/391], train_loss: 0.984 | train_acc: 66.391% | lr: 0.002000
[2020-03-03 09:30:44,209] - step: [200/391], train_loss: 0.985 | train_acc: 66.133% | lr: 0.002000
[2020-03-03 09:30:45,054] - step: [300/391], train_loss: 0.986 | train_acc: 66.128% | lr: 0.002000
[2020-03-03 09:30:45,838] - --- cost time: 3.4086s ---
[2020-03-03 09:30:45,838] - *************** test ***************
[2020-03-03 09:30:46,369] - test_loss: 1.007 | test_acc: 65.340%
[2020-03-03 09:30:46,369] - ************************************

[2020-03-03 09:30:46,416] - ========== epoch: [10/50] ==========
[2020-03-03 09:30:47,351] - step: [100/391], train_loss: 0.958 | train_acc: 66.844% | lr: 0.002000
[2020-03-03 09:30:48,190] - step: [200/391], train_loss: 0.946 | train_acc: 67.289% | lr: 0.002000
[2020-03-03 09:30:49,035] - step: [300/391], train_loss: 0.942 | train_acc: 67.427% | lr: 0.002000
[2020-03-03 09:30:49,821] - --- cost time: 3.4047s ---
[2020-03-03 09:30:49,821] - *************** test ***************
[2020-03-03 09:30:50,349] - test_loss: 0.985 | test_acc: 66.040%
[2020-03-03 09:30:50,349] - ************************************

[2020-03-03 09:30:50,553] - ========== epoch: [11/50] ==========
[2020-03-03 09:30:51,495] - step: [100/391], train_loss: 0.924 | train_acc: 68.109% | lr: 0.002000
[2020-03-03 09:30:52,338] - step: [200/391], train_loss: 0.916 | train_acc: 68.520% | lr: 0.002000
[2020-03-03 09:30:53,188] - step: [300/391], train_loss: 0.914 | train_acc: 68.641% | lr: 0.002000
[2020-03-03 09:30:53,995] - --- cost time: 3.4417s ---
[2020-03-03 09:30:53,996] - *************** test ***************
[2020-03-03 09:30:54,526] - test_loss: 0.968 | test_acc: 67.640%
[2020-03-03 09:30:54,526] - ************************************

[2020-03-03 09:30:54,573] - ========== epoch: [12/50] ==========
[2020-03-03 09:30:55,530] - step: [100/391], train_loss: 0.891 | train_acc: 70.008% | lr: 0.002000
[2020-03-03 09:30:56,407] - step: [200/391], train_loss: 0.885 | train_acc: 69.906% | lr: 0.002000
[2020-03-03 09:30:57,278] - step: [300/391], train_loss: 0.884 | train_acc: 69.872% | lr: 0.002000
[2020-03-03 09:30:58,080] - --- cost time: 3.5072s ---
[2020-03-03 09:30:58,081] - *************** test ***************
[2020-03-03 09:30:58,620] - test_loss: 0.922 | test_acc: 68.940%
[2020-03-03 09:30:58,620] - ************************************

[2020-03-03 09:30:58,672] - ========== epoch: [13/50] ==========
[2020-03-03 09:30:59,645] - step: [100/391], train_loss: 0.883 | train_acc: 69.867% | lr: 0.002000
[2020-03-03 09:31:00,507] - step: [200/391], train_loss: 0.882 | train_acc: 69.914% | lr: 0.002000
[2020-03-03 09:31:01,380] - step: [300/391], train_loss: 0.868 | train_acc: 70.354% | lr: 0.002000
[2020-03-03 09:31:02,172] - --- cost time: 3.4993s ---
[2020-03-03 09:31:02,173] - *************** test ***************
[2020-03-03 09:31:02,707] - test_loss: 0.939 | test_acc: 68.410%
[2020-03-03 09:31:02,708] - ************************************

[2020-03-03 09:31:02,740] - ========== epoch: [14/50] ==========
[2020-03-03 09:31:03,698] - step: [100/391], train_loss: 0.862 | train_acc: 70.500% | lr: 0.002000
[2020-03-03 09:31:04,546] - step: [200/391], train_loss: 0.857 | train_acc: 70.602% | lr: 0.002000
[2020-03-03 09:31:05,394] - step: [300/391], train_loss: 0.857 | train_acc: 70.599% | lr: 0.002000
[2020-03-03 09:31:06,182] - --- cost time: 3.4414s ---
[2020-03-03 09:31:06,183] - *************** test ***************
[2020-03-03 09:31:06,716] - test_loss: 0.874 | test_acc: 70.380%
[2020-03-03 09:31:06,716] - ************************************

[2020-03-03 09:31:06,755] - ========== epoch: [15/50] ==========
[2020-03-03 09:31:07,697] - step: [100/391], train_loss: 0.822 | train_acc: 71.680% | lr: 0.002000
[2020-03-03 09:31:08,543] - step: [200/391], train_loss: 0.816 | train_acc: 72.047% | lr: 0.002000
[2020-03-03 09:31:09,391] - step: [300/391], train_loss: 0.810 | train_acc: 72.188% | lr: 0.002000
[2020-03-03 09:31:10,182] - --- cost time: 3.4262s ---
[2020-03-03 09:31:10,182] - *************** test ***************
[2020-03-03 09:31:10,711] - test_loss: 0.867 | test_acc: 70.600%
[2020-03-03 09:31:10,711] - ************************************

[2020-03-03 09:31:10,757] - ========== epoch: [16/50] ==========
[2020-03-03 09:31:11,701] - step: [100/391], train_loss: 0.818 | train_acc: 72.000% | lr: 0.002000
[2020-03-03 09:31:12,548] - step: [200/391], train_loss: 0.807 | train_acc: 72.504% | lr: 0.002000
[2020-03-03 09:31:13,398] - step: [300/391], train_loss: 0.807 | train_acc: 72.443% | lr: 0.002000
[2020-03-03 09:31:14,189] - --- cost time: 3.4315s ---
[2020-03-03 09:31:14,190] - *************** test ***************
[2020-03-03 09:31:14,722] - test_loss: 0.864 | test_acc: 70.830%
[2020-03-03 09:31:14,722] - ************************************

[2020-03-03 09:31:14,798] - ========== epoch: [17/50] ==========
[2020-03-03 09:31:15,741] - step: [100/391], train_loss: 0.791 | train_acc: 72.977% | lr: 0.002000
[2020-03-03 09:31:16,588] - step: [200/391], train_loss: 0.790 | train_acc: 73.023% | lr: 0.002000
[2020-03-03 09:31:17,439] - step: [300/391], train_loss: 0.788 | train_acc: 73.076% | lr: 0.002000
[2020-03-03 09:31:18,229] - --- cost time: 3.4307s ---
[2020-03-03 09:31:18,229] - *************** test ***************
[2020-03-03 09:31:18,762] - test_loss: 0.872 | test_acc: 71.230%
[2020-03-03 09:31:18,762] - ************************************

[2020-03-03 09:31:18,809] - ========== epoch: [18/50] ==========
[2020-03-03 09:31:19,752] - step: [100/391], train_loss: 0.758 | train_acc: 74.234% | lr: 0.002000
[2020-03-03 09:31:20,602] - step: [200/391], train_loss: 0.768 | train_acc: 73.898% | lr: 0.002000
[2020-03-03 09:31:21,452] - step: [300/391], train_loss: 0.777 | train_acc: 73.786% | lr: 0.002000
[2020-03-03 09:31:22,241] - --- cost time: 3.4309s ---
[2020-03-03 09:31:22,241] - *************** test ***************
[2020-03-03 09:31:22,767] - test_loss: 0.827 | test_acc: 71.360%
[2020-03-03 09:31:22,767] - ************************************

[2020-03-03 09:31:22,813] - ========== epoch: [19/50] ==========
[2020-03-03 09:31:23,753] - step: [100/391], train_loss: 0.751 | train_acc: 74.203% | lr: 0.002000
[2020-03-03 09:31:24,598] - step: [200/391], train_loss: 0.763 | train_acc: 74.180% | lr: 0.002000
[2020-03-03 09:31:25,448] - step: [300/391], train_loss: 0.764 | train_acc: 74.128% | lr: 0.002000
[2020-03-03 09:31:26,240] - --- cost time: 3.4262s ---
[2020-03-03 09:31:26,240] - *************** test ***************
[2020-03-03 09:31:26,777] - test_loss: 0.803 | test_acc: 72.860%
[2020-03-03 09:31:26,777] - ************************************

[2020-03-03 09:31:26,822] - ========== epoch: [20/50] ==========
[2020-03-03 09:31:27,764] - step: [100/391], train_loss: 0.744 | train_acc: 75.062% | lr: 0.002000
[2020-03-03 09:31:28,614] - step: [200/391], train_loss: 0.739 | train_acc: 75.102% | lr: 0.002000
[2020-03-03 09:31:29,463] - step: [300/391], train_loss: 0.745 | train_acc: 74.940% | lr: 0.002000
[2020-03-03 09:31:30,253] - --- cost time: 3.4309s ---
[2020-03-03 09:31:30,253] - *************** test ***************
[2020-03-03 09:31:30,788] - test_loss: 0.789 | test_acc: 73.500%
[2020-03-03 09:31:30,788] - ************************************

[2020-03-03 09:31:30,962] - ========== epoch: [21/50] ==========
[2020-03-03 09:31:31,908] - step: [100/391], train_loss: 0.713 | train_acc: 75.656% | lr: 0.002000
[2020-03-03 09:31:32,756] - step: [200/391], train_loss: 0.720 | train_acc: 75.516% | lr: 0.002000
[2020-03-03 09:31:33,607] - step: [300/391], train_loss: 0.728 | train_acc: 75.237% | lr: 0.002000
[2020-03-03 09:31:34,396] - --- cost time: 3.4336s ---
[2020-03-03 09:31:34,396] - *************** test ***************
[2020-03-03 09:31:34,928] - test_loss: 0.798 | test_acc: 73.400%
[2020-03-03 09:31:34,928] - ************************************

[2020-03-03 09:31:34,953] - ========== epoch: [22/50] ==========
[2020-03-03 09:31:35,893] - step: [100/391], train_loss: 0.689 | train_acc: 76.469% | lr: 0.002000
[2020-03-03 09:31:36,741] - step: [200/391], train_loss: 0.709 | train_acc: 75.902% | lr: 0.002000
[2020-03-03 09:31:37,589] - step: [300/391], train_loss: 0.715 | train_acc: 75.797% | lr: 0.002000
[2020-03-03 09:31:38,381] - --- cost time: 3.4273s ---
[2020-03-03 09:31:38,381] - *************** test ***************
[2020-03-03 09:31:38,947] - test_loss: 0.804 | test_acc: 73.360%
[2020-03-03 09:31:38,947] - ************************************

[2020-03-03 09:31:38,978] - ========== epoch: [23/50] ==========
[2020-03-03 09:31:39,922] - step: [100/391], train_loss: 0.700 | train_acc: 76.109% | lr: 0.002000
[2020-03-03 09:31:40,769] - step: [200/391], train_loss: 0.708 | train_acc: 75.969% | lr: 0.002000
[2020-03-03 09:31:41,615] - step: [300/391], train_loss: 0.709 | train_acc: 76.102% | lr: 0.002000
[2020-03-03 09:31:42,403] - --- cost time: 3.4246s ---
[2020-03-03 09:31:42,403] - *************** test ***************
[2020-03-03 09:31:42,937] - test_loss: 0.801 | test_acc: 72.810%
[2020-03-03 09:31:42,937] - ************************************

[2020-03-03 09:31:42,962] - ========== epoch: [24/50] ==========
[2020-03-03 09:31:43,903] - step: [100/391], train_loss: 0.688 | train_acc: 76.844% | lr: 0.002000
[2020-03-03 09:31:44,749] - step: [200/391], train_loss: 0.694 | train_acc: 76.695% | lr: 0.002000
[2020-03-03 09:31:45,596] - step: [300/391], train_loss: 0.692 | train_acc: 76.706% | lr: 0.002000
[2020-03-03 09:31:46,386] - --- cost time: 3.4234s ---
[2020-03-03 09:31:46,386] - *************** test ***************
[2020-03-03 09:31:46,914] - test_loss: 0.785 | test_acc: 73.140%
[2020-03-03 09:31:46,915] - ************************************

[2020-03-03 09:31:46,940] - ========== epoch: [25/50] ==========
[2020-03-03 09:31:47,879] - step: [100/391], train_loss: 0.697 | train_acc: 76.398% | lr: 0.002000
[2020-03-03 09:31:48,726] - step: [200/391], train_loss: 0.691 | train_acc: 76.586% | lr: 0.002000
[2020-03-03 09:31:49,573] - step: [300/391], train_loss: 0.693 | train_acc: 76.516% | lr: 0.002000
[2020-03-03 09:31:50,362] - --- cost time: 3.4221s ---
[2020-03-03 09:31:50,363] - *************** test ***************
[2020-03-03 09:31:50,892] - test_loss: 0.767 | test_acc: 74.950%
[2020-03-03 09:31:50,892] - ************************************

[2020-03-03 09:31:50,939] - ========== epoch: [26/50] ==========
[2020-03-03 09:31:51,883] - step: [100/391], train_loss: 0.666 | train_acc: 77.430% | lr: 0.002000
[2020-03-03 09:31:52,731] - step: [200/391], train_loss: 0.671 | train_acc: 77.246% | lr: 0.002000
[2020-03-03 09:31:53,577] - step: [300/391], train_loss: 0.669 | train_acc: 77.372% | lr: 0.002000
[2020-03-03 09:31:54,364] - --- cost time: 3.4244s ---
[2020-03-03 09:31:54,364] - *************** test ***************
[2020-03-03 09:31:54,886] - test_loss: 0.795 | test_acc: 73.860%
[2020-03-03 09:31:54,886] - ************************************

[2020-03-03 09:31:54,911] - ========== epoch: [27/50] ==========
[2020-03-03 09:31:55,855] - step: [100/391], train_loss: 0.684 | train_acc: 76.695% | lr: 0.002000
[2020-03-03 09:31:56,706] - step: [200/391], train_loss: 0.680 | train_acc: 76.941% | lr: 0.002000
[2020-03-03 09:31:57,555] - step: [300/391], train_loss: 0.679 | train_acc: 77.023% | lr: 0.002000
[2020-03-03 09:31:58,343] - --- cost time: 3.4312s ---
[2020-03-03 09:31:58,343] - *************** test ***************
[2020-03-03 09:31:58,869] - test_loss: 0.778 | test_acc: 74.760%
[2020-03-03 09:31:58,869] - ************************************

[2020-03-03 09:31:58,900] - ========== epoch: [28/50] ==========
[2020-03-03 09:31:59,843] - step: [100/391], train_loss: 0.665 | train_acc: 77.312% | lr: 0.002000
[2020-03-03 09:32:00,692] - step: [200/391], train_loss: 0.670 | train_acc: 77.395% | lr: 0.002000
[2020-03-03 09:32:01,542] - step: [300/391], train_loss: 0.666 | train_acc: 77.529% | lr: 0.002000
[2020-03-03 09:32:02,332] - --- cost time: 3.4317s ---
[2020-03-03 09:32:02,332] - *************** test ***************
[2020-03-03 09:32:02,860] - test_loss: 0.760 | test_acc: 75.070%
[2020-03-03 09:32:02,861] - ************************************

[2020-03-03 09:32:02,896] - ========== epoch: [29/50] ==========
[2020-03-03 09:32:03,836] - step: [100/391], train_loss: 0.655 | train_acc: 78.305% | lr: 0.002000
[2020-03-03 09:32:04,684] - step: [200/391], train_loss: 0.663 | train_acc: 77.914% | lr: 0.002000
[2020-03-03 09:32:05,529] - step: [300/391], train_loss: 0.663 | train_acc: 77.846% | lr: 0.002000
[2020-03-03 09:32:06,334] - --- cost time: 3.4382s ---
[2020-03-03 09:32:06,335] - *************** test ***************
[2020-03-03 09:32:06,865] - test_loss: 0.733 | test_acc: 75.820%
[2020-03-03 09:32:06,865] - ************************************

[2020-03-03 09:32:06,911] - ========== epoch: [30/50] ==========
[2020-03-03 09:32:07,850] - step: [100/391], train_loss: 0.628 | train_acc: 79.062% | lr: 0.002000
[2020-03-03 09:32:08,698] - step: [200/391], train_loss: 0.644 | train_acc: 78.301% | lr: 0.002000
[2020-03-03 09:32:09,543] - step: [300/391], train_loss: 0.653 | train_acc: 78.039% | lr: 0.002000
[2020-03-03 09:32:10,329] - --- cost time: 3.4178s ---
[2020-03-03 09:32:10,330] - *************** test ***************
[2020-03-03 09:32:10,855] - test_loss: 0.765 | test_acc: 74.960%
[2020-03-03 09:32:10,855] - ************************************

[2020-03-03 09:32:11,020] - ========== epoch: [31/50] ==========
[2020-03-03 09:32:11,965] - step: [100/391], train_loss: 0.623 | train_acc: 78.766% | lr: 0.002000
[2020-03-03 09:32:12,813] - step: [200/391], train_loss: 0.625 | train_acc: 79.043% | lr: 0.002000
[2020-03-03 09:32:13,662] - step: [300/391], train_loss: 0.632 | train_acc: 78.802% | lr: 0.002000
[2020-03-03 09:32:14,450] - --- cost time: 3.4300s ---
[2020-03-03 09:32:14,451] - *************** test ***************
[2020-03-03 09:32:14,993] - test_loss: 0.817 | test_acc: 72.540%
[2020-03-03 09:32:14,993] - ************************************

[2020-03-03 09:32:15,018] - ========== epoch: [32/50] ==========
[2020-03-03 09:32:15,957] - step: [100/391], train_loss: 0.641 | train_acc: 78.750% | lr: 0.002000
[2020-03-03 09:32:16,805] - step: [200/391], train_loss: 0.638 | train_acc: 78.617% | lr: 0.002000
[2020-03-03 09:32:17,651] - step: [300/391], train_loss: 0.642 | train_acc: 78.419% | lr: 0.002000
[2020-03-03 09:32:18,455] - --- cost time: 3.4368s ---
[2020-03-03 09:32:18,456] - *************** test ***************
[2020-03-03 09:32:18,984] - test_loss: 0.736 | test_acc: 76.050%
[2020-03-03 09:32:18,984] - ************************************

[2020-03-03 09:32:19,031] - ========== epoch: [33/50] ==========
[2020-03-03 09:32:19,969] - step: [100/391], train_loss: 0.617 | train_acc: 79.328% | lr: 0.002000
[2020-03-03 09:32:20,814] - step: [200/391], train_loss: 0.629 | train_acc: 78.797% | lr: 0.002000
[2020-03-03 09:32:21,661] - step: [300/391], train_loss: 0.627 | train_acc: 78.953% | lr: 0.002000
[2020-03-03 09:32:22,451] - --- cost time: 3.4205s ---
[2020-03-03 09:32:22,452] - *************** test ***************
[2020-03-03 09:32:22,979] - test_loss: 0.749 | test_acc: 75.730%
[2020-03-03 09:32:22,979] - ************************************

[2020-03-03 09:32:23,003] - ========== epoch: [34/50] ==========
[2020-03-03 09:32:23,939] - step: [100/391], train_loss: 0.640 | train_acc: 78.492% | lr: 0.002000
[2020-03-03 09:32:24,784] - step: [200/391], train_loss: 0.632 | train_acc: 78.770% | lr: 0.002000
[2020-03-03 09:32:25,630] - step: [300/391], train_loss: 0.627 | train_acc: 78.971% | lr: 0.002000
[2020-03-03 09:32:26,413] - --- cost time: 3.4092s ---
[2020-03-03 09:32:26,413] - *************** test ***************
[2020-03-03 09:32:26,933] - test_loss: 0.790 | test_acc: 74.460%
[2020-03-03 09:32:26,933] - ************************************

[2020-03-03 09:32:26,958] - ========== epoch: [35/50] ==========
[2020-03-03 09:32:27,898] - step: [100/391], train_loss: 0.611 | train_acc: 79.117% | lr: 0.002000
[2020-03-03 09:32:28,744] - step: [200/391], train_loss: 0.613 | train_acc: 79.242% | lr: 0.002000
[2020-03-03 09:32:29,589] - step: [300/391], train_loss: 0.621 | train_acc: 78.922% | lr: 0.002000
[2020-03-03 09:32:30,377] - --- cost time: 3.4188s ---
[2020-03-03 09:32:30,378] - *************** test ***************
[2020-03-03 09:32:30,905] - test_loss: 0.709 | test_acc: 76.850%
[2020-03-03 09:32:30,905] - ************************************

[2020-03-03 09:32:30,957] - ========== epoch: [36/50] ==========
[2020-03-03 09:32:31,895] - step: [100/391], train_loss: 0.634 | train_acc: 78.656% | lr: 0.002000
[2020-03-03 09:32:32,742] - step: [200/391], train_loss: 0.633 | train_acc: 78.824% | lr: 0.002000
[2020-03-03 09:32:33,589] - step: [300/391], train_loss: 0.624 | train_acc: 79.109% | lr: 0.002000
[2020-03-03 09:32:34,379] - --- cost time: 3.4216s ---
[2020-03-03 09:32:34,379] - *************** test ***************
[2020-03-03 09:32:34,907] - test_loss: 0.742 | test_acc: 75.460%
[2020-03-03 09:32:34,908] - ************************************

[2020-03-03 09:32:34,933] - ========== epoch: [37/50] ==========
[2020-03-03 09:32:35,871] - step: [100/391], train_loss: 0.619 | train_acc: 79.352% | lr: 0.002000
[2020-03-03 09:32:36,719] - step: [200/391], train_loss: 0.618 | train_acc: 79.379% | lr: 0.002000
[2020-03-03 09:32:37,564] - step: [300/391], train_loss: 0.615 | train_acc: 79.292% | lr: 0.002000
[2020-03-03 09:32:38,352] - --- cost time: 3.4185s ---
[2020-03-03 09:32:38,352] - *************** test ***************
[2020-03-03 09:32:38,888] - test_loss: 0.736 | test_acc: 75.560%
[2020-03-03 09:32:38,888] - ************************************

[2020-03-03 09:32:38,914] - ========== epoch: [38/50] ==========
[2020-03-03 09:32:39,854] - step: [100/391], train_loss: 0.597 | train_acc: 79.797% | lr: 0.002000
[2020-03-03 09:32:40,700] - step: [200/391], train_loss: 0.592 | train_acc: 79.992% | lr: 0.002000
[2020-03-03 09:32:41,548] - step: [300/391], train_loss: 0.602 | train_acc: 79.633% | lr: 0.002000
[2020-03-03 09:32:42,335] - --- cost time: 3.4213s ---
[2020-03-03 09:32:42,336] - *************** test ***************
[2020-03-03 09:32:42,862] - test_loss: 0.715 | test_acc: 76.660%
[2020-03-03 09:32:42,862] - ************************************

[2020-03-03 09:32:42,888] - ========== epoch: [39/50] ==========
[2020-03-03 09:32:43,829] - step: [100/391], train_loss: 0.603 | train_acc: 80.031% | lr: 0.002000
[2020-03-03 09:32:44,677] - step: [200/391], train_loss: 0.592 | train_acc: 80.332% | lr: 0.002000
[2020-03-03 09:32:45,527] - step: [300/391], train_loss: 0.595 | train_acc: 80.284% | lr: 0.002000
[2020-03-03 09:32:46,316] - --- cost time: 3.4281s ---
[2020-03-03 09:32:46,317] - *************** test ***************
[2020-03-03 09:32:46,844] - test_loss: 0.721 | test_acc: 76.380%
[2020-03-03 09:32:46,844] - ************************************

[2020-03-03 09:32:46,875] - ========== epoch: [40/50] ==========
[2020-03-03 09:32:47,841] - step: [100/391], train_loss: 0.599 | train_acc: 79.562% | lr: 0.002000
[2020-03-03 09:32:48,688] - step: [200/391], train_loss: 0.586 | train_acc: 80.312% | lr: 0.002000
[2020-03-03 09:32:49,534] - step: [300/391], train_loss: 0.595 | train_acc: 79.958% | lr: 0.002000
[2020-03-03 09:32:50,320] - --- cost time: 3.4439s ---
[2020-03-03 09:32:50,320] - *************** test ***************
[2020-03-03 09:32:50,883] - test_loss: 0.739 | test_acc: 76.310%
[2020-03-03 09:32:50,883] - ************************************

[2020-03-03 09:32:51,044] - ========== epoch: [41/50] ==========
[2020-03-03 09:32:51,993] - step: [100/391], train_loss: 0.532 | train_acc: 82.078% | lr: 0.000200
[2020-03-03 09:32:52,841] - step: [200/391], train_loss: 0.511 | train_acc: 82.777% | lr: 0.000200
[2020-03-03 09:32:53,687] - step: [300/391], train_loss: 0.503 | train_acc: 82.992% | lr: 0.000200
[2020-03-03 09:32:54,475] - --- cost time: 3.4299s ---
[2020-03-03 09:32:54,475] - *************** test ***************
[2020-03-03 09:32:55,000] - test_loss: 0.640 | test_acc: 79.530%
[2020-03-03 09:32:55,000] - ************************************

[2020-03-03 09:32:55,047] - ========== epoch: [42/50] ==========
[2020-03-03 09:32:55,986] - step: [100/391], train_loss: 0.488 | train_acc: 83.641% | lr: 0.000200
[2020-03-03 09:32:56,830] - step: [200/391], train_loss: 0.482 | train_acc: 83.570% | lr: 0.000200
[2020-03-03 09:32:57,677] - step: [300/391], train_loss: 0.484 | train_acc: 83.521% | lr: 0.000200
[2020-03-03 09:32:58,465] - --- cost time: 3.4177s ---
[2020-03-03 09:32:58,466] - *************** test ***************
[2020-03-03 09:32:58,992] - test_loss: 0.633 | test_acc: 79.170%
[2020-03-03 09:32:58,992] - ************************************

[2020-03-03 09:32:59,016] - ========== epoch: [43/50] ==========
[2020-03-03 09:32:59,954] - step: [100/391], train_loss: 0.472 | train_acc: 84.094% | lr: 0.000200
[2020-03-03 09:33:00,803] - step: [200/391], train_loss: 0.469 | train_acc: 84.188% | lr: 0.000200
[2020-03-03 09:33:01,649] - step: [300/391], train_loss: 0.467 | train_acc: 84.214% | lr: 0.000200
[2020-03-03 09:33:02,452] - --- cost time: 3.4352s ---
[2020-03-03 09:33:02,452] - *************** test ***************
[2020-03-03 09:33:02,982] - test_loss: 0.645 | test_acc: 79.210%
[2020-03-03 09:33:02,982] - ************************************

[2020-03-03 09:33:03,008] - ========== epoch: [44/50] ==========
[2020-03-03 09:33:03,947] - step: [100/391], train_loss: 0.468 | train_acc: 84.273% | lr: 0.000200
[2020-03-03 09:33:04,796] - step: [200/391], train_loss: 0.471 | train_acc: 84.133% | lr: 0.000200
[2020-03-03 09:33:05,641] - step: [300/391], train_loss: 0.469 | train_acc: 84.214% | lr: 0.000200
[2020-03-03 09:33:06,430] - --- cost time: 3.4220s ---
[2020-03-03 09:33:06,430] - *************** test ***************
[2020-03-03 09:33:06,969] - test_loss: 0.624 | test_acc: 79.750%
[2020-03-03 09:33:06,969] - ************************************

[2020-03-03 09:33:07,043] - ========== epoch: [45/50] ==========
[2020-03-03 09:33:07,985] - step: [100/391], train_loss: 0.458 | train_acc: 84.547% | lr: 0.000200
[2020-03-03 09:33:08,833] - step: [200/391], train_loss: 0.459 | train_acc: 84.438% | lr: 0.000200
[2020-03-03 09:33:09,682] - step: [300/391], train_loss: 0.460 | train_acc: 84.281% | lr: 0.000200
[2020-03-03 09:33:10,471] - --- cost time: 3.4271s ---
[2020-03-03 09:33:10,471] - *************** test ***************
[2020-03-03 09:33:11,038] - test_loss: 0.635 | test_acc: 79.430%
[2020-03-03 09:33:11,038] - ************************************

[2020-03-03 09:33:11,062] - ========== epoch: [46/50] ==========
[2020-03-03 09:33:12,003] - step: [100/391], train_loss: 0.452 | train_acc: 84.758% | lr: 0.000200
[2020-03-03 09:33:12,849] - step: [200/391], train_loss: 0.453 | train_acc: 84.469% | lr: 0.000200
[2020-03-03 09:33:13,699] - step: [300/391], train_loss: 0.453 | train_acc: 84.464% | lr: 0.000200
[2020-03-03 09:33:14,489] - --- cost time: 3.4262s ---
[2020-03-03 09:33:14,489] - *************** test ***************
[2020-03-03 09:33:15,022] - test_loss: 0.616 | test_acc: 80.030%
[2020-03-03 09:33:15,022] - ************************************

[2020-03-03 09:33:15,069] - ========== epoch: [47/50] ==========
[2020-03-03 09:33:16,009] - step: [100/391], train_loss: 0.448 | train_acc: 84.680% | lr: 0.000200
[2020-03-03 09:33:16,856] - step: [200/391], train_loss: 0.451 | train_acc: 84.770% | lr: 0.000200
[2020-03-03 09:33:17,703] - step: [300/391], train_loss: 0.449 | train_acc: 84.706% | lr: 0.000200
[2020-03-03 09:33:18,492] - --- cost time: 3.4224s ---
[2020-03-03 09:33:18,492] - *************** test ***************
[2020-03-03 09:33:19,028] - test_loss: 0.616 | test_acc: 80.130%
[2020-03-03 09:33:19,028] - ************************************

[2020-03-03 09:33:19,074] - ========== epoch: [48/50] ==========
[2020-03-03 09:33:20,012] - step: [100/391], train_loss: 0.434 | train_acc: 85.164% | lr: 0.000200
[2020-03-03 09:33:20,858] - step: [200/391], train_loss: 0.442 | train_acc: 84.953% | lr: 0.000200
[2020-03-03 09:33:21,707] - step: [300/391], train_loss: 0.444 | train_acc: 84.773% | lr: 0.000200
[2020-03-03 09:33:22,497] - --- cost time: 3.4222s ---
[2020-03-03 09:33:22,497] - *************** test ***************
[2020-03-03 09:33:23,027] - test_loss: 0.629 | test_acc: 79.310%
[2020-03-03 09:33:23,027] - ************************************

[2020-03-03 09:33:23,052] - ========== epoch: [49/50] ==========
[2020-03-03 09:33:23,993] - step: [100/391], train_loss: 0.443 | train_acc: 85.117% | lr: 0.000200
[2020-03-03 09:33:24,841] - step: [200/391], train_loss: 0.434 | train_acc: 85.457% | lr: 0.000200
[2020-03-03 09:33:25,688] - step: [300/391], train_loss: 0.438 | train_acc: 85.216% | lr: 0.000200
[2020-03-03 09:33:26,476] - --- cost time: 3.4229s ---
[2020-03-03 09:33:26,476] - *************** test ***************
[2020-03-03 09:33:27,010] - test_loss: 0.619 | test_acc: 79.690%
[2020-03-03 09:33:27,011] - ************************************

[2020-03-03 09:33:27,036] - ========== epoch: [50/50] ==========
[2020-03-03 09:33:27,977] - step: [100/391], train_loss: 0.417 | train_acc: 85.867% | lr: 0.000200
[2020-03-03 09:33:28,825] - step: [200/391], train_loss: 0.431 | train_acc: 85.402% | lr: 0.000200
[2020-03-03 09:33:29,673] - step: [300/391], train_loss: 0.435 | train_acc: 85.211% | lr: 0.000200
[2020-03-03 09:33:30,476] - --- cost time: 3.4396s ---
[2020-03-03 09:33:30,477] - *************** test ***************
[2020-03-03 09:33:31,024] - test_loss: 0.624 | test_acc: 79.470%
[2020-03-03 09:33:31,024] - ************************************

[2020-03-03 09:33:31,190] - Training Finished ==> best accuracy: 80.130%
